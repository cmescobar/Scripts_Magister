{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:04:46.206185Z",
     "start_time": "2021-04-19T05:04:35.635483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal, fftpack\n",
    "from collections import defaultdict\n",
    "from testing_functions import test_hss\n",
    "from process_functions import preprocessing_audio\n",
    "from utils import find_and_open_audio, signal_segmentation, get_resp_segments\n",
    "from heart_sound_segmentation.filter_and_sampling import downsampling_signal, \\\n",
    "    upsampling_signal\n",
    "from source_separation.descriptor_functions import get_spectrogram\n",
    "from IPython.display import Audio\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing, linear_model, svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from pybalu.feature_selection import sfs\n",
    "from pybalu.feature_transformation import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones previas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:04:48.848586Z",
     "start_time": "2021-04-19T05:04:48.793172Z"
    },
    "code_folding": [
     1,
     166,
     242,
     306
    ]
   },
   "outputs": [],
   "source": [
    "# Funciones de características\n",
    "def get_filterbanks(N, samplerate, freq_lim, n_filters, norm_exp=1,\n",
    "                    scale_type='mel', filter_type='triangular',\n",
    "                    norm_filters=True, plot_filterbank=False):\n",
    "    '''Función que permite obtener un banco de filtros linealmente\n",
    "    espaciados o espaciados en frecuencia de mel para calcular\n",
    "    coeficientes cepstrales.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : ndarray\n",
    "        Largo de la señal.\n",
    "    samplerate : float\n",
    "        Tasa de muestreo de la señal de entrada.\n",
    "    freq_lim : float\n",
    "        Frecuencia límite para calcular los coeficientes cepstrales.\n",
    "    n_filters : int\n",
    "        Cantidad de filtros a obtener.\n",
    "    scale_type : {'mel', 'linear'}, optional\n",
    "        Tipo de espaciado entre los bancos de filtros para el cálculo\n",
    "        de los coeficientes cepstrales. Por defecto es 'mel' (MFCC). \n",
    "    filter_type : {'triangular', 'hanning', 'squared'}, optional\n",
    "        Forma del filtro a utilizar para el cálculo de la energía en \n",
    "        cada banda. Por defecto es 'triangular'.\n",
    "    inverse_func : {'dct', 'idft'}, optional\n",
    "        Función a utilizar para obtener los coeficientes cepstrales.\n",
    "        Por defecto es 'dct'.\n",
    "    plot_filterbank : bool, optional\n",
    "        Booleano que indica si se grafica el banco de filtros. Por \n",
    "        defecto es False.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [1] http://practicalcryptography.com/miscellaneous/machine-learning/\n",
    "        guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "    [2] Xuedong Huang, Alex Acero, Hsiao-Wuen Hon - Spoken Language \n",
    "        Processing A Guide to Theory, Algorithm and System \n",
    "        Development-Prentice Hall PTR (2001)\n",
    "    '''\n",
    "    def _freq_to_bin(f):\n",
    "        # Definición del bin correspondiente en la definición\n",
    "        # del intervalo de cálculo. Se usa (N - 1) ya que los bins\n",
    "        # se definen entre 0 y (N - 1) (largo N)\n",
    "        return np.rint(f / samplerate * (N - 1)).astype(int)\n",
    "    \n",
    "    \n",
    "    def _triangular_filter(bins_points):\n",
    "        # Definición del banco de filtros\n",
    "        filter_bank = np.zeros((n_filters, N))\n",
    "        \n",
    "        for i in range(1, n_filters + 1):\n",
    "            # Tramo ascendente del filtro triangular\n",
    "            filter_bank[i - 1][bins_points[i - 1]:bins_points[i] + 1] = \\\n",
    "                np.linspace(0, 1, abs(bins_points[i] - bins_points[i - 1] + 1))\n",
    "            \n",
    "            # Tramo descendente del filtro triangular\n",
    "            filter_bank[i - 1][bins_points[i]:bins_points[i + 1] + 1] = \\\n",
    "                np.linspace(1, 0, abs(bins_points[i + 1] - bins_points[i] + 1))\n",
    "            \n",
    "        return filter_bank\n",
    "    \n",
    "    \n",
    "    def _hanning_filter(bins_points):\n",
    "        # Definición del banco de filtros\n",
    "        filter_bank = np.zeros((n_filters, N))\n",
    "        \n",
    "        for i in range(1, n_filters + 1):\n",
    "            # Tramo ascendente del filtro triangular\n",
    "            filter_bank[i - 1][bins_points[i - 1]:bins_points[i + 1] + 1] = \\\n",
    "                np.hanning(abs(bins_points[i + 1] - bins_points[i - 1] + 1))\n",
    "        \n",
    "        return filter_bank\n",
    "    \n",
    "    \n",
    "    def _squared_filter(bins_points):\n",
    "        # Definición del banco de filtros\n",
    "        filter_bank = np.zeros((n_filters, N))\n",
    "        \n",
    "        for i in range(1, n_filters + 1):\n",
    "            # Tramo ascendente del filtro triangular\n",
    "            filter_bank[i - 1][bins_points[i - 1]:bins_points[i + 1] + 1] = 1\n",
    "        \n",
    "        return filter_bank\n",
    "    \n",
    "    \n",
    "    def _norm_filterbank(filter_bank):\n",
    "        # Definición del banco de filtros de salida\n",
    "        filter_bank_out = np.zeros((n_filters, N))\n",
    "        \n",
    "        # Normalizar los filtros a energía 1\n",
    "        for i in range(n_filters):\n",
    "            filter_bank_out[i] = filter_bank[i] / \\\n",
    "                                 sum(filter_bank[i] ** norm_exp)\n",
    "            \n",
    "        return filter_bank_out\n",
    "    \n",
    "    \n",
    "    # Definición de los bines en base a las frecuencias de cada filtro\n",
    "    if scale_type == 'linear':\n",
    "        # Definición de las \"n_filters\" frecuencias equiespaciadas entre\n",
    "        # 0 y freq_lim. Se le agregan 2 puntos (0 y el freq_lim) ya que se \n",
    "        # necesitan para definir los límites de los filtros.\n",
    "        freqs = np.arange(0, (n_filters + 1) + 1) * freq_lim / (n_filters + 1)\n",
    "    \n",
    "    \n",
    "    elif scale_type == 'mel':\n",
    "        # Definición del límite en frecuencias de mel (para no pasarse del\n",
    "        # freq_lim al devolverse)\n",
    "        mel_freq_lim = 2595 * np.log10(1 + freq_lim / 700)\n",
    "        \n",
    "        # Definición de las \"n_filters\" frecuencias espaciadas en escala mel \n",
    "        # entre 0 y freq_lim. Se le agregan 2 puntos (0 y el freq_lim) ya \n",
    "        # que se necesitan para definir los límites de los filtros.\n",
    "        mel_freqs = np.arange(0, (n_filters + 1) + 1) * mel_freq_lim / (n_filters + 1)\n",
    "        \n",
    "        # Transformando de intervalos equi espaciados usando la escala\n",
    "        # de mel. Es necesario hacer la transformación inversa ya que\n",
    "        # en este caso se dice que lo equi espaciado viene de mel\n",
    "        freqs = 700 * (10 ** (mel_freqs / 2595) - 1)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Opción de tipo de coeficiente cepstral no válido.')\n",
    "    \n",
    "    \n",
    "    # Transformando a bins\n",
    "    bins_to = _freq_to_bin(freqs)\n",
    "    \n",
    "    \n",
    "    # Obtención del banco de filtros\n",
    "    if filter_type == 'triangular':\n",
    "        filter_bank = _triangular_filter(bins_to)\n",
    "        \n",
    "    if filter_type == 'hanning':\n",
    "        filter_bank = _hanning_filter(bins_to)\n",
    "    \n",
    "    elif filter_type == 'squared':\n",
    "        filter_bank = _squared_filter(bins_to)\n",
    "    \n",
    "    # Normalizar por la energía de la señal\n",
    "    if norm_filters:\n",
    "        filter_bank = _norm_filterbank(filter_bank)\n",
    "    \n",
    "    \n",
    "    # Gráfico del banco de filtros\n",
    "    if plot_filterbank:\n",
    "        plt.figure()\n",
    "        \n",
    "        # Definición del vector de frecuencias\n",
    "        f_plot = np.arange(N) * samplerate / N\n",
    "        \n",
    "        for i in range(n_filters):\n",
    "            plt.plot(filter_bank[i])\n",
    "            # plt.plot(f_plot, filter_bank[i])\n",
    "\n",
    "        for i in bins_to:\n",
    "            # plt.axvline(i * samplerate / N, c='silver', linestyle=':')\n",
    "            plt.axvline(i, c='silver', linestyle=':')\n",
    "            \n",
    "        # plt.xlim([0, freq_lim])\n",
    "        plt.xlim([0, bins_to[-1]])\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    return filter_bank\n",
    "\n",
    "\n",
    "def get_cepstral_coefficients(signal_in, samplerate, spectrogram_params,\n",
    "                              freq_lim, n_filters, n_coefs, scale_type='mel', \n",
    "                              filter_type='triangular', inverse_func='dct', \n",
    "                              norm_filters=True, plot_filterbank=False, \n",
    "                              power=2):\n",
    "    '''Función que permite obtener los coeficientes cepstrales a partir de \n",
    "    un banco de filtros.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_in : ndarray\n",
    "        Señal de entrada.\n",
    "    samplerate : float\n",
    "        Tasa de muestreo de la señal de entrada.\n",
    "    freq_lim : float\n",
    "        Frecuencia límite para calcular los coeficientes cepstrales.\n",
    "    n_coefs : int\n",
    "        Cantidad de coeficientes a obtener.\n",
    "    scale_type : {'mel', 'linear'}, optional\n",
    "        Tipo de espaciado entre los bancos de filtros para el cálculo\n",
    "        de los coeficientes cepstrales. Por defecto es 'mel' (MFCC). \n",
    "    filter_type : {'triangular', 'hanning', 'squared'}, optional\n",
    "        Forma del filtro a utilizar para el cálculo de la energía en \n",
    "        cada banda. Por defecto es 'triangular'.\n",
    "    inverse_func : {'dct', 'idft'}, optional\n",
    "        Función a utilizar para obtener los coeficientes cepstrales.\n",
    "        Por defecto es 'dct'.\n",
    "    plot_filterbank : bool, optional\n",
    "        Booleano que indica si se grafica el banco de filtros. Por \n",
    "        defecto es False.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [1] http://practicalcryptography.com/miscellaneous/machine-learning/\n",
    "        guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "    [2] Xuedong Huang, Alex Acero, Hsiao-Wuen Hon - Spoken Language \n",
    "        Processing A Guide to Theory, Algorithm and System \n",
    "        Development-Prentice Hall PTR (2001)\n",
    "    '''    \n",
    "    # Definición de la cantidad de puntos a considerar\n",
    "    filter_bank = get_filterbanks(spectrogram_params['N'], samplerate, \n",
    "                                  freq_lim=freq_lim, n_filters=n_filters, \n",
    "                                  scale_type=scale_type, \n",
    "                                  filter_type=filter_type,\n",
    "                                  norm_filters=norm_filters, \n",
    "                                  plot_filterbank=plot_filterbank)\n",
    "    \n",
    "    # Obtener el espectrograma de la señal\n",
    "    t, f, S = get_spectrogram(signal_in, samplerate, N=spectrogram_params['N'], \n",
    "                              padding=spectrogram_params['padding'], \n",
    "                              repeat=spectrogram_params['repeat'], \n",
    "                              noverlap=spectrogram_params['noverlap'], \n",
    "                              window=spectrogram_params['window'], \n",
    "                              whole=True)\n",
    "    \n",
    "    # Definición del espectro de la señal\n",
    "    energy_spectrum = np.abs(S) ** power\n",
    "    \n",
    "    # Se aplica el banco de filtros sobre el espectro de la señal\n",
    "    energy_coefs = np.dot(filter_bank, energy_spectrum)\n",
    "    \n",
    "    # Aplicando el logaritmo\n",
    "    energy_coefs = np.log(energy_coefs + 1e-10)\n",
    "    \n",
    "    # Calculando los coeficientes cepstrales\n",
    "    if inverse_func == 'dct':\n",
    "        cepstral_coefs = fftpack.dct(energy_coefs, norm='ortho', axis=0)\n",
    "    elif inverse_func == 'idft':\n",
    "        cepstral_coefs = np.fft.ifft(energy_coefs, axis=-1).real\n",
    "    else:\n",
    "        raise Exception('Opción de tipo de función inversa no válida.')\n",
    "    \n",
    "    \n",
    "    return cepstral_coefs[:n_coefs]\n",
    "\n",
    "\n",
    "def get_bands_coefficients(signal_in, samplerate, spectrogram_params,\n",
    "                           freq_lim, n_coefs, scale_type='mel', \n",
    "                           filter_type='triangular', norm_filters=True, \n",
    "                           plot_filterbank=False, \n",
    "                           power=2):\n",
    "    '''Función que permite obtener la energía por bandas de frecuencia\n",
    "    a partir de un banco de filtros.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_in : ndarray\n",
    "        Señal de entrada.\n",
    "    samplerate : float\n",
    "        Tasa de muestreo de la señal de entrada.\n",
    "    freq_lim : float\n",
    "        Frecuencia límite para calcular los coeficientes cepstrales.\n",
    "    n_coefs : int\n",
    "        Cantidad de coeficientes a obtener.\n",
    "    scale_type : {'mel', 'linear'}, optional\n",
    "        Tipo de espaciado entre los bancos de filtros para el cálculo\n",
    "        de los coeficientes cepstrales. Por defecto es 'mel' (MFCC). \n",
    "    filter_type : {'triangular', 'hanning', 'squared'}, optional\n",
    "        Forma del filtro a utilizar para el cálculo de la energía en \n",
    "        cada banda. Por defecto es 'triangular'.\n",
    "    inverse_func : {'dct', 'idft'}, optional\n",
    "        Función a utilizar para obtener los coeficientes cepstrales.\n",
    "        Por defecto es 'dct'.\n",
    "    plot_filterbank : bool, optional\n",
    "        Booleano que indica si se grafica el banco de filtros. Por \n",
    "        defecto es False.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [1] http://practicalcryptography.com/miscellaneous/machine-learning/\n",
    "        guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "    [2] Xuedong Huang, Alex Acero, Hsiao-Wuen Hon - Spoken Language \n",
    "        Processing A Guide to Theory, Algorithm and System \n",
    "        Development-Prentice Hall PTR (2001)\n",
    "    '''    \n",
    "    # Definición de la cantidad de puntos a considerar\n",
    "    filter_bank = get_filterbanks(spectrogram_params['N'], samplerate, \n",
    "                                  freq_lim=freq_lim, \n",
    "                                  n_coefs=n_coefs, scale_type=scale_type, \n",
    "                                  filter_type=filter_type,\n",
    "                                  norm_filters=norm_filters, \n",
    "                                  plot_filterbank=plot_filterbank)\n",
    "    \n",
    "    # Obtener el espectrograma de la señal\n",
    "    t, f, S = get_spectrogram(signal_in, samplerate, N=spectrogram_params['N'], \n",
    "                              padding=spectrogram_params['padding'], \n",
    "                              repeat=spectrogram_params['repeat'], \n",
    "                              noverlap=spectrogram_params['noverlap'], \n",
    "                              window=spectrogram_params['window'], \n",
    "                              whole=True)\n",
    "    \n",
    "    # Definición del espectro de la señal\n",
    "    energy_spectrum = np.abs(S) ** power\n",
    "    \n",
    "    # Se aplica el banco de filtros sobre el espectro de la señal\n",
    "    energy_coefs = np.dot(filter_bank, energy_spectrum)\n",
    "    \n",
    "    return energy_coefs\n",
    "\n",
    "\n",
    "def get_energy_bands(signal_in, samplerate, spectrogram_params, \n",
    "                     fmin=0, fmax=1000, fband=20, power=2):\n",
    "    '''Función que permite definir un espectrograma en bandas de \n",
    "    energía.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_in : ndarray\n",
    "        Señal de entrada.\n",
    "    samplerate : float\n",
    "        Tasa de muestreo de la señal de entrada.\n",
    "    spectrogram_params : dict\n",
    "        Parámetros del espectrograma.\n",
    "    fmin : float, optional\n",
    "        Frecuencia mínima a considerar en el intervalo de interés.\n",
    "        Por defecto es 0.\n",
    "    fmax : float, optional\n",
    "        Frecuencia máxima a considerar en el intervalo de interés.\n",
    "        Este valor no puede mayor a samplerate / 2. Por defecto \n",
    "        es 1000.\n",
    "    fband : float, optional\n",
    "        Ancho de cada banda de frecuencia entre fmin y fmax. Por \n",
    "        defecto es 20.\n",
    "    power : float, optional\n",
    "        Exponente con el que se calcula la energía.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    energy_S : ndarray\n",
    "        Bandas de energía a través del tiempo (formato \n",
    "        espectrograma) con dimensión (#bandas x #bins de tiempo \n",
    "        del espectrograma).     \n",
    "    '''\n",
    "    # Obtener el espectrograma\n",
    "    t, f, S = get_spectrogram(signal_in, samplerate, \n",
    "                              N=spectrogram_params['N'], \n",
    "                              padding=spectrogram_params['padding'], \n",
    "                              repeat=spectrogram_params['repeat'], \n",
    "                              noverlap=spectrogram_params['noverlap'], \n",
    "                              window=spectrogram_params['window'], \n",
    "                              whole=False)\n",
    "    \n",
    "    # Definición de los intervalos\n",
    "    f_intervals = np.arange(fmin, fmax, fband)\n",
    "\n",
    "    # Definición de la lista que almacenará los datos\n",
    "    energy_band = np.zeros(len(f_intervals) - 1)\n",
    "    energy_S = np.zeros((len(energy_band), len(t)))\n",
    "\n",
    "    for i in range(len(f_intervals) - 1):\n",
    "        lower_lim = f_intervals[i]\n",
    "        upper_lim = f_intervals[i + 1]\n",
    "\n",
    "        # Definición de los índices de interés\n",
    "        indexes = np.where((lower_lim <= f) & (f <= upper_lim))[0]\n",
    "\n",
    "        # Definiendo el valor\n",
    "        energy_S[i] = np.sum(abs(S[indexes,:]) ** power, axis=0)\n",
    "    \n",
    "    return energy_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:04:49.286743Z",
     "start_time": "2021-04-19T05:04:49.268616Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _conditioning_signal(signal_in, samplerate, samplerate_to):\n",
    "    # Acondicionando en caso de que no tenga samplerate de 1000 Hz.\n",
    "    if samplerate < samplerate_to:\n",
    "        print(f'Upsampling de la señal de fs = {samplerate} Hz '\n",
    "              f'a fs = {samplerate_to} Hz.') \n",
    "        new_rate = samplerate_to           \n",
    "        audio_to = upsampling_signal(signal_in, samplerate, new_samplerate=new_rate)\n",
    "\n",
    "    elif samplerate > samplerate_to:\n",
    "        print(f'Downsampling de la señal de fs = {samplerate} Hz '\n",
    "              f'a fs = {samplerate_to} Hz.')\n",
    "        new_rate, audio_to = downsampling_signal(signal_in, samplerate, \n",
    "                                                 freq_pass=samplerate_to//2-100, \n",
    "                                                 freq_stop=samplerate_to//2)\n",
    "\n",
    "    else:\n",
    "        print(f'Samplerate adecuado a fs = {samplerate} Hz.')\n",
    "        audio_to = signal_in\n",
    "        new_rate = samplerate_to\n",
    "\n",
    "    # Mensaje para asegurar\n",
    "    print(f'Señal acondicionada a {new_rate} Hz para la separación de fuentes.')\n",
    "\n",
    "    # Asegurándose de que el largo de la señal sea par\n",
    "    if len(audio_to) % 2 != 0:\n",
    "        audio_to = np.concatenate((audio_to, [0]))\n",
    "\n",
    "    return audio_to, new_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:04:49.582121Z",
     "start_time": "2021-04-19T05:04:49.570141Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pybalu_clean(features, tol=1e-8, show=False):\n",
    "    n_features = features.shape[1]\n",
    "    ip = np.ones(n_features, dtype=int)\n",
    "\n",
    "    # cleaning correlated features\n",
    "    warnings.filterwarnings('ignore')\n",
    "    C = np.abs(np.corrcoef(features, rowvar=False))\n",
    "    idxs = np.vstack(np.where(C > .99))\n",
    "    \n",
    "    # remove pairs of same feature ( feature i will have a correlation of 1 whit itself )\n",
    "    idxs = idxs[:, idxs[0,:] != idxs[1,:]]\n",
    "    \n",
    "    # remove correlated features\n",
    "    if idxs.size > 0:\n",
    "        ip[np.max(idxs, 0)] = 0\n",
    "    \n",
    "    # remove constant features\n",
    "    s = features.std(axis=0, ddof=1)\n",
    "    ip[s < tol] = 0\n",
    "    p = np.where(ip.astype(bool))[0]\n",
    "\n",
    "    if show:\n",
    "        print(f'Clean: number of features reduced from {n_features} to {p.size}.')\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parámetros de los descriptores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:05:03.118330Z",
     "start_time": "2021-04-19T05:05:03.103344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parámetro base de datos\n",
    "preprocess = True\n",
    "\n",
    "# Parámetros de los espectrogramas generales\n",
    "N = 1024\n",
    "noverlap = int(0.9 * N)\n",
    "spec_params = {'N': N, 'noverlap': noverlap, 'window': 'hann', \n",
    "               'padding': 0, 'repeat': 0}\n",
    "\n",
    "# Parámetros MFCC\n",
    "mfcc_params = {'n_mfcc': 50, 'n_filters': 50, 'spec_params': spec_params,\n",
    "               'freq_lim': 2000, 'norm_filters': True, 'power': 2}\n",
    "lfcc_params = {'n_mfcc': 50, 'n_filters': 50, 'spec_params': spec_params,\n",
    "               'freq_lim': 2000, 'norm_filters': True, 'power': 2}\n",
    "energy_params = {'spec_params': spec_params, 'fmin': 0, 'fmax': 1000, \n",
    "                 'fband': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:05:27.976774Z",
     "start_time": "2021-04-19T05:05:27.956262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dirección de la base de datos\n",
    "db_original = 'C:/Users/Chris/Desktop/Scripts_Magister/Respiratory_Sound_Database/audio_and_txt_files'\n",
    "db_folder = 'preprocessed_signals_OLD'\n",
    "\n",
    "# Nombres de los archivos\n",
    "filenames = [i[:-4] for i in os.listdir(db_folder) if i.endswith('.wav') and not 'Tc' in i]\n",
    "\n",
    "\n",
    "# Definición de los cuadros clínicos por cada paciente\n",
    "db_original_root = f'{\"/\".join(db_original.split(\"/\")[:-1])}'\n",
    "\n",
    "\n",
    "with open(f'{db_original_root}/patient_diagnosis.csv', 'r', encoding='utf8') as file:\n",
    "    # Definición del diagnóstico para cada paciente\n",
    "    patient_diagnosis = dict()\n",
    "    \n",
    "    for line in file:\n",
    "        # Obteniendo la información\n",
    "        patient, diagnostic = line.strip().split(',')\n",
    "        \n",
    "        # Agregando al diccionario\n",
    "        patient_diagnosis[patient] = diagnostic\n",
    "\n",
    "    \n",
    "# Definición de la codificación de cuadros clínicos\n",
    "clinical_codification = {'Asthma': 1, 'Bronchiectasis': 2, 'Bronchiolitis': 3,\n",
    "                         'Healthy': 4, 'LRTI': 5, 'Pneumonia': 6, 'URTI': 7,\n",
    "                         'COPD': 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:48:08.821983Z",
     "start_time": "2021-04-19T05:47:59.133642Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1: 101_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 2: 101_1b1_Pr_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 3: 102_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 4: 103_2b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 5: 106_2b1_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 6: 106_2b1_Pr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 7: 107_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 8: 107_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 9: 107_2b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 10: 107_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 11: 107_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 12: 107_2b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 13: 107_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 14: 107_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 15: 107_2b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 16: 107_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 17: 107_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 18: 107_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 19: 107_2b5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 20: 107_2b5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 21: 107_2b5_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 22: 107_2b5_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 23: 107_2b5_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 24: 107_2b5_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 25: 107_3p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 26: 107_3p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 27: 107_3p2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 28: 107_3p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 29: 107_3p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 30: 107_3p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 31: 108_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 32: 114_1b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 33: 114_1b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 34: 114_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 35: 114_1b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 36: 114_1b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 37: 115_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 38: 116_1b2_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 39: 119_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 40: 122_2b1_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 41: 122_2b1_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 42: 122_2b2_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 43: 122_2b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 44: 122_2b3_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 45: 122_2b3_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 46: 123_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 47: 126_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 48: 127_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80062,)\n",
      "Iteración 49: 129_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 50: 130_1p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 51: 130_1p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 52: 130_1p2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 53: 130_1p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 54: 130_1p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 55: 130_1p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 56: 130_1p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 57: 130_1p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 58: 130_1p3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 59: 130_1p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 60: 130_1p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 61: 130_1p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 62: 130_1p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 63: 130_1p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 64: 130_1p4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 65: 130_1p4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 66: 130_1p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 67: 130_1p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 68: 130_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 69: 130_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 70: 130_2b2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 71: 130_2b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 72: 130_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 73: 130_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 74: 130_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 75: 130_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 76: 130_2b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 77: 130_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 78: 130_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 79: 130_2b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 80: 130_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 81: 130_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 82: 130_2b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 83: 130_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 84: 130_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 85: 130_2p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 86: 130_2p5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 87: 130_2p5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 88: 130_2p5_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 89: 130_2p5_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 90: 130_2p5_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 91: 130_3b3_Ll_mc_AKGC417L\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Healthy or Pneumonia\n",
      "Iteración 92: 130_3b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 93: 130_3b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 94: 130_3b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 95: 130_3b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 96: 130_3b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 97: 130_3p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 98: 130_3p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 99: 130_3p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 100: 130_3p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 101: 130_3p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 102: 130_3p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 103: 130_3p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 104: 130_3p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 105: 130_3p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 106: 130_3p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 107: 131_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 108: 132_2b1_Lr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 109: 132_2b2_Lr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 110: 133_2p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 111: 133_2p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 112: 133_2p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 113: 133_2p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 114: 133_2p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 115: 133_2p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 116: 133_2p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 117: 133_2p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 118: 133_2p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 119: 133_2p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 120: 133_2p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 121: 133_3p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 122: 133_3p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 123: 133_3p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 124: 133_3p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 125: 134_2b1_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 126: 134_2b1_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 127: 134_2b2_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 128: 134_2b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 129: 134_2b3_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 130: 135_2b1_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 131: 135_2b1_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 132: 135_2b1_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 133: 135_2b2_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 134: 135_2b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 135: 135_2b2_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 136: 135_2b3_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 137: 135_2b3_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 138: 135_2b3_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 139: 135_2b3_Pr_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 140: 136_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 141: 137_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 142: 137_1b1_Ll_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 143: 138_1p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 144: 138_1p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 145: 138_1p2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 146: 138_1p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 147: 138_1p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 148: 138_1p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 149: 138_1p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 150: 138_1p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 151: 138_1p3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 152: 138_1p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 153: 138_1p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 154: 138_1p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 155: 138_1p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 156: 138_1p4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 157: 138_1p4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 158: 138_1p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 159: 138_1p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 160: 138_2p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 161: 138_2p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 162: 138_2p2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 163: 138_2p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 164: 138_2p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 165: 138_2p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 166: 140_2b2_Ll_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 167: 140_2b3_Ll_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 168: 141_1b1_Pr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 169: 141_1b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 170: 141_1b2_Lr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 171: 141_1b2_Pr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 172: 141_1b3_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 173: 141_1b3_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 174: 141_1b3_Pr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 175: 142_1b1_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 176: 143_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 177: 144_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80102,)\n",
      "Iteración 178: 145_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 179: 145_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 180: 145_2b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 181: 145_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 182: 145_3b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 183: 145_3b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 184: 145_3b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 185: 146_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 186: 146_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 187: 146_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 188: 146_2b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 189: 146_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 190: 146_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 191: 146_8p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 192: 146_8p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 193: 146_8p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 194: 146_8p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 195: 146_8p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 196: 147_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 197: 147_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 198: 147_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 199: 147_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 200: 147_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 201: 147_2b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 202: 147_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 203: 147_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 204: 147_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 205: 147_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 206: 147_2b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 207: 147_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 208: 147_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 209: 148_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 210: 149_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 211: 149_1b1_Lr_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 212: 149_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 213: 150_1b2_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 214: 151_2p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 215: 151_2p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 216: 151_2p2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 217: 151_2p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 218: 151_2p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 219: 151_2p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 220: 151_2p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 221: 151_2p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 222: 151_2p3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 223: 151_2p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 224: 151_2p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 225: 151_2p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 226: 151_2p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 227: 151_2p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 228: 151_2p4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 229: 151_2p4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 230: 151_2p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 231: 151_2p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 232: 151_3p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 233: 151_3p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 234: 151_3p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 235: 151_3p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 236: 151_3p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 237: 151_3p3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 238: 152_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 239: 153_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 240: 154_1b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 241: 154_1b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 242: 154_1b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 243: 154_1b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 244: 154_1b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 245: 154_1b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 246: 154_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 247: 154_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 248: 154_2b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 249: 154_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 250: 154_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 251: 154_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 252: 154_3b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 253: 154_3b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 254: 154_3b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 255: 154_4b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 256: 154_4b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 257: 154_4b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 258: 154_4b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 259: 154_4b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 260: 154_4b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 261: 155_2b1_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 262: 156_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 263: 156_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 264: 156_2b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 265: 156_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 266: 156_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 267: 156_2b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 268: 156_5b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 269: 156_5b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 270: 156_5b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 271: 156_5b3_Lr_mc_AKGC417L\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Healthy or Pneumonia\n",
      "Iteración 272: 156_5b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 273: 156_5b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 274: 156_8b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 275: 156_8b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 276: 156_8b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 277: 156_8b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 278: 156_8b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 279: 158_1b3_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 280: 158_1p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 281: 158_1p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 282: 158_1p2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 283: 158_1p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 284: 158_1p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 285: 158_1p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 286: 158_1p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 287: 158_1p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 288: 158_1p3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 289: 158_1p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 290: 158_1p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 291: 158_1p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 292: 158_1p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 293: 158_1p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 294: 158_1p4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 295: 158_1p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 296: 158_1p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 297: 158_2p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 298: 158_2p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 299: 159_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 300: 159_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 301: 159_1b1_Ll_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 302: 159_1b1_Pr_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 303: 160_1b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 304: 160_1b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 305: 160_1b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 306: 160_1b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 307: 160_1b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 308: 160_1b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 309: 160_1b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 310: 160_1b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 311: 160_1b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 312: 160_1b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 313: 160_1b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 314: 160_1b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 315: 160_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 316: 160_1b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 317: 160_1b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 318: 160_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 319: 160_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 320: 160_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 321: 160_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 322: 161_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 323: 161_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 324: 162_1b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 325: 162_1b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 326: 162_1b2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 327: 162_1b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 328: 162_1b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 329: 162_1b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 330: 162_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 331: 162_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 332: 162_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 333: 162_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 334: 162_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 335: 162_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 336: 162_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 337: 162_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 338: 162_2b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 339: 162_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 340: 162_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 341: 162_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 342: 162_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 343: 162_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 344: 163_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 345: 163_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 346: 163_2b2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 347: 163_2b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 348: 163_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 349: 163_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 350: 163_8b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 351: 163_8b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 352: 163_8b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 353: 163_8b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 354: 163_8b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 355: 163_8b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 356: 164_1b1_Ll_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 357: 165_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 358: 165_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 359: 165_1b1_Pr_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 360: 167_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 361: 167_1b1_Pr_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 362: 168_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 363: 169_1b1_Lr_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 364: 169_1b2_Ll_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 365: 170_1b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 366: 170_1b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 367: 170_1b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 368: 170_1b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 369: 170_1b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 370: 170_1b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 371: 170_1b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 372: 170_1b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 373: 170_1b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 374: 170_1b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 375: 170_1b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 376: 170_1b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 377: 170_1b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 378: 170_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 379: 170_1b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 380: 170_1b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 381: 170_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 382: 170_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 383: 170_2b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 384: 170_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 385: 170_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 386: 171_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 387: 172_1b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 388: 172_1b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 389: 172_1b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 390: 172_1b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 391: 172_1b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 392: 172_1b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 393: 172_1b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 394: 172_1b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 395: 172_1b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 396: 172_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 397: 172_1b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 398: 172_1b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 399: 172_1b5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 400: 172_1b5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 401: 172_1b5_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 402: 172_1b5_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 403: 172_1b5_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 404: 172_1b5_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 405: 172_2b5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 406: 172_2b5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 407: 172_2b5_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 408: 172_2b5_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 409: 172_2b5_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 410: 173_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 411: 174_1p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 412: 174_1p2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 413: 174_1p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 414: 174_1p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 415: 174_1p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 416: 174_1p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 417: 174_1p3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 418: 174_1p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 419: 174_1p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 420: 174_1p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 421: 174_1p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 422: 174_1p4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 423: 174_1p4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 424: 174_1p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 425: 174_1p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 426: 174_2p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 427: 174_2p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 428: 174_2p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 429: 174_2p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 430: 176_1b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 431: 176_1b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 432: 176_1b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 433: 176_1b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 434: 176_1b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 435: 176_1b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 436: 176_1b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 437: 176_1b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 438: 176_1b4_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 439: 176_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 440: 176_1b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 441: 176_1b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 442: 176_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 443: 176_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 444: 176_2b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 445: 176_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 446: 176_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 447: 176_2b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 448: 177_1b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 449: 177_1b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 450: 177_1b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 451: 177_1b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 452: 177_1b2_Pr_mc_AKGC417L\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Healthy or Pneumonia\n",
      "Iteración 453: 177_1b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 454: 177_1b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 455: 177_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 456: 177_1b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 457: 177_1b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 458: 177_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 459: 177_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 460: 177_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 461: 177_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 462: 178_1b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 463: 178_1b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 464: 178_1b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 465: 178_1b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 466: 178_1b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 467: 178_1b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 468: 178_1b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 469: 178_1b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 470: 178_1b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 471: 178_1b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 472: 178_1b6_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 473: 178_1b6_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 474: 178_1b6_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 475: 178_1b6_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 476: 178_1b6_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 477: 178_1b6_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 478: 178_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 479: 178_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 480: 178_2b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 481: 178_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 482: 179_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 483: 180_1b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 484: 180_1b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 485: 180_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 486: 180_1b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 487: 180_1b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 488: 181_1b1_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 489: 181_1b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 490: 183_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 491: 184_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 492: 186_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 493: 186_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 494: 186_2b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 495: 186_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 496: 186_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 497: 186_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 498: 186_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 499: 186_2b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 500: 186_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 501: 186_2b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 502: 186_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 503: 186_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 504: 186_2b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 505: 186_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 506: 186_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 507: 186_3b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 508: 186_3b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 509: 186_3b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 510: 186_3b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 511: 186_3b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 512: 187_1b1_Ll_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 513: 188_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 514: 188_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 515: 188_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 516: 189_1b2_Lr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 517: 191_2b1_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 518: 191_2b1_Pr_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 519: 192_2b1_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 520: 192_2b1_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 521: 192_2b2_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 522: 192_2b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 523: 192_2b3_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 524: 192_2b3_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 525: 193_1b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 526: 193_1b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 527: 193_1b2_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 528: 193_1b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 529: 193_1b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 530: 193_1b4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 531: 193_7b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 532: 193_7b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 533: 193_7b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 534: 193_7b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 535: 193_7b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 536: 193_7b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 537: 194_1b1_Lr_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 538: 194_1b1_Pr_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 539: 196_1b1_Pr_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 540: 197_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 541: 198_1b5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 542: 198_1b5_Ar_mc_AKGC417L\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Healthy or Pneumonia\n",
      "Iteración 543: 198_1b5_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 544: 198_1b5_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 545: 198_1b5_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 546: 198_1b5_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 547: 198_6p1_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 548: 198_6p1_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 549: 198_6p1_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 550: 198_6p1_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 551: 198_6p1_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 552: 198_6p1_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 553: 199_2b1_Ll_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 554: 199_2b3_Ll_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 555: 200_2p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 556: 200_2p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 557: 200_2p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 558: 200_2p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 559: 200_2p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 560: 200_2p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 561: 200_2p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 562: 200_2p3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 563: 200_2p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 564: 200_2p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 565: 200_2p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 566: 200_2p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 567: 200_2p4_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 568: 200_2p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 569: 200_2p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 570: 200_3p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 571: 200_3p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 572: 200_3p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 573: 200_3p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 574: 201_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 575: 201_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 576: 201_1b2_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 577: 201_1b2_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 578: 201_1b3_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 579: 201_1b3_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 580: 202_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (79380,)\n",
      "Iteración 581: 203_1p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 582: 203_1p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 583: 203_1p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 584: 203_1p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 585: 203_1p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 586: 203_1p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 587: 203_1p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 588: 203_1p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 589: 203_1p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 590: 203_1p4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 591: 203_1p4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 592: 203_1p4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 593: 203_1p4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 594: 203_2p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 595: 203_2p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 596: 203_2p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 597: 203_2p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 598: 204_2b5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 599: 204_2b5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 600: 204_2b5_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 601: 204_7p5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 602: 204_7p5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 603: 204_7p5_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 604: 204_7p5_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 605: 204_7p5_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 606: 205_1b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 607: 205_1b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 608: 205_1b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 609: 205_1b3_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 610: 205_1b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 611: 205_1b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 612: 205_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 613: 205_2b3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 614: 205_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 615: 205_2b3_Ll_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 616: 205_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 617: 205_3b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 618: 205_3b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 619: 205_3b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 620: 205_3b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 621: 205_4b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 622: 205_4b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 623: 205_4b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 624: 205_4b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 625: 205_4b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 626: 206_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 627: 206_1b1_Lr_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 628: 206_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 629: 207_2b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 630: 207_2b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 631: 207_2b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 632: 207_2b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 633: 207_2b3_Al_mc_AKGC417L\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 634: 207_2b3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 635: 207_2b3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 636: 207_2b3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 637: 207_2b4_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 638: 207_2b4_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 639: 207_2b4_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 640: 207_2b4_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 641: 207_3b2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 642: 207_3b2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 643: 207_3b2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 644: 207_3b2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 645: 207_3b2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 646: 208_1b1_Ll_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (79982,)\n",
      "Iteración 647: 210_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 648: 210_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 649: 211_1p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 650: 211_1p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 651: 211_1p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 652: 211_1p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 653: 211_1p5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 654: 213_1p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 655: 213_1p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 656: 213_1p2_Lr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 657: 213_1p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 658: 213_1p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 659: 213_1p3_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 660: 213_1p3_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 661: 213_1p3_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 662: 213_1p3_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 663: 213_1p5_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 664: 213_1p5_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 665: 213_1p5_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 666: 213_1p5_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 667: 213_2p2_Al_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 668: 213_2p2_Ar_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 669: 213_2p2_Pl_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 670: 213_2p2_Pr_mc_AKGC417L\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 671: 214_1b1_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (79540,)\n",
      "Iteración 672: 215_1b2_Ar_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 673: 216_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 674: 216_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 675: 219_2b1_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 676: 219_2b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 677: 220_1b2_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 678: 221_2b1_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 679: 221_2b1_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 680: 221_2b1_Lr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 681: 221_2b1_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 682: 221_2b2_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 683: 221_2b2_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 684: 221_2b2_Lr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 685: 221_2b2_Pl_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 686: 221_2b3_Al_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 687: 221_2b3_Ar_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 688: 221_2b3_Lr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 689: 221_2b3_Pr_mc_LittC2SE\n",
      "--------------------------\n",
      "Not Healthy or Pneumonia\n",
      "Iteración 690: 224_1b2_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 691: 225_1b1_Pl_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 692: 226_1b1_Al_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 693: 226_1b1_Ll_sc_Meditron\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n",
      "Iteración 694: 226_1b1_Pl_sc_LittC2SE\n",
      "--------------------------\n",
      "Samplerate = 4000, largo = (80182,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Definición de los arrays donde se acumulará las características\n",
    "X_data_mean = list()\n",
    "X_data_max = list()\n",
    "\n",
    "# Definición de los arrays donde se acumularán las etiquetas\n",
    "Y_diagnosis = list()\n",
    "\n",
    "\n",
    "# Diccionario que indica los segmentos que corresponden a cada paciente\n",
    "patient_register = defaultdict(list)\n",
    "\n",
    "# Contador de los segmentos\n",
    "seg_i = 0\n",
    "\n",
    "# Nombre del archivo .wav a utilizar\n",
    "for num, name in enumerate(filenames):\n",
    "    print(f'Iteración {num + 1}: {name}')\n",
    "    print(f'--------------------------')\n",
    "    \n",
    "    # Definición del paciente de interés\n",
    "    patient = name.split('_')[0]\n",
    "    \n",
    "#     if patient_diagnosis[patient] == 'COPD':\n",
    "#         print('COPD: Pasar...')\n",
    "#         continue\n",
    "    \n",
    "    if not patient_diagnosis[patient] in ['Healthy', 'Pneumonia']:\n",
    "        print('Not Healthy or Pneumonia')\n",
    "        continue\n",
    "    \n",
    "    if preprocess:\n",
    "        filename = f'{db_folder}/{name}'\n",
    "    else:\n",
    "        filename = f'{db_original}/{name}'\n",
    "\n",
    "    # Cargando el archivo\n",
    "    try:\n",
    "        samplerate, resp_signal = wavfile.read(f'{filename}.wav')\n",
    "    except:\n",
    "        resp_signal, samplerate = sf.read(f'{filename}.wav')\n",
    "    \n",
    "    print(f'Samplerate = {samplerate}, largo = {resp_signal.shape}')\n",
    "    \n",
    "    # Normalizando\n",
    "    resp_signal = resp_signal / max(abs(resp_signal))\n",
    "        \n",
    "    # Registrando\n",
    "    patient_register[patient].append(seg_i)\n",
    "    seg_i += 1\n",
    "    \n",
    "    ### Calculando las características a partir del segmento ###\n",
    "\n",
    "    # Cálculo del MFCC\n",
    "    mfcc_features = \\\n",
    "        get_cepstral_coefficients(resp_signal, samplerate, \n",
    "                                  spectrogram_params=mfcc_params['spec_params'],\n",
    "                                  freq_lim=mfcc_params['freq_lim'], \n",
    "                                  n_filters=mfcc_params['n_filters'], \n",
    "                                  n_coefs=mfcc_params['n_mfcc'], \n",
    "                                  scale_type='mel', \n",
    "                                  filter_type='triangular', inverse_func='dct', \n",
    "                                  norm_filters=mfcc_params['norm_filters'], \n",
    "                                  plot_filterbank=False, \n",
    "                                  power=mfcc_params['power'])\n",
    "\n",
    "    # Cálculo del LFCC\n",
    "    lfcc_features = \\\n",
    "        get_cepstral_coefficients(resp_signal, samplerate, \n",
    "                                  spectrogram_params=lfcc_params['spec_params'],\n",
    "                                  freq_lim=lfcc_params['freq_lim'], \n",
    "                                  n_filters=lfcc_params['n_filters'], \n",
    "                                  n_coefs=lfcc_params['n_mfcc'], \n",
    "                                  scale_type='linear', \n",
    "                                  filter_type='triangular', inverse_func='dct', \n",
    "                                  norm_filters=lfcc_params['norm_filters'], \n",
    "                                  plot_filterbank=False, \n",
    "                                  power=lfcc_params['power'])\n",
    "\n",
    "    # Cálculo de la energía por bandas\n",
    "    energy_S = \\\n",
    "        get_energy_bands(resp_signal, samplerate,\n",
    "                         spectrogram_params=energy_params['spec_params'],\n",
    "                         fmin=energy_params['fmin'], \n",
    "                         fmax=energy_params['fmax'], \n",
    "                         fband=energy_params['fband'])\n",
    "\n",
    "    # Colapsando la información\n",
    "    to_append_mean = np.concatenate((mfcc_features.mean(axis=1),\n",
    "                                     lfcc_features.mean(axis=1),\n",
    "                                     energy_S.mean(axis=1)), axis=0)\n",
    "    to_append_max = np.concatenate((mfcc_features.max(axis=1),\n",
    "                                    lfcc_features.max(axis=1),\n",
    "                                    energy_S.max(axis=1)), axis=0)\n",
    "\n",
    "    # Agregando la información a cada arreglo\n",
    "    X_data_mean.append(to_append_mean)\n",
    "    X_data_max.append(to_append_max)\n",
    "\n",
    "    Y_diagnosis.append(clinical_codification[patient_diagnosis[patient]])\n",
    "\n",
    "\n",
    "# Transformando listas a arrays\n",
    "X_data_mean = np.array(X_data_mean)\n",
    "X_data_max = np.array(X_data_max)\n",
    "\n",
    "Y_diagnosis = np.array(Y_diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:48:11.498284Z",
     "start_time": "2021-04-19T05:48:11.472327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo 1: 10\n",
      "Grupo 2: 0\n",
      "Grupo 3: 14\n",
      "Grupo 4: 8\n",
      "Grupo 5: 4\n",
      "Grupo 6: 3\n",
      "Grupo 7: 2\n",
      "Grupo 8: 5\n",
      "Grupo 9: 0\n",
      "Grupo 10: 4\n",
      "Definidos 50 de 50\n"
     ]
    }
   ],
   "source": [
    "# Definición de los grupos de pacientes\n",
    "patient_groups = {1: ['101', '102', '103', '106', '107', '108', '114', '115', '116', \n",
    "                      '119', '122', '123', '126', '127', '129', '162'],\n",
    "                  2: ['130', '131', '132', '165', '197'],\n",
    "                  3: ['133', '134', '135', '136', '137', '138', '140', '141', '142', \n",
    "                      '143', '169'],\n",
    "                  4: ['144', '145', '146', '147', '148', '149', '150', '151', '152',\n",
    "                      '153', '155', '159', '179'],\n",
    "                  5: ['154', '156', '160', '161', '167', '225', '226'],\n",
    "                  6: ['158', '163', '164', '168', '170', '171', '183', '216', '221',\n",
    "                      '224'],\n",
    "                  7: ['172', '173', '174', '176', '177', '180', '189', '191', '196'],\n",
    "                  8: ['178', '181', '184', '186', '187', '188', '192', '194', '202', \n",
    "                      '204'],\n",
    "                  9: ['193', '198', '199', '200', '201', '203'],\n",
    "                  10: ['205', '206', '207', '208', '210', '211', '213', '214', '215',\n",
    "                       '219', '220']}\n",
    "\n",
    "# Definición de variables de control\n",
    "segment_count = 0\n",
    "patients_reviewed = list()\n",
    "\n",
    "for i in patient_groups.keys():\n",
    "    segments_by_group = 0\n",
    "    \n",
    "    for j in patient_groups[i]:\n",
    "        # Sumando al contador de grupo\n",
    "        segments_by_group += len(patient_register[j])\n",
    "        \n",
    "    # Agregando a la lista de pacientes totales\n",
    "    patients_reviewed.extend(patient_groups[i])\n",
    "    \n",
    "    # Sumando al contador total \n",
    "    segment_count += segments_by_group\n",
    "    \n",
    "    # Print de sanidad\n",
    "    print(f'Grupo {i}: {segments_by_group}')\n",
    "\n",
    "print(f'Definidos {segment_count} de {Y_diagnosis.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T06:46:54.128548Z",
     "start_time": "2021-04-19T06:46:50.602845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 112.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:03<00:00, 17.1 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [7 5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train = X_data_mean[:35]\n",
    "X_test = X_data_mean[35:]\n",
    "Y_train = Y_diagnosis[:35]\n",
    "Y_test = Y_diagnosis[35:]\n",
    "\n",
    "# class_params = {'classifier': 'knn', 'k_neigh': 5}\n",
    "class_params = {'classifier': 'svm', 'kernel': 'poly'}\n",
    "\n",
    "classifier, X_test, params_out, Y_pred = \\\n",
    "    ML_classification_system(X_train, Y_train, X_test, Y_test, \n",
    "                             clean_params=clean_params, \n",
    "                             sel_params=sel_params, \n",
    "                             class_params=class_params)\n",
    "\n",
    "cmat = confusion_matrix(Y_pred, Y_test)\n",
    "print(cmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diseño del sistema de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:48:19.932436Z",
     "start_time": "2021-04-19T05:48:19.863520Z"
    },
    "code_folding": [
     0,
     117,
     260,
     278,
     336,
     353,
     371,
     480,
     543
    ]
   },
   "outputs": [],
   "source": [
    "def ML_classification_system(X_train, Y_train, X_test, Y_test, \n",
    "                             clean_params=None, sel_params=None, \n",
    "                             class_params=None):\n",
    "    '''Diseño del sistema de clasificación basado en Machine \n",
    "    Learning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : ndarray\n",
    "        Datos de entrenamiento.\n",
    "    Y_train : ndarray\n",
    "        Etiquetas de los datos de entrenamiento.\n",
    "    X_test : ndarray\n",
    "        Datos de testeo.\n",
    "    Y_test : ndarray\n",
    "        Etiquetas de los datos de testeo.\n",
    "    clean_params: dict or None, optional\n",
    "        Parámetros del proceso de limpieza de características. \n",
    "        Si es None se utilizan características por defecto: \n",
    "        'tol': 13-5, 'show': True. Por defecto es None.\n",
    "    sel_params: dict or None, optional\n",
    "        Parámetros del proceso de selección de características. \n",
    "        Si es None se utilizan características por defecto: \n",
    "        'n_features': 10, 'show': True. Por defecto es None.\n",
    "    class_params: dict or None, optional\n",
    "        Parámetros del proceso de clasificación. Si es None se \n",
    "        utilizan características por defecto: \n",
    "        'classifier': 'knn', 'k_neigh': 10. Por defecto es None. \n",
    "        En caso de usar 'svm', es posible modificar el 'kernel'.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    classifier : class\n",
    "        Clasificador entrenado.\n",
    "    X_test : ndarray\n",
    "        Matriz de testeo modificada (en caso de que X_test no \n",
    "        sea None).\n",
    "    params_out : dict\n",
    "        Parámetros obtenidos a partir del entrenamiento del\n",
    "        sistema sobre los datos. Se entrega información de las\n",
    "        características del clean ('s_clean'), normalización\n",
    "        ('a_norm' y 'b_norm'), y de la selección de \n",
    "        características ('s_sfs').\n",
    "    Y_pred : ndarray or None\n",
    "        Predicción realizada por el sistema (en caso de que\n",
    "        Y_test no sea None). Si no se entrega Y_test, la salida\n",
    "        será None.\n",
    "    '''\n",
    "    # Parámetros por defecto\n",
    "    if clean_params is None:\n",
    "        clean_params = {'tol': 1e-5, 'show': True}\n",
    "    \n",
    "    if sel_params is None:\n",
    "        sel_params = {'n_features': 10, 'show': True}\n",
    "    \n",
    "    if class_params is None:\n",
    "        class_params = {'classifier': 'knn', 'k_neigh': 10}\n",
    "        \n",
    "    Y_pred = None\n",
    "    \n",
    "    \n",
    "    #### Pipeline de la etapa de clasificación ####\n",
    "    \n",
    "    ## 1) Limpieza de las características\n",
    "    s_clean = pybalu_clean(X_train, tol=clean_params['tol'], \n",
    "                           show=clean_params['show'])\n",
    "    \n",
    "    # Aplicando la limpieza\n",
    "    X_train = X_train[:, s_clean]\n",
    "    \n",
    "    \n",
    "    ## 2) Normalización de los datos\n",
    "    X_train, a_norm, b_norm = normalize(X_train)\n",
    "    \n",
    "    \n",
    "    ## 3) Selección de características\n",
    "    s_sfs = sfs(X_train, Y_train, show=sel_params['show'],\n",
    "                n_features=sel_params['n_features'])\n",
    "    \n",
    "    # Aplicando la selección\n",
    "    X_train = X_train[:, s_sfs]\n",
    "    \n",
    "    \n",
    "    ## 4) Proceso de clasificación   \n",
    "    if class_params['classifier'] == 'knn':\n",
    "        classifier = KNeighborsClassifier(n_neighbors=\\\n",
    "                                          class_params['k_neigh'])\n",
    "        \n",
    "    elif class_params['classifier'] == 'svm':\n",
    "        classifier = svm.SVC(kernel=class_params['kernel'])\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Opción de clasificador no definida '\n",
    "                        'correctamente.')\n",
    "    \n",
    "    # Ajustando el clasificador\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    \n",
    "    # Aplicando todo el proceso a los datos de testeo\n",
    "    if X_test is not None:\n",
    "        X_test = X_test[:, s_clean]         # 1) Clean\n",
    "        X_test = a_norm * X_test + b_norm   # 2) Normalización\n",
    "        X_test = X_test[:, s_sfs]           # 3) Selección\n",
    "        \n",
    "        # Aplicando el clasificador\n",
    "        if Y_test is not None:\n",
    "            Y_pred = classifier.predict(X_test)\n",
    "\n",
    "    \n",
    "    # Definición del diccionario de parámetros\n",
    "    params_out = {'a_norm': a_norm, 'b_norm': b_norm, 's_clean': s_clean,\n",
    "                  's_sfs': s_sfs}\n",
    "        \n",
    "    return classifier, X_test, params_out, Y_pred\n",
    "\n",
    "\n",
    "def NN_MLP_classification_system(X_train, Y_train, X_test, Y_test, \n",
    "                                 clean_params=None, sel_params=None, \n",
    "                                 mlp_params=None):\n",
    "    '''Diseño del sistema de clasificación basado en Redes Neuronales\n",
    "    Multicapas.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : ndarray\n",
    "        Datos de entrenamiento.\n",
    "    Y_train : ndarray\n",
    "        Etiquetas de los datos de entrenamiento.\n",
    "    X_test : ndarray\n",
    "        Datos de testeo.\n",
    "    Y_test : ndarray\n",
    "        Etiquetas de los datos de testeo.\n",
    "    clean_params: dict or None, optional\n",
    "        Parámetros del proceso de limpieza de características. \n",
    "        Si es None se utilizan características por defecto: \n",
    "        {'tol': 13-5, 'show': True}. Por defecto es None.\n",
    "    sel_params: dict or None, optional\n",
    "        Parámetros del proceso de selección de características. \n",
    "        Si es None se utilizan características por defecto: \n",
    "        {'n_features': 10, 'show': True}. Por defecto es None.\n",
    "    mlp_params : dict or None, optional\n",
    "        Parámetros del preoceso de clasificación con MLP. Si es\n",
    "        None se utilizan las características por defecto:\n",
    "        {'optimizer': 'Adam', 'loss': 'binary_crossentropy',\n",
    "         'batch_size': None, 'epochs': 100, 'verbose': 1, \n",
    "         'metrics': ['accuracy', tf.keras.metrics.Recall(), \n",
    "                      tf.keras.metrics.Precision()],\n",
    "         'out_layer': 'sigmoid', 'preprocessing': True}\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    classifier : class\n",
    "        Clasificador entrenado.\n",
    "    X_test : ndarray\n",
    "        Matriz de testeo modificada (en caso de que X_test no \n",
    "        sea None).\n",
    "    params_out : dict\n",
    "        Parámetros obtenidos a partir del entrenamiento del\n",
    "        sistema sobre los datos. Se entrega información de las\n",
    "        características del clean ('s_clean'), normalización\n",
    "        ('a_norm' y 'b_norm'), y de la selección de \n",
    "        características ('s_sfs').\n",
    "    Y_pred : ndarray or None\n",
    "        Predicción realizada por el sistema (en caso de que\n",
    "        Y_test no sea None). Si no se entrega Y_test, la salida\n",
    "        será None.\n",
    "    '''\n",
    "    # Parámetros por defecto\n",
    "    if clean_params is None:\n",
    "        clean_params = {'tol': 1e-5, 'show': True}\n",
    "    \n",
    "    if sel_params is None:\n",
    "        sel_params = {'n_features': 10, 'show': True}\n",
    "        \n",
    "    if mlp_params is None:\n",
    "        mlp_params = {'optimizer': 'Adam', 'loss': 'binary_crossentropy',\n",
    "                      'batch_size': None, 'epochs': 100, 'verbose': 1, \n",
    "                      'metrics': ['accuracy', tf.keras.metrics.Recall(), \n",
    "                                  tf.keras.metrics.Precision()],\n",
    "                      'out_layer': 'sigmoid', 'preprocessing': True}\n",
    "    \n",
    "    Y_pred = None\n",
    "    \n",
    "    \n",
    "    #### Pipeline de la etapa de clasificación ####\n",
    "    \n",
    "    # Rutina de preprocesamiento\n",
    "    if mlp_params['preprocessing']:\n",
    "        ## 1) Limpieza de las características\n",
    "        s_clean = pybalu_clean(X_train, tol=clean_params['tol'], \n",
    "                               show=clean_params['show'])\n",
    "\n",
    "        # Aplicando la limpieza\n",
    "        X_train = X_train[:, s_clean]\n",
    "\n",
    "\n",
    "        ## 2) Normalización de los datos\n",
    "        X_train, a_norm, b_norm = normalize(X_train)\n",
    "\n",
    "\n",
    "        ## 3) Selección de características\n",
    "        s_sfs = sfs(X_train, Y_train, show=sel_params['show'],\n",
    "                    n_features=sel_params['n_features'])\n",
    "\n",
    "        # Aplicando la selección\n",
    "        X_train = X_train[:, s_sfs]\n",
    "\n",
    "    \n",
    "    \n",
    "    ## 4) Proceso de clasificación\n",
    "    \n",
    "    # Definición del modelo\n",
    "    model = MLP_network(input_shape=(X_train.shape[1],),\n",
    "                        out_layer=mlp_params['out_layer'])\n",
    "    \n",
    "    # Compilando modelos\n",
    "    model.compile(optimizer=mlp_params['optimizer'], \n",
    "                  loss=mlp_params['loss'],\n",
    "                  metrics=mlp_params['metrics'])\n",
    "    \n",
    "    \n",
    "    # Definición de los vectores\n",
    "    if mlp_params['out_layer'] == 'softmax':\n",
    "        # One-Hot\n",
    "        Y_train_to = \\\n",
    "            np.array([Y_train, np.ones(len(Y_train)) - Y_train]).T\n",
    "    \n",
    "    elif mlp_params['out_layer'] == 'sigmoid':\n",
    "        # Normal\n",
    "        Y_train_to = Y_train\n",
    "    \n",
    "    \n",
    "    # Ajustando el Modelo\n",
    "    history = model.fit(x=X_train, y=Y_train_to, \n",
    "                        batch_size=mlp_params['batch_size'],\n",
    "                        epochs=mlp_params['epochs'],\n",
    "                        verbose=mlp_params['verbose'])\n",
    "    \n",
    "    \n",
    "    # Aplicando todo el proceso a los datos de testeo\n",
    "    if X_test is not None:\n",
    "        # Si se realizó el preprocesamiento, se actualiza\n",
    "        if preprocessing:\n",
    "            X_test = X_test[:, s_clean]         # 1) Clean\n",
    "            X_test = X_test * a_norm + b_norm   # 2) Normalización\n",
    "            X_test = X_test[:, s_sfs]           # 3) Selección\n",
    "        \n",
    "        # Aplicando el clasificador\n",
    "        if Y_test is not None:\n",
    "            Y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    # Definición del diccionario de parámetros\n",
    "    params_out = {'a_norm': a_norm, 'b_norm': b_norm, 's_clean': s_clean,\n",
    "                  's_sfs': s_sfs, 'history': history}\n",
    "        \n",
    "    return model, X_test, params_out, Y_pred\n",
    "\n",
    "\n",
    "def MLP_network(input_shape, out_layer='sigmoid'):\n",
    "    '''Función que define una red de perceptrones multicapas para \n",
    "    clasificar.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : list or ndarray\n",
    "        Dimensión de la información de entrada.\n",
    "    out_layer : {'sigmoid', 'softmax'}, optional\n",
    "        Función a usar en la capa de salida de la red. Por defecto\n",
    "        es 'sigmoid'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model: tensorflow.keras.Model\n",
    "        Modelo del sistema.\n",
    "    '''\n",
    "    \n",
    "    def _layer(input_layer, units, kernel_initializer, \n",
    "               bias_initializer, name):\n",
    "        '''Función auxiliar que modela las capas Dense + batchnorm +\n",
    "        Activation ReLU'''\n",
    "        # Aplicando la concatenación de capas\n",
    "        x_dense = tf.keras.layers.Dense(units=units, \n",
    "                                        bias_initializer=bias_initializer,\n",
    "                                        kernel_initializer=kernel_initializer,\n",
    "                                        name=f'Dense_{name}')(input_layer)\n",
    "        x_dense = \\\n",
    "            tf.keras.layers.BatchNormalization(name=f'BatchNorm_{name}')(x_dense)\n",
    "        x_dense = \\\n",
    "            tf.keras.layers.Activation('relu', name=f'Activation_{name}')(x_dense)\n",
    "\n",
    "        return x_dense\n",
    "    \n",
    "    \n",
    "    # Definición de la entrada\n",
    "    x_in = tf.keras.Input(shape=input_shape, dtype='float32')\n",
    "    \n",
    "    \n",
    "    # Definición de la red misma\n",
    "    x_layer = _layer(x_in, units=500, kernel_initializer='he_normal', \n",
    "                     bias_initializer='he_normal', name='Layer_1')\n",
    "    x_layer = _layer(x_layer, units=200, kernel_initializer='he_normal', \n",
    "                     bias_initializer='he_normal', name='Layer_2')\n",
    "    x_layer = _layer(x_layer, units=100, kernel_initializer='he_normal', \n",
    "                     bias_initializer='he_normal', name='Layer_3')\n",
    "    x_layer = _layer(x_layer, units=80, kernel_initializer='he_normal', \n",
    "                     bias_initializer='he_normal', name='Layer_4')\n",
    "    x_layer = _layer(x_layer, units=30, kernel_initializer='he_normal', \n",
    "                     bias_initializer='he_normal', name='Layer_5')\n",
    "    x_layer = _layer(x_layer, units=10, kernel_initializer='he_normal', \n",
    "                     bias_initializer='he_normal', name='Layer_6')\n",
    "    x_layer = _layer(x_layer, units=5, kernel_initializer='he_normal', \n",
    "                     bias_initializer='he_normal', name='Layer_7')\n",
    "    \n",
    "    # Definición de la salida\n",
    "    if out_layer == 'softmax':\n",
    "        x_out = tf.keras.layers.Dense(2, activation='softmax', \n",
    "                                      kernel_initializer='he_normal', \n",
    "                                      bias_initializer='he_normal',\n",
    "                                      name='softmax_out')(x_layer)\n",
    "    elif out_layer == 'sigmoid':\n",
    "        x_out = tf.keras.layers.Dense(1, activation='sigmoid', \n",
    "                                      kernel_initializer='he_normal', \n",
    "                                      bias_initializer='he_normal',\n",
    "                                      name='sigmoid_out')(x_layer)\n",
    "    else:\n",
    "        raise Exception(f'Opción de parámetro \"out_layer\"={out_layer} '\n",
    "                        f'no válido.')\n",
    "    \n",
    "    # Definir el modelo\n",
    "    model = tf.keras.Model(inputs=x_in, outputs=x_out, name='Red_MLP')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def CNN_network(input_shape, padding_value, out_layer='sigmoid'):\n",
    "    '''Función que define una red CNN para extraer características y \n",
    "    clasificar.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    padding_value : float\n",
    "        Valor utilizado para hacer padding en la señal.\n",
    "    out_layer : {'sigmoid', 'softmax'}, optional\n",
    "        Función a usar en la capa de salida de la red. Por defecto\n",
    "        es 'sigmoid'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model: tensorflow.keras.Model\n",
    "        Modelo del sistema.\n",
    "    '''\n",
    "    def _conv_bn_act_layer(input_layer, filters, kernel_size, padding,\n",
    "                           kernel_initializer, bias_initializer, name):\n",
    "        '''Función auxiliar que modela las capas azules conv + batchnorm +\n",
    "        Activation ReLU para realizar el ENCODING.'''\n",
    "        # Aplicando la concatenación de capas\n",
    "        x_conv = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, \n",
    "                                        kernel_initializer=kernel_initializer,\n",
    "                                        bias_initializer=bias_initializer,\n",
    "                                        padding=padding, \n",
    "                                        name=f'Conv_{name}')(input_layer)\n",
    "        x_conv = \\\n",
    "            tf.keras.layers.BatchNormalization(name=f'BatchNorm_{name}')(x_conv)\n",
    "        x_conv = \\\n",
    "            tf.keras.layers.Activation('relu', name=f'Activation_{name}')(x_conv)\n",
    "\n",
    "        return x_conv\n",
    "    \n",
    "    \n",
    "    def _cnn_layers(input_layer, n_layers_conv, layer_params):\n",
    "        '''Función auxiliar que permite modelar \"n_layers_conv\" capas CNN seguida de \n",
    "        una capa de Maxpooling.  \n",
    "        '''\n",
    "        # Definición de la salida de este bloque\n",
    "        x_enc = input_layer\n",
    "        \n",
    "        # Aplicando \"n_layers_conv\" capas convolucionales de codificación\n",
    "        for i in range(n_layers_conv):\n",
    "            x_enc = _conv_bn_act_layer(x_enc, filters=layer_params['filters'], \n",
    "                                       kernel_size=layer_params['kernel_size'], \n",
    "                                       padding=layer_params['padding'],\n",
    "                                       kernel_initializer=layer_params['kernel_initializer'],\n",
    "                                       bias_initializer=layer_params['bias_initializer'],\n",
    "                                       name=f\"{layer_params['name']}_{i}\")\n",
    "\n",
    "        # Finalmente la capa de MaxPooling\n",
    "        x_enc = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2, \n",
    "                                             padding='valid',\n",
    "                                             name=f\"MaxPool_Conv_{layer_params['name']}\")(x_enc)\n",
    "        return x_enc\n",
    "    \n",
    "    \n",
    "    def _mlp_layers(input_layer, units, kernel_initializer, \n",
    "               bias_initializer, name):\n",
    "        '''Función auxiliar que modela las capas Dense + batchnorm +\n",
    "        Activation ReLU'''\n",
    "        # Aplicando la concatenación de capas\n",
    "        x_dense = tf.keras.layers.Dense(units=units, \n",
    "                                        bias_initializer=bias_initializer,\n",
    "                                        kernel_initializer=kernel_initializer,\n",
    "                                        name=f'Dense_{name}')(input_layer)\n",
    "        x_dense = \\\n",
    "            tf.keras.layers.BatchNormalization(name=f'BatchNorm_{name}')(x_dense)\n",
    "        x_dense = \\\n",
    "            tf.keras.layers.Activation('relu', name=f'Activation_{name}')(x_dense)\n",
    "\n",
    "        return x_dense\n",
    "    \n",
    "    \n",
    "    # Definición de la entrada\n",
    "    x_in = tf.keras.Input(shape=input_shape, dtype='float32')\n",
    "    \n",
    "    # Definición de la capa de máscara\n",
    "    x_masked = tf.keras.layers.Masking(mask_value=padding_value)(x_in)\n",
    "                                             \n",
    "    # Definición de la CNN\n",
    "    layer_params_1 = {'filters': 50, 'kernel_size': 100, 'padding': 'same',\n",
    "                      'kernel_initializer': 'he_normal',\n",
    "                      'bias_initializer': 'he_normal', 'name': 'cnn_1'}\n",
    "    x_layer = _cnn_layers(x_masked, n_layers_conv=2, layer_params=layer_params_1)\n",
    "                                             \n",
    "    layer_params_2 = {'filters': 30, 'kernel_size': 50, 'padding': 'same',\n",
    "                      'kernel_initializer': 'he_normal',\n",
    "                      'bias_initializer': 'he_normal', 'name': 'cnn_2'}\n",
    "    x_layer = _cnn_layers(x_layer, n_layers_conv=2, layer_params=layer_params_2)\n",
    "                                             \n",
    "    layer_params_3 = {'filters': 10, 'kernel_size': 25, 'padding': 'same',\n",
    "                      'kernel_initializer': 'he_normal',\n",
    "                      'bias_initializer': 'he_normal', 'name': 'cnn_3'}\n",
    "    x_layer = _cnn_layers(x_layer, n_layers_conv=3, layer_params=layer_params_3)\n",
    "                                             \n",
    "    layer_params_4 = {'filters': 7, 'kernel_size': 13, 'padding': 'same',\n",
    "                      'kernel_initializer': 'he_normal',\n",
    "                      'bias_initializer': 'he_normal', 'name': 'cnn_4'}\n",
    "    x_layer = _cnn_layers(x_layer, n_layers_conv=3, layer_params=layer_params_4)\n",
    "                      \n",
    "    \n",
    "    # Definición de la capa de aplanamiento para conectar la CNN con la FCL \n",
    "    x_layer = tf.keras.layers.Flatten()(x_layer)                                     \n",
    "    \n",
    "    \n",
    "    # Definición de la red misma\n",
    "    x_layer = _mlp_layers(x_layer, units=500, kernel_initializer='he_normal', \n",
    "                          bias_initializer='he_normal', name='Layer_1')\n",
    "    x_layer = _mlp_layers(x_layer, units=200, kernel_initializer='he_normal', \n",
    "                          bias_initializer='he_normal', name='Layer_2')\n",
    "    x_layer = _mlp_layers(x_layer, units=100, kernel_initializer='he_normal', \n",
    "                          bias_initializer='he_normal', name='Layer_3')\n",
    "    x_layer = _mlp_layers(x_layer, units=80, kernel_initializer='he_normal', \n",
    "                          bias_initializer='he_normal', name='Layer_4')\n",
    "    x_layer = _mlp_layers(x_layer, units=30, kernel_initializer='he_normal', \n",
    "                          bias_initializer='he_normal', name='Layer_5')\n",
    "    x_layer = _mlp_layers(x_layer, units=10, kernel_initializer='he_normal', \n",
    "                          bias_initializer='he_normal', name='Layer_6')\n",
    "    x_layer = _mlp_layers(x_layer, units=5, kernel_initializer='he_normal', \n",
    "                          bias_initializer='he_normal', name='Layer_7')\n",
    "    \n",
    "    # Definición de la salida\n",
    "    if out_layer == 'softmax':\n",
    "        x_out = tf.keras.layers.Dense(2, activation='softmax', \n",
    "                                      kernel_initializer='he_normal', \n",
    "                                      bias_initializer='he_normal',\n",
    "                                      name='softmax_out')(x_layer)\n",
    "    elif out_layer == 'sigmoid':\n",
    "        x_out = tf.keras.layers.Dense(1, activation='sigmoid', \n",
    "                                      kernel_initializer='he_normal', \n",
    "                                      bias_initializer='he_normal',\n",
    "                                      name='sigmoid_out')(x_layer)\n",
    "    else:\n",
    "        raise Exception(f'Opción de parámetro \"out_layer\"={out_layer} '\n",
    "                        f'no válido.')\n",
    "    \n",
    "    # Definir el modelo\n",
    "    model = tf.keras.Model(inputs=x_in, outputs=x_out, name='Red_CNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_test_definition(X_data, Y_data, index_test, patient_groups,\n",
    "                          patient_register, kfold=10):\n",
    "    '''Función que permite retornar los conjuntos de entrenamiento\n",
    "    y testeo en base a la división de la base de datos realizada \n",
    "    previamente para hacer una validación cruzada.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_data : ndarray\n",
    "        Matriz de características.\n",
    "    Y_data : ndarray\n",
    "        Etiquetas de la matriz de características.\n",
    "    index_test : int\n",
    "        Índice del grupo de testeo en la validación cruzada.\n",
    "    patient_gropus : dict\n",
    "        Diccionario que contiene los pacientes que corresponden\n",
    "        a cada grupo de la validación cruzada.\n",
    "    patient_register : dict\n",
    "        Diccionario que contiene las entradas de cada paciente\n",
    "        en la matriz de características.\n",
    "    kfold : int, optional\n",
    "        k de la validación cruzada que se realiza. Por defecto \n",
    "        es 10.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train : ndarray\n",
    "        Datos de entrenamiento.\n",
    "    Y_train : ndarray\n",
    "        Etiquetas de los datos de entrenamiento.\n",
    "    X_test : ndarray\n",
    "        Datos de testeo.\n",
    "    Y_test : ndarray\n",
    "        Etiquetas de los datos de testeo.\n",
    "    '''\n",
    "    # Definición de los pacientes de testeo \n",
    "    test_patients = patient_groups[index_test]\n",
    "    \n",
    "    # Y entrenamiento\n",
    "    train_patients = list()\n",
    "    for i in range(1, kfold + 1):\n",
    "        if i != index_test:\n",
    "            train_patients.extend(patient_groups[i])\n",
    "            \n",
    "    # Definición de las entradas de entrenamiento y testeo\n",
    "    train_indexes = list()\n",
    "    test_indexes = list()\n",
    "    \n",
    "    for i in train_patients:\n",
    "        train_indexes.extend(patient_register[str(i)])\n",
    "    \n",
    "    for i in test_patients:\n",
    "        test_indexes.extend(patient_register[str(i)])\n",
    "\n",
    "    # Aplicando los indices sobre los datos\n",
    "    X_train = X_data[train_indexes]\n",
    "    Y_train = Y_data[train_indexes]\n",
    "    X_test  = X_data[test_indexes]\n",
    "    Y_test  = Y_data[test_indexes]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "    \n",
    "    \n",
    "def crossval_results(X_data, Y_data, experiment_type='ML', clean_params=None, \n",
    "                     sel_params=None, class_params=None, mlp_params=None,\n",
    "                     kfold=10):\n",
    "    '''Función que permite calcular el desempeño del clasificador\n",
    "    mediante una validación cruzada de los datos.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_data : ndarray\n",
    "        Matriz de características.\n",
    "    Y_data : ndarray\n",
    "        Etiquetas de la matriz de características.\n",
    "    experiment_type : {'ML', 'NN-MLP' 'CNN'}, optional\n",
    "        Tipo de sistema a estudiar. 'ML' corresponde a un diseño\n",
    "        estilo Machine-Learning (Rec. de Patrones). 'NN-MLP'\n",
    "        corresponde a un diseño que utiliza como salida un \n",
    "        clasificador de perceptrones multicapas. 'CNN' es un\n",
    "        diseño que utiliza una CNN con arquitectura clásica\n",
    "        (AlexNet o VGG-16) para clasificar cada segmento.\n",
    "        Por defecto es 'ML'.\n",
    "    clean_params: dict or None, optional\n",
    "        Parámetros del proceso de limpieza de características. \n",
    "        Si es None se utilizan características por defecto: \n",
    "        'tol': 13-5, 'show': True. Por defecto es None.\n",
    "    sel_params: dict or None, optional\n",
    "        Parámetros del proceso de selección de características. \n",
    "        Si es None se utilizan características por defecto: \n",
    "        'n_features': 10, 'show': True. Por defecto es None.\n",
    "    class_params: dict or None, optional\n",
    "        Parámetros del proceso de clasificación. Si es None se \n",
    "        utilizan características por defecto: \n",
    "        'classifier': 'knn', 'k_neigh': 10. Por defecto es None. \n",
    "        En caso de usar 'svm', es posible modificar el 'kernel'.\n",
    "    mlp_params : dict or None, optional\n",
    "        Parámetros del preoceso de clasificación con MLP. Si es\n",
    "        None se utilizan las características por defecto:\n",
    "        {'optimizer': 'Adam', 'loss': 'binary_crossentropy',\n",
    "         'batch_size': None, 'epochs': 100, 'verbose': 1, \n",
    "         'metrics': ['accuracy', tf.keras.metrics.Recall(), \n",
    "                      tf.keras.metrics.Precision()],\n",
    "         'out_layer': 'sigmoid', 'preprocessing': True}\n",
    "    kfold : int, optional\n",
    "        k de las repeticiones de la validación cruzada k-fold.\n",
    "        Por defecto es 10.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    confmat_list: list\n",
    "        Lista de las matrices de confusión para cada iteración.\n",
    "    accuracy_list : list\n",
    "        Lista de las accuracys para cada iteración.\n",
    "    '''\n",
    "    # Definición de la lista de matrices de confusión\n",
    "    confmat_list = list()\n",
    "    \n",
    "    # Iteraciónes del k-fold cross validation\n",
    "    for index in range(1, kfold + 1):\n",
    "        # Definición de la base de datos\n",
    "        X_train, Y_train, X_test, Y_test = \\\n",
    "            train_test_definition(X_data, Y_data, index_test=index, \n",
    "                                  patient_groups=patient_groups,\n",
    "                                  patient_register=patient_register)\n",
    "\n",
    "        # Aplicando el clasificador\n",
    "        if experiment_type == 'ML':\n",
    "            classifier, X_test, params_out, Y_pred = \\\n",
    "                    ML_classification_system(X_train, Y_train, X_test, Y_test, \n",
    "                                             clean_params=clean_params, \n",
    "                                             sel_params=sel_params, \n",
    "                                             class_params=class_params)\n",
    "            \n",
    "        elif experiment_type == 'NN-MLP':\n",
    "            model, X_test, params_out, Y_pred = \\\n",
    "                NN_MLP_classification_system(X_train, Y_train, X_test, Y_test, \n",
    "                                             clean_params=clean_params, \n",
    "                                             sel_params=sel_params, \n",
    "                                             mlp_params=mlp_params)\n",
    "            \n",
    "            # Modificar el Y_pred\n",
    "            Y_pred = np.where(Y_pred < 0.5, 0, 1)[:, 0]\n",
    "\n",
    "        elif experiment_type == 'CNN':\n",
    "            pass\n",
    "    \n",
    "        else:\n",
    "            raise Exception('Opción no válida para \"experiment_type\".')\n",
    "    \n",
    "        # Obteniendo la matriz de confusión\n",
    "        conf_mat = confusion_matrix(Y_pred, Y_test)\n",
    "        \n",
    "        # Agregando a la lista\n",
    "        confmat_list.append(conf_mat)\n",
    "    \n",
    "    # Cálculo de los resultados finales\n",
    "    accuracy_list = list()\n",
    "    \n",
    "    for cmat in confmat_list:\n",
    "        accuracy_i = np.sum(np.diag(cmat)) / np.sum(cmat)\n",
    "        accuracy_list.append(accuracy_i)\n",
    "        \n",
    "    print(f'Accuracy {kfold}-fold CV: {np.mean(accuracy_list)} +- '\n",
    "          f'{np.std(accuracy_list)}')\n",
    "    \n",
    "    return confmat_list, accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:48:20.243609Z",
     "start_time": "2021-04-19T05:48:20.227669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros generales\n",
    "clean_params = {'tol': 1e-5, 'show': True}\n",
    "sel_params = {'n_features': 60, 'show': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:48:28.233716Z",
     "start_time": "2021-04-19T05:48:21.114513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 112.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:03<00:00, 16.8 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 112.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:03<00:00, 17.3 features/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 60)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-848e7980f18b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                          \u001b[0mclean_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                          \u001b[0msel_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msel_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                          class_params=class_params)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mconfmat_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_max\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-484e8ef374fd>\u001b[0m in \u001b[0;36mcrossval_results\u001b[1;34m(X_data, Y_data, experiment_type, clean_params, sel_params, class_params, mlp_params, kfold)\u001b[0m\n\u001b[0;32m    611\u001b[0m                                              \u001b[0mclean_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                                              \u001b[0msel_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msel_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m                                              class_params=class_params)\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mexperiment_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NN-MLP'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-484e8ef374fd>\u001b[0m in \u001b[0;36mML_classification_system\u001b[1;34m(X_train, Y_train, X_test, Y_test, clean_params, sel_params, class_params)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;31m# Aplicando el clasificador\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    670\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 672\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 60)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "class_params = {'classifier': 'knn', 'k_neigh': 3}\n",
    "\n",
    "# Diseño de los clasificadores y resultados\n",
    "confmat_mean, accuracy_mean = \\\n",
    "        crossval_results(X_data_mean, Y_diagnosis, \n",
    "                         experiment_type='ML', \n",
    "                         clean_params=clean_params, \n",
    "                         sel_params=sel_params, \n",
    "                         class_params=class_params)\n",
    "\n",
    "confmat_max, accuracy_max = \\\n",
    "        crossval_results(X_data_max, Y_diagnosis, \n",
    "                         experiment_type='ML', \n",
    "                         clean_params=clean_params, \n",
    "                         sel_params=sel_params, \n",
    "                         class_params=class_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:46:00.509290Z",
     "start_time": "2021-04-19T05:44:03.466116Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:04<00:00, 12.0 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.5 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.5 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.7 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.5 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 112.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.9 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.6 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.6 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.3 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:05<00:00, 11.6 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10-fold CV: 0.31217032967032965 +- 0.3085031385464791\n",
      "Clean: number of features reduced from 149 to 135.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.48 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.17 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 134.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.13 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.89 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.10 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.14 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 132.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 8.76 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.20 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.16 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 134.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:06<00:00, 9.06 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10-fold CV: 0.16638888888888886 +- 0.23468671657823242\n"
     ]
    }
   ],
   "source": [
    "class_params = {'classifier': 'svm', 'kernel': 'poly'}\n",
    "\n",
    "# Diseño de los clasificadores y resultados\n",
    "confmat_mean, accuracy_mean = \\\n",
    "        crossval_results(X_data_mean, Y_diagnosis, \n",
    "                         experiment_type='ML', \n",
    "                         clean_params=clean_params, \n",
    "                         sel_params=sel_params, \n",
    "                         class_params=class_params)\n",
    "\n",
    "confmat_max, accuracy_max = \\\n",
    "        crossval_results(X_data_max, Y_diagnosis, \n",
    "                         experiment_type='ML', \n",
    "                         clean_params=clean_params, \n",
    "                         sel_params=sel_params, \n",
    "                         class_params=class_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T05:34:46.374307Z",
     "start_time": "2021-04-19T05:34:46.359838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  1,  1,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  3,  2,  6,  4, 51]], dtype=int64), array([[ 0,  0],\n",
       "        [ 5, 59]], dtype=int64), array([[ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  1,  0,  1],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 2,  2, 11,  2, 50]], dtype=int64), array([[ 1,  0,  0,  1,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0],\n",
       "        [ 0,  2,  0,  0,  0],\n",
       "        [ 2,  5,  0,  1, 56]], dtype=int64), array([[ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  1],\n",
       "        [ 4,  1,  3,  0, 56]], dtype=int64), array([[ 0,  0,  0,  0,  0,  2],\n",
       "        [ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  2],\n",
       "        [ 0,  0,  0,  0,  0,  2],\n",
       "        [ 0,  0,  1,  0,  0,  0],\n",
       "        [ 0,  1,  1,  3,  1, 59]], dtype=int64), array([[ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  3],\n",
       "        [ 1,  1,  1,  0, 77]], dtype=int64), array([[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 5,  3, 56]], dtype=int64), array([[ 0,  0,  2],\n",
       "        [ 0,  0,  1],\n",
       "        [ 6,  0, 59]], dtype=int64), array([[ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  1,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  2,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  3,  2,  0,  1, 60]], dtype=int64)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T11:10:21.039483Z",
     "start_time": "2021-04-18T10:39:53.344360Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 121.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:15<00:00, 4.00 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:16<00:00, 3.72 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.53 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:19<00:00, 3.07 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.37 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:15<00:00, 3.77 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:16<00:00, 3.69 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:16<00:00, 3.71 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:16<00:00, 3.65 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.51 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10-fold CV: 0.5547237580848834 +- 0.08159031973013899\n",
      "Clean: number of features reduced from 149 to 121.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:16<00:00, 3.66 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.36 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:18<00:00, 3.30 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:19<00:00, 3.10 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.43 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.43 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:18<00:00, 3.27 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:18<00:00, 3.23 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.41 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:17<00:00, 3.47 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10-fold CV: 0.7507860071542727 +- 0.07070154593320024\n",
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.81 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.86 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.63 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.84 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:20<00:00, 2.86 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.82 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.79 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.76 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.76 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:21<00:00, 2.81 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10-fold CV: 0.5655197838280108 +- 0.07584921945477313\n",
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.65 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.67 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.68 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:23<00:00, 2.57 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:23<00:00, 2.61 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.64 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.65 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.67 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:22<00:00, 2.69 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean: number of features reduced from 149 to 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|████████████████████████████████████████████████████| 60.0/60.0 [00:23<00:00, 2.52 features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10-fold CV: 0.7933760009183782 +- 0.055980745332417696\n"
     ]
    }
   ],
   "source": [
    "preprocessing = True\n",
    "mlp_params = {'optimizer': 'Adam', 'loss': 'binary_crossentropy',\n",
    "              'batch_size': None, 'epochs': 30, 'verbose': 0, \n",
    "              'metrics': ['accuracy', tf.keras.metrics.Recall(), \n",
    "                          tf.keras.metrics.Precision()],\n",
    "              'out_layer': 'sigmoid', 'preprocessing': True}\n",
    "\n",
    "# Diseño de los clasificadores y resultados\n",
    "confmat_mean, accuracy_mean = \\\n",
    "        crossval_results(X_data_mean, Y_diagnosis, \n",
    "                         experiment_type='NN-MLP', \n",
    "                         clean_params=clean_params, \n",
    "                         sel_params=sel_params, \n",
    "                         mlp_params=mlp_params)\n",
    "\n",
    "confmat_max, accuracy_max = \\\n",
    "        crossval_results(X_data_max, Y_diagnosis, \n",
    "                         experiment_type='NN-MLP', \n",
    "                         clean_params=clean_params, \n",
    "                         sel_params=sel_params, \n",
    "                         mlp_params=mlp_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T22:46:47.813141Z",
     "start_time": "2021-04-18T22:46:46.909399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4902, 31320, 1)\n"
     ]
    }
   ],
   "source": [
    "X_segments_mat = tf.keras.preprocessing.sequence.pad_sequences(X_segments, padding=\"post\", value=10)\n",
    "X_segments_mat = np.expand_dims(X_segments_mat, axis=-1)\n",
    "print(X_segments_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T22:56:05.765746Z",
     "start_time": "2021-04-18T22:56:05.554140Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_params = {'optimizer': 'Adam', 'loss': 'categorical_crossentropy',\n",
    "              'batch_size': 5, 'epochs': 10, 'verbose': 0, \n",
    "              'metrics': ['accuracy', tf.keras.metrics.Recall(), \n",
    "                          tf.keras.metrics.Precision()],\n",
    "              'out_layer': 'softmax'}\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = \\\n",
    "        train_test_definition(X_segments_mat, Y_crackl, index_test=10, \n",
    "                              patient_groups=patient_groups,\n",
    "                              patient_register=patient_register, kfold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T22:56:10.681684Z",
     "start_time": "2021-04-18T22:56:10.171032Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CNN_network(input_shape=X_segments_mat.shape[1:], padding_value=10, \n",
    "                    out_layer=cnn_params['out_layer'])\n",
    "model.compile(optimizer=cnn_params['optimizer'], loss=cnn_params['loss'],\n",
    "              metrics=cnn_params['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T22:56:11.976225Z",
     "start_time": "2021-04-18T22:56:11.808675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Red_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 31320, 1)]        0         \n",
      "_________________________________________________________________\n",
      "masking_13 (Masking)         (None, 31320, 1)          0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_1_0 (Conv1D)        (None, 31320, 50)         5050      \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_1_0 (BatchNorm (None, 31320, 50)         200       \n",
      "_________________________________________________________________\n",
      "Activation_cnn_1_0 (Activati (None, 31320, 50)         0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_1_1 (Conv1D)        (None, 31320, 50)         250050    \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_1_1 (BatchNorm (None, 31320, 50)         200       \n",
      "_________________________________________________________________\n",
      "Activation_cnn_1_1 (Activati (None, 31320, 50)         0         \n",
      "_________________________________________________________________\n",
      "MaxPool_Conv_cnn_1 (MaxPooli (None, 15660, 50)         0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_2_0 (Conv1D)        (None, 15660, 30)         75030     \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_2_0 (BatchNorm (None, 15660, 30)         120       \n",
      "_________________________________________________________________\n",
      "Activation_cnn_2_0 (Activati (None, 15660, 30)         0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_2_1 (Conv1D)        (None, 15660, 30)         45030     \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_2_1 (BatchNorm (None, 15660, 30)         120       \n",
      "_________________________________________________________________\n",
      "Activation_cnn_2_1 (Activati (None, 15660, 30)         0         \n",
      "_________________________________________________________________\n",
      "MaxPool_Conv_cnn_2 (MaxPooli (None, 7830, 30)          0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_3_0 (Conv1D)        (None, 7830, 10)          7510      \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_3_0 (BatchNorm (None, 7830, 10)          40        \n",
      "_________________________________________________________________\n",
      "Activation_cnn_3_0 (Activati (None, 7830, 10)          0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_3_1 (Conv1D)        (None, 7830, 10)          2510      \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_3_1 (BatchNorm (None, 7830, 10)          40        \n",
      "_________________________________________________________________\n",
      "Activation_cnn_3_1 (Activati (None, 7830, 10)          0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_3_2 (Conv1D)        (None, 7830, 10)          2510      \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_3_2 (BatchNorm (None, 7830, 10)          40        \n",
      "_________________________________________________________________\n",
      "Activation_cnn_3_2 (Activati (None, 7830, 10)          0         \n",
      "_________________________________________________________________\n",
      "MaxPool_Conv_cnn_3 (MaxPooli (None, 3915, 10)          0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_4_0 (Conv1D)        (None, 3915, 7)           917       \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_4_0 (BatchNorm (None, 3915, 7)           28        \n",
      "_________________________________________________________________\n",
      "Activation_cnn_4_0 (Activati (None, 3915, 7)           0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_4_1 (Conv1D)        (None, 3915, 7)           644       \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_4_1 (BatchNorm (None, 3915, 7)           28        \n",
      "_________________________________________________________________\n",
      "Activation_cnn_4_1 (Activati (None, 3915, 7)           0         \n",
      "_________________________________________________________________\n",
      "Conv_cnn_4_2 (Conv1D)        (None, 3915, 7)           644       \n",
      "_________________________________________________________________\n",
      "BatchNorm_cnn_4_2 (BatchNorm (None, 3915, 7)           28        \n",
      "_________________________________________________________________\n",
      "Activation_cnn_4_2 (Activati (None, 3915, 7)           0         \n",
      "_________________________________________________________________\n",
      "MaxPool_Conv_cnn_4 (MaxPooli (None, 1957, 7)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 13699)             0         \n",
      "_________________________________________________________________\n",
      "Dense_Layer_1 (Dense)        (None, 500)               6850000   \n",
      "_________________________________________________________________\n",
      "BatchNorm_Layer_1 (BatchNorm (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "Activation_Layer_1 (Activati (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "Dense_Layer_2 (Dense)        (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "BatchNorm_Layer_2 (BatchNorm (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "Activation_Layer_2 (Activati (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_Layer_3 (Dense)        (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "BatchNorm_Layer_3 (BatchNorm (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "Activation_Layer_3 (Activati (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Dense_Layer_4 (Dense)        (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "BatchNorm_Layer_4 (BatchNorm (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "Activation_Layer_4 (Activati (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "Dense_Layer_5 (Dense)        (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "BatchNorm_Layer_5 (BatchNorm (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "Activation_Layer_5 (Activati (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "Dense_Layer_6 (Dense)        (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "BatchNorm_Layer_6 (BatchNorm (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "Activation_Layer_6 (Activati (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "Dense_Layer_7 (Dense)        (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "BatchNorm_Layer_7 (BatchNorm (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "Activation_Layer_7 (Activati (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "softmax_out (Dense)          (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 7,375,626\n",
      "Trainable params: 7,373,354\n",
      "Non-trainable params: 2,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T22:56:13.227093Z",
     "start_time": "2021-04-18T22:56:13.213841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4410, 31320, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T22:56:14.395904Z",
     "start_time": "2021-04-18T22:56:14.392876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pasando a One-Hot\n",
    "Y_train1H = np.array([Y_train, np.ones(Y_train.shape[0]) - Y_train]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-18T22:56:14.798Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/882 [==>...........................] - ETA: 0s - loss: 0.7896 - accuracy: 0.4000 - recall_8: 0.4000 - precision_8: 0.400 - ETA: 2:06 - loss: 1.1463 - accuracy: 0.3000 - recall_8: 0.3000 - precision_8: 0.300 - ETA: 2:47 - loss: 1.2646 - accuracy: 0.2667 - recall_8: 0.2667 - precision_8: 0.266 - ETA: 3:07 - loss: 1.1994 - accuracy: 0.2500 - recall_8: 0.2500 - precision_8: 0.250 - ETA: 3:20 - loss: 1.1784 - accuracy: 0.2400 - recall_8: 0.2400 - precision_8: 0.240 - ETA: 3:27 - loss: 1.2030 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:33 - loss: 1.1494 - accuracy: 0.2286 - recall_8: 0.2286 - precision_8: 0.228 - ETA: 3:37 - loss: 1.1309 - accuracy: 0.2250 - recall_8: 0.2250 - precision_8: 0.225 - ETA: 3:40 - loss: 1.1329 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:43 - loss: 1.1343 - accuracy: 0.1800 - recall_8: 0.1800 - precision_8: 0.180 - ETA: 3:45 - loss: 1.1214 - accuracy: 0.1818 - recall_8: 0.1818 - precision_8: 0.181 - ETA: 3:46 - loss: 1.0978 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:48 - loss: 1.0894 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:49 - loss: 1.0821 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:50 - loss: 1.0757 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:50 - loss: 1.0990 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:51 - loss: 1.1008 - accuracy: 0.1882 - recall_8: 0.1882 - precision_8: 0.188 - ETA: 3:51 - loss: 1.1023 - accuracy: 0.1778 - recall_8: 0.1778 - precision_8: 0.177 - ETA: 3:52 - loss: 1.0957 - accuracy: 0.1789 - recall_8: 0.1789 - precision_8: 0.178 - ETA: 3:52 - loss: 1.0809 - accuracy: 0.1900 - recall_8: 0.1900 - precision_8: 0.190 - ETA: 3:53 - loss: 1.0906 - accuracy: 0.1905 - recall_8: 0.1905 - precision_8: 0.190 - ETA: 3:53 - loss: 1.0773 - accuracy: 0.1909 - recall_8: 0.1909 - precision_8: 0.190 - ETA: 3:53 - loss: 1.0789 - accuracy: 0.1826 - recall_8: 0.1826 - precision_8: 0.182 - ETA: 3:54 - loss: 1.0743 - accuracy: 0.1833 - recall_8: 0.1833 - precision_8: 0.183 - ETA: 3:54 - loss: 1.0587 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:54 - loss: 1.0399 - accuracy: 0.2077 - recall_8: 0.2077 - precision_8: 0.207 - ETA: 3:54 - loss: 1.0360 - accuracy: 0.2148 - recall_8: 0.2148 - precision_8: 0.214 - ETA: 3:54 - loss: 1.0384 - accuracy: 0.2071 - recall_8: 0.2071 - precision_8: 0.207 - ETA: 3:54 - loss: 1.0400 - accuracy: 0.2069 - recall_8: 0.2069 - precision_8: 0.206 - ETA: 3:54 - loss: 1.0456 - accuracy: 0.2067 - recall_8: 0.2067 - precision_8: 0.206 - ETA: 3:54 - loss: 1.0622 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:54 - loss: 1.0632 - accuracy: 0.1937 - recall_8: 0.1937 - precision_8: 0.193 - ETA: 3:54 - loss: 1.0599 - accuracy: 0.1939 - recall_8: 0.1939 - precision_8: 0.193 - ETA: 3:54 - loss: 1.0568 - accuracy: 0.1941 - recall_8: 0.1941 - precision_8: 0.194 - ETA: 3:54 - loss: 1.0577 - accuracy: 0.1886 - recall_8: 0.1886 - precision_8: 0.188 - ETA: 3:54 - loss: 1.0547 - accuracy: 0.1889 - recall_8: 0.1889 - precision_8: 0.188 - ETA: 3:54 - loss: 1.0488 - accuracy: 0.1892 - recall_8: 0.1892 - precision_8: 0.189 - ETA: 3:54 - loss: 1.0551 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:54 - loss: 1.0523 - accuracy: 0.2000 - recall_8: 0.2000 - precision_8: 0.200 - ETA: 3:54 - loss: 1.0529 - accuracy: 0.1950 - recall_8: 0.1950 - precision_8: 0.195 - ETA: 3:54 - loss: 1.0502 - accuracy: 0.1951 - recall_8: 0.1951 - precision_8: 0.195 - ETA: 3:53 - loss: 1.0576 - accuracy: 0.2048 - recall_8: 0.2048 - precision_8: 0.204 - ETA: 3:53 - loss: 1.0458 - accuracy: 0.2186 - recall_8: 0.2186 - precision_8: 0.218 - ETA: 3:53 - loss: 1.0528 - accuracy: 0.2273 - recall_8: 0.2273 - precision_8: 0.227 - ETA: 3:53 - loss: 1.0530 - accuracy: 0.2311 - recall_8: 0.2311 - precision_8: 0.231 - ETA: 3:53 - loss: 1.0445 - accuracy: 0.2348 - recall_8: 0.2348 - precision_8: 0.234 - ETA: 3:53 - loss: 1.0498 - accuracy: 0.2426 - recall_8: 0.2426 - precision_8: 0.242 - ETA: 3:52 - loss: 1.0515 - accuracy: 0.2375 - recall_8: 0.2375 - precision_8: 0.237 - ETA: 3:52 - loss: 1.0515 - accuracy: 0.2327 - recall_8: 0.2327 - precision_8: 0.232 - ETA: 3:52 - loss: 1.0416 - accuracy: 0.2440 - recall_8: 0.2440 - precision_8: 0.244 - ETA: 3:52 - loss: 1.0373 - accuracy: 0.2471 - recall_8: 0.2471 - precision_8: 0.247 - ETA: 3:52 - loss: 1.0352 - accuracy: 0.2462 - recall_8: 0.2462 - precision_8: 0.246 - ETA: 3:52 - loss: 1.0338 - accuracy: 0.2453 - recall_8: 0.2453 - precision_8: 0.245 - ETA: 3:51 - loss: 1.0347 - accuracy: 0.2444 - recall_8: 0.2444 - precision_8: 0.244 - ETA: 3:51 - loss: 1.0348 - accuracy: 0.2400 - recall_8: 0.2400 - precision_8: 0.240 - ETA: 3:51 - loss: 1.0306 - accuracy: 0.2429 - recall_8: 0.2429 - precision_8: 0.242 - ETA: 3:51 - loss: 1.0250 - accuracy: 0.2456 - recall_8: 0.2456 - precision_8: 0.245 - ETA: 3:51 - loss: 1.0231 - accuracy: 0.2448 - recall_8: 0.2448 - precision_8: 0.244 - ETA: 3:50 - loss: 1.0187 - accuracy: 0.2475 - recall_8: 0.2475 - precision_8: 0.247 - ETA: 3:50 - loss: 1.0150 - accuracy: 0.2500 - recall_8: 0.2500 - precision_8: 0.250 - ETA: 3:50 - loss: 1.0133 - accuracy: 0.2492 - recall_8: 0.2492 - precision_8: 0.249 - ETA: 3:50 - loss: 1.0136 - accuracy: 0.2452 - recall_8: 0.2452 - precision_8: 0.245 - ETA: 3:50 - loss: 1.0119 - accuracy: 0.2444 - recall_8: 0.2444 - precision_8: 0.244 - ETA: 3:49 - loss: 1.0127 - accuracy: 0.2406 - recall_8: 0.2406 - precision_8: 0.240 - ETA: 3:49 - loss: 1.0092 - accuracy: 0.2400 - recall_8: 0.2400 - precision_8: 0.240 - ETA: 3:49 - loss: 1.0076 - accuracy: 0.2394 - recall_8: 0.2394 - precision_8: 0.239 - ETA: 3:49 - loss: 1.0044 - accuracy: 0.2418 - recall_8: 0.2418 - precision_8: 0.241 - ETA: 3:48 - loss: 0.9975 - accuracy: 0.2500 - recall_8: 0.2500 - precision_8: 0.250 - ETA: 3:48 - loss: 0.9977 - accuracy: 0.2464 - recall_8: 0.2464 - precision_8: 0.246 - ETA: 3:48 - loss: 0.9959 - accuracy: 0.2486 - recall_8: 0.2486 - precision_8: 0.248 - ETA: 3:48 - loss: 0.9913 - accuracy: 0.2535 - recall_8: 0.2535 - precision_8: 0.253 - ETA: 3:48 - loss: 0.9919 - accuracy: 0.2500 - recall_8: 0.2500 - precision_8: 0.250 - ETA: 3:47 - loss: 0.9871 - accuracy: 0.2521 - recall_8: 0.2521 - precision_8: 0.252 - ETA: 3:47 - loss: 0.9858 - accuracy: 0.2514 - recall_8: 0.2514 - precision_8: 0.251 - ETA: 3:47 - loss: 0.9851 - accuracy: 0.2507 - recall_8: 0.2507 - precision_8: 0.250 - ETA: 3:47 - loss: 0.9812 - accuracy: 0.2526 - recall_8: 0.2526 - precision_8: 0.252 - ETA: 3:46 - loss: 0.9788 - accuracy: 0.2597 - recall_8: 0.2597 - precision_8: 0.259 - ETA: 3:46 - loss: 0.9763 - accuracy: 0.2615 - recall_8: 0.2615 - precision_8: 0.261 - ETA: 3:46 - loss: 0.9717 - accuracy: 0.2608 - recall_8: 0.2608 - precision_8: 0.260 - ETA: 3:46 - loss: 0.9706 - accuracy: 0.2600 - recall_8: 0.2600 - precision_8: 0.260 - ETA: 3:45 - loss: 0.9743 - accuracy: 0.2617 - recall_8: 0.2617 - precision_8: 0.261 - ETA: 3:45 - loss: 0.9751 - accuracy: 0.2610 - recall_8: 0.2610 - precision_8: 0.261 - ETA: 3:45 - loss: 0.9759 - accuracy: 0.2602 - recall_8: 0.2602 - precision_8: 0.260 - ETA: 3:45 - loss: 0.9748 - accuracy: 0.2595 - recall_8: 0.2595 - precision_8: 0.259 - ETA: 3:44 - loss: 0.9771 - accuracy: 0.2635 - recall_8: 0.2635 - precision_8: 0.263 - ETA: 3:44 - loss: 0.9747 - accuracy: 0.2628 - recall_8: 0.2628 - precision_8: 0.262 - ETA: 3:44 - loss: 0.9705 - accuracy: 0.2644 - recall_8: 0.2644 - precision_8: 0.264 - ETA: 3:44 - loss: 0.9691 - accuracy: 0.2659 - recall_8: 0.2659 - precision_8: 0.265 - ETA: 3:44 - loss: 0.9641 - accuracy: 0.2719 - recall_8: 0.2719 - precision_8: 0.271 - ETA: 3:43 - loss: 0.9696 - accuracy: 0.2733 - recall_8: 0.2733 - precision_8: 0.273 - ETA: 3:43 - loss: 0.9701 - accuracy: 0.2703 - recall_8: 0.2703 - precision_8: 0.270 - ETA: 3:43 - loss: 0.9698 - accuracy: 0.2674 - recall_8: 0.2674 - precision_8: 0.267 - ETA: 3:43 - loss: 0.9656 - accuracy: 0.2667 - recall_8: 0.2667 - precision_8: 0.266 - ETA: 3:42 - loss: 0.9656 - accuracy: 0.2660 - recall_8: 0.2660 - precision_8: 0.266 - ETA: 3:42 - loss: 0.9635 - accuracy: 0.2674 - recall_8: 0.2674 - precision_8: 0.267190/882 [=====>........................] - ETA: 3:42 - loss: 0.9611 - accuracy: 0.2708 - recall_8: 0.2708 - precision_8: 0.270 - ETA: 3:42 - loss: 0.9587 - accuracy: 0.2742 - recall_8: 0.2742 - precision_8: 0.274 - ETA: 3:41 - loss: 0.9587 - accuracy: 0.2796 - recall_8: 0.2796 - precision_8: 0.279 - ETA: 3:41 - loss: 0.9587 - accuracy: 0.2768 - recall_8: 0.2768 - precision_8: 0.276 - ETA: 3:41 - loss: 0.9558 - accuracy: 0.2800 - recall_8: 0.2800 - precision_8: 0.280 - ETA: 3:40 - loss: 0.9557 - accuracy: 0.2812 - recall_8: 0.2812 - precision_8: 0.281 - ETA: 3:40 - loss: 0.9525 - accuracy: 0.2824 - recall_8: 0.2824 - precision_8: 0.282 - ETA: 3:40 - loss: 0.9524 - accuracy: 0.2816 - recall_8: 0.2816 - precision_8: 0.281 - ETA: 3:40 - loss: 0.9515 - accuracy: 0.2808 - recall_8: 0.2808 - precision_8: 0.280 - ETA: 3:39 - loss: 0.9515 - accuracy: 0.2857 - recall_8: 0.2857 - precision_8: 0.285 - ETA: 3:39 - loss: 0.9514 - accuracy: 0.2830 - recall_8: 0.2830 - precision_8: 0.283 - ETA: 3:39 - loss: 0.9513 - accuracy: 0.2804 - recall_8: 0.2804 - precision_8: 0.280 - ETA: 3:39 - loss: 0.9504 - accuracy: 0.2796 - recall_8: 0.2796 - precision_8: 0.279 - ETA: 3:38 - loss: 0.9487 - accuracy: 0.2807 - recall_8: 0.2807 - precision_8: 0.280 - ETA: 3:38 - loss: 0.9477 - accuracy: 0.2800 - recall_8: 0.2800 - precision_8: 0.280 - ETA: 3:38 - loss: 0.9482 - accuracy: 0.2847 - recall_8: 0.2847 - precision_8: 0.284 - ETA: 3:38 - loss: 0.9429 - accuracy: 0.2911 - recall_8: 0.2911 - precision_8: 0.291 - ETA: 3:37 - loss: 0.9403 - accuracy: 0.2920 - recall_8: 0.2920 - precision_8: 0.292 - ETA: 3:37 - loss: 0.9383 - accuracy: 0.2930 - recall_8: 0.2930 - precision_8: 0.293 - ETA: 3:37 - loss: 0.9351 - accuracy: 0.2974 - recall_8: 0.2974 - precision_8: 0.297 - ETA: 3:37 - loss: 0.9343 - accuracy: 0.2966 - recall_8: 0.2966 - precision_8: 0.296 - ETA: 3:36 - loss: 0.9341 - accuracy: 0.2940 - recall_8: 0.2940 - precision_8: 0.294 - ETA: 3:36 - loss: 0.9333 - accuracy: 0.2932 - recall_8: 0.2932 - precision_8: 0.293 - ETA: 3:36 - loss: 0.9318 - accuracy: 0.2941 - recall_8: 0.2941 - precision_8: 0.294 - ETA: 3:36 - loss: 0.9302 - accuracy: 0.2950 - recall_8: 0.2950 - precision_8: 0.295 - ETA: 3:35 - loss: 0.9308 - accuracy: 0.2992 - recall_8: 0.2992 - precision_8: 0.299 - ETA: 3:35 - loss: 0.9274 - accuracy: 0.3033 - recall_8: 0.3033 - precision_8: 0.303 - ETA: 3:35 - loss: 0.9287 - accuracy: 0.3057 - recall_8: 0.3057 - precision_8: 0.305 - ETA: 3:34 - loss: 0.9267 - accuracy: 0.3081 - recall_8: 0.3081 - precision_8: 0.308 - ETA: 3:34 - loss: 0.9263 - accuracy: 0.3104 - recall_8: 0.3104 - precision_8: 0.310 - ETA: 3:34 - loss: 0.9255 - accuracy: 0.3095 - recall_8: 0.3095 - precision_8: 0.309 - ETA: 3:34 - loss: 0.9241 - accuracy: 0.3102 - recall_8: 0.3102 - precision_8: 0.310 - ETA: 3:33 - loss: 0.9231 - accuracy: 0.3094 - recall_8: 0.3094 - precision_8: 0.309 - ETA: 3:33 - loss: 0.9223 - accuracy: 0.3085 - recall_8: 0.3085 - precision_8: 0.308 - ETA: 3:33 - loss: 0.9215 - accuracy: 0.3077 - recall_8: 0.3077 - precision_8: 0.307 - ETA: 3:33 - loss: 0.9216 - accuracy: 0.3084 - recall_8: 0.3084 - precision_8: 0.308 - ETA: 3:32 - loss: 0.9226 - accuracy: 0.3106 - recall_8: 0.3106 - precision_8: 0.310 - ETA: 3:32 - loss: 0.9236 - accuracy: 0.3128 - recall_8: 0.3128 - precision_8: 0.312 - ETA: 3:32 - loss: 0.9246 - accuracy: 0.3149 - recall_8: 0.3149 - precision_8: 0.314 - ETA: 3:32 - loss: 0.9243 - accuracy: 0.3126 - recall_8: 0.3126 - precision_8: 0.312 - ETA: 3:31 - loss: 0.9246 - accuracy: 0.3147 - recall_8: 0.3147 - precision_8: 0.314 - ETA: 3:31 - loss: 0.9245 - accuracy: 0.3153 - recall_8: 0.3153 - precision_8: 0.315 - ETA: 3:31 - loss: 0.9260 - accuracy: 0.3159 - recall_8: 0.3159 - precision_8: 0.315 - ETA: 3:30 - loss: 0.9261 - accuracy: 0.3194 - recall_8: 0.3194 - precision_8: 0.319 - ETA: 3:30 - loss: 0.9257 - accuracy: 0.3214 - recall_8: 0.3214 - precision_8: 0.321 - ETA: 3:30 - loss: 0.9239 - accuracy: 0.3234 - recall_8: 0.3234 - precision_8: 0.323 - ETA: 3:30 - loss: 0.9231 - accuracy: 0.3225 - recall_8: 0.3225 - precision_8: 0.322 - ETA: 3:29 - loss: 0.9211 - accuracy: 0.3231 - recall_8: 0.3231 - precision_8: 0.323 - ETA: 3:29 - loss: 0.9198 - accuracy: 0.3250 - recall_8: 0.3250 - precision_8: 0.325 - ETA: 3:29 - loss: 0.9205 - accuracy: 0.3255 - recall_8: 0.3255 - precision_8: 0.325 - ETA: 3:29 - loss: 0.9192 - accuracy: 0.3288 - recall_8: 0.3288 - precision_8: 0.328 - ETA: 3:28 - loss: 0.9175 - accuracy: 0.3306 - recall_8: 0.3306 - precision_8: 0.330 - ETA: 3:28 - loss: 0.9159 - accuracy: 0.3324 - recall_8: 0.3324 - precision_8: 0.332 - ETA: 3:28 - loss: 0.9157 - accuracy: 0.3329 - recall_8: 0.3329 - precision_8: 0.332 - ETA: 3:27 - loss: 0.9150 - accuracy: 0.3320 - recall_8: 0.3320 - precision_8: 0.332 - ETA: 3:27 - loss: 0.9143 - accuracy: 0.3298 - recall_8: 0.3298 - precision_8: 0.329 - ETA: 3:27 - loss: 0.9135 - accuracy: 0.3329 - recall_8: 0.3329 - precision_8: 0.332 - ETA: 3:27 - loss: 0.9119 - accuracy: 0.3346 - recall_8: 0.3346 - precision_8: 0.334 - ETA: 3:26 - loss: 0.9108 - accuracy: 0.3364 - recall_8: 0.3364 - precision_8: 0.336 - ETA: 3:26 - loss: 0.9093 - accuracy: 0.3368 - recall_8: 0.3368 - precision_8: 0.336 - ETA: 3:26 - loss: 0.9085 - accuracy: 0.3359 - recall_8: 0.3359 - precision_8: 0.335 - ETA: 3:26 - loss: 0.9071 - accuracy: 0.3389 - recall_8: 0.3389 - precision_8: 0.338 - ETA: 3:25 - loss: 0.9060 - accuracy: 0.3392 - recall_8: 0.3392 - precision_8: 0.339 - ETA: 3:25 - loss: 0.9048 - accuracy: 0.3409 - recall_8: 0.3409 - precision_8: 0.340 - ETA: 3:25 - loss: 0.9041 - accuracy: 0.3400 - recall_8: 0.3400 - precision_8: 0.340 - ETA: 3:24 - loss: 0.9033 - accuracy: 0.3391 - recall_8: 0.3391 - precision_8: 0.339 - ETA: 3:24 - loss: 0.9026 - accuracy: 0.3383 - recall_8: 0.3383 - precision_8: 0.338 - ETA: 3:24 - loss: 0.9023 - accuracy: 0.3362 - recall_8: 0.3362 - precision_8: 0.336 - ETA: 3:24 - loss: 0.9019 - accuracy: 0.3341 - recall_8: 0.3341 - precision_8: 0.334 - ETA: 3:23 - loss: 0.9006 - accuracy: 0.3333 - recall_8: 0.3333 - precision_8: 0.333 - ETA: 3:23 - loss: 0.8990 - accuracy: 0.3349 - recall_8: 0.3349 - precision_8: 0.334 - ETA: 3:23 - loss: 0.8969 - accuracy: 0.3389 - recall_8: 0.3389 - precision_8: 0.338 - ETA: 3:22 - loss: 0.8966 - accuracy: 0.3369 - recall_8: 0.3369 - precision_8: 0.336 - ETA: 3:22 - loss: 0.8956 - accuracy: 0.3396 - recall_8: 0.3396 - precision_8: 0.339 - ETA: 3:22 - loss: 0.8942 - accuracy: 0.3400 - recall_8: 0.3400 - precision_8: 0.340 - ETA: 3:22 - loss: 0.8938 - accuracy: 0.3380 - recall_8: 0.3380 - precision_8: 0.338 - ETA: 3:21 - loss: 0.8931 - accuracy: 0.3372 - recall_8: 0.3372 - precision_8: 0.337 - ETA: 3:21 - loss: 0.8928 - accuracy: 0.3364 - recall_8: 0.3364 - precision_8: 0.336 - ETA: 3:21 - loss: 0.8915 - accuracy: 0.3368 - recall_8: 0.3368 - precision_8: 0.336 - ETA: 3:21 - loss: 0.8908 - accuracy: 0.3349 - recall_8: 0.3349 - precision_8: 0.334 - ETA: 3:20 - loss: 0.8893 - accuracy: 0.3364 - recall_8: 0.3364 - precision_8: 0.336 - ETA: 3:20 - loss: 0.8883 - accuracy: 0.3367 - recall_8: 0.3367 - precision_8: 0.336 - ETA: 3:20 - loss: 0.8876 - accuracy: 0.3360 - recall_8: 0.3360 - precision_8: 0.336 - ETA: 3:19 - loss: 0.8871 - accuracy: 0.3374 - recall_8: 0.3374 - precision_8: 0.337 - ETA: 3:19 - loss: 0.8872 - accuracy: 0.3389 - recall_8: 0.3389 - precision_8: 0.338 - ETA: 3:19 - loss: 0.8865 - accuracy: 0.3381 - recall_8: 0.3381 - precision_8: 0.338 - ETA: 3:19 - loss: 0.8856 - accuracy: 0.3385 - recall_8: 0.3385 - precision_8: 0.338 - ETA: 3:18 - loss: 0.8851 - accuracy: 0.3366 - recall_8: 0.3366 - precision_8: 0.336 - ETA: 3:18 - loss: 0.8841 - accuracy: 0.3391 - recall_8: 0.3391 - precision_8: 0.339 - ETA: 3:18 - loss: 0.8827 - accuracy: 0.3405 - recall_8: 0.3405 - precision_8: 0.340 - ETA: 3:17 - loss: 0.8819 - accuracy: 0.3409 - recall_8: 0.3409 - precision_8: 0.340 - ETA: 3:17 - loss: 0.8814 - accuracy: 0.3390 - recall_8: 0.3390 - precision_8: 0.339 - ETA: 3:17 - loss: 0.8805 - accuracy: 0.3394 - recall_8: 0.3394 - precision_8: 0.339 - ETA: 3:17 - loss: 0.8798 - accuracy: 0.3386 - recall_8: 0.3386 - precision_8: 0.338 - ETA: 3:16 - loss: 0.8791 - accuracy: 0.3379 - recall_8: 0.3379 - precision_8: 0.3379"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/882 [========>.....................] - ETA: 3:16 - loss: 0.8770 - accuracy: 0.3414 - recall_8: 0.3414 - precision_8: 0.341 - ETA: 3:16 - loss: 0.8765 - accuracy: 0.3396 - recall_8: 0.3396 - precision_8: 0.339 - ETA: 3:16 - loss: 0.8760 - accuracy: 0.3378 - recall_8: 0.3378 - precision_8: 0.337 - ETA: 3:15 - loss: 0.8739 - accuracy: 0.3412 - recall_8: 0.3412 - precision_8: 0.341 - ETA: 3:15 - loss: 0.8732 - accuracy: 0.3405 - recall_8: 0.3405 - precision_8: 0.340 - ETA: 3:15 - loss: 0.8726 - accuracy: 0.3418 - recall_8: 0.3418 - precision_8: 0.341 - ETA: 3:14 - loss: 0.8718 - accuracy: 0.3421 - recall_8: 0.3421 - precision_8: 0.342 - ETA: 3:14 - loss: 0.8711 - accuracy: 0.3414 - recall_8: 0.3414 - precision_8: 0.341 - ETA: 3:14 - loss: 0.8727 - accuracy: 0.3417 - recall_8: 0.3417 - precision_8: 0.341 - ETA: 3:14 - loss: 0.8733 - accuracy: 0.3420 - recall_8: 0.3420 - precision_8: 0.342 - ETA: 3:13 - loss: 0.8726 - accuracy: 0.3413 - recall_8: 0.3413 - precision_8: 0.341 - ETA: 3:13 - loss: 0.8719 - accuracy: 0.3406 - recall_8: 0.3406 - precision_8: 0.340 - ETA: 3:13 - loss: 0.8712 - accuracy: 0.3419 - recall_8: 0.3419 - precision_8: 0.341 - ETA: 3:12 - loss: 0.8722 - accuracy: 0.3412 - recall_8: 0.3412 - precision_8: 0.341 - ETA: 3:12 - loss: 0.8714 - accuracy: 0.3415 - recall_8: 0.3415 - precision_8: 0.341 - ETA: 3:12 - loss: 0.8710 - accuracy: 0.3417 - recall_8: 0.3417 - precision_8: 0.341 - ETA: 3:12 - loss: 0.8698 - accuracy: 0.3440 - recall_8: 0.3440 - precision_8: 0.344 - ETA: 3:11 - loss: 0.8693 - accuracy: 0.3423 - recall_8: 0.3423 - precision_8: 0.342 - ETA: 3:11 - loss: 0.8686 - accuracy: 0.3416 - recall_8: 0.3416 - precision_8: 0.341 - ETA: 3:11 - loss: 0.8677 - accuracy: 0.3429 - recall_8: 0.3429 - precision_8: 0.342 - ETA: 3:10 - loss: 0.8679 - accuracy: 0.3431 - recall_8: 0.3431 - precision_8: 0.343 - ETA: 3:10 - loss: 0.8679 - accuracy: 0.3443 - recall_8: 0.3443 - precision_8: 0.344 - ETA: 3:10 - loss: 0.8664 - accuracy: 0.3465 - recall_8: 0.3465 - precision_8: 0.346 - ETA: 3:10 - loss: 0.8657 - accuracy: 0.3467 - recall_8: 0.3467 - precision_8: 0.346 - ETA: 3:09 - loss: 0.8650 - accuracy: 0.3460 - recall_8: 0.3460 - precision_8: 0.346 - ETA: 3:09 - loss: 0.8640 - accuracy: 0.3472 - recall_8: 0.3472 - precision_8: 0.347 - ETA: 3:09 - loss: 0.8640 - accuracy: 0.3465 - recall_8: 0.3465 - precision_8: 0.346 - ETA: 3:09 - loss: 0.8641 - accuracy: 0.3468 - recall_8: 0.3468 - precision_8: 0.346 - ETA: 3:08 - loss: 0.8633 - accuracy: 0.3489 - recall_8: 0.3489 - precision_8: 0.348 - ETA: 3:08 - loss: 0.8626 - accuracy: 0.3482 - recall_8: 0.3482 - precision_8: 0.348 - ETA: 3:08 - loss: 0.8619 - accuracy: 0.3484 - recall_8: 0.3484 - precision_8: 0.348 - ETA: 3:07 - loss: 0.8611 - accuracy: 0.3477 - recall_8: 0.3477 - precision_8: 0.347 - ETA: 3:07 - loss: 0.8605 - accuracy: 0.3471 - recall_8: 0.3471 - precision_8: 0.347 - ETA: 3:07 - loss: 0.8598 - accuracy: 0.3464 - recall_8: 0.3464 - precision_8: 0.346 - ETA: 3:07 - loss: 0.8585 - accuracy: 0.3484 - recall_8: 0.3484 - precision_8: 0.348 - ETA: 3:06 - loss: 0.8591 - accuracy: 0.3487 - recall_8: 0.3487 - precision_8: 0.348 - ETA: 3:06 - loss: 0.8577 - accuracy: 0.3515 - recall_8: 0.3515 - precision_8: 0.351 - ETA: 3:06 - loss: 0.8564 - accuracy: 0.3535 - recall_8: 0.3535 - precision_8: 0.353 - ETA: 3:05 - loss: 0.8557 - accuracy: 0.3537 - recall_8: 0.3537 - precision_8: 0.353 - ETA: 3:05 - loss: 0.8548 - accuracy: 0.3539 - recall_8: 0.3539 - precision_8: 0.353 - ETA: 3:05 - loss: 0.8542 - accuracy: 0.3532 - recall_8: 0.3532 - precision_8: 0.353 - ETA: 3:05 - loss: 0.8530 - accuracy: 0.3552 - recall_8: 0.3552 - precision_8: 0.355 - ETA: 3:04 - loss: 0.8524 - accuracy: 0.3545 - recall_8: 0.3545 - precision_8: 0.354 - ETA: 3:04 - loss: 0.8518 - accuracy: 0.3530 - recall_8: 0.3530 - precision_8: 0.353 - ETA: 3:04 - loss: 0.8512 - accuracy: 0.3523 - recall_8: 0.3523 - precision_8: 0.352 - ETA: 3:03 - loss: 0.8505 - accuracy: 0.3525 - recall_8: 0.3525 - precision_8: 0.352 - ETA: 3:03 - loss: 0.8499 - accuracy: 0.3519 - recall_8: 0.3519 - precision_8: 0.351 - ETA: 3:03 - loss: 0.8492 - accuracy: 0.3529 - recall_8: 0.3529 - precision_8: 0.352 - ETA: 3:03 - loss: 0.8479 - accuracy: 0.3548 - recall_8: 0.3548 - precision_8: 0.354 - ETA: 3:02 - loss: 0.8478 - accuracy: 0.3550 - recall_8: 0.3550 - precision_8: 0.355 - ETA: 3:02 - loss: 0.8472 - accuracy: 0.3544 - recall_8: 0.3544 - precision_8: 0.354 - ETA: 3:02 - loss: 0.8460 - accuracy: 0.3562 - recall_8: 0.3562 - precision_8: 0.356 - ETA: 3:02 - loss: 0.8456 - accuracy: 0.3572 - recall_8: 0.3572 - precision_8: 0.357 - ETA: 3:01 - loss: 0.8445 - accuracy: 0.3590 - recall_8: 0.3590 - precision_8: 0.359 - ETA: 3:01 - loss: 0.8439 - accuracy: 0.3600 - recall_8: 0.3600 - precision_8: 0.360 - ETA: 3:01 - loss: 0.8433 - accuracy: 0.3593 - recall_8: 0.3593 - precision_8: 0.359 - ETA: 3:00 - loss: 0.8438 - accuracy: 0.3587 - recall_8: 0.3587 - precision_8: 0.358 - ETA: 3:00 - loss: 0.8432 - accuracy: 0.3581 - recall_8: 0.3581 - precision_8: 0.358 - ETA: 3:00 - loss: 0.8426 - accuracy: 0.3590 - recall_8: 0.3590 - precision_8: 0.359 - ETA: 3:00 - loss: 0.8425 - accuracy: 0.3592 - recall_8: 0.3592 - precision_8: 0.359 - ETA: 2:59 - loss: 0.8419 - accuracy: 0.3610 - recall_8: 0.3610 - precision_8: 0.361 - ETA: 2:59 - loss: 0.8413 - accuracy: 0.3635 - recall_8: 0.3635 - precision_8: 0.363 - ETA: 2:59 - loss: 0.8402 - accuracy: 0.3652 - recall_8: 0.3652 - precision_8: 0.365 - ETA: 2:58 - loss: 0.8391 - accuracy: 0.3669 - recall_8: 0.3669 - precision_8: 0.366 - ETA: 2:58 - loss: 0.8382 - accuracy: 0.3663 - recall_8: 0.3663 - precision_8: 0.366 - ETA: 2:58 - loss: 0.8376 - accuracy: 0.3664 - recall_8: 0.3664 - precision_8: 0.366 - ETA: 2:58 - loss: 0.8365 - accuracy: 0.3681 - recall_8: 0.3681 - precision_8: 0.368 - ETA: 2:57 - loss: 0.8359 - accuracy: 0.3698 - recall_8: 0.3698 - precision_8: 0.369 - ETA: 2:57 - loss: 0.8353 - accuracy: 0.3714 - recall_8: 0.3714 - precision_8: 0.371 - ETA: 2:57 - loss: 0.8342 - accuracy: 0.3731 - recall_8: 0.3731 - precision_8: 0.373 - ETA: 2:56 - loss: 0.8330 - accuracy: 0.3747 - recall_8: 0.3747 - precision_8: 0.374 - ETA: 2:56 - loss: 0.8324 - accuracy: 0.3771 - recall_8: 0.3771 - precision_8: 0.377 - ETA: 2:56 - loss: 0.8319 - accuracy: 0.3787 - recall_8: 0.3787 - precision_8: 0.378 - ETA: 2:56 - loss: 0.8313 - accuracy: 0.3795 - recall_8: 0.3795 - precision_8: 0.379 - ETA: 2:55 - loss: 0.8307 - accuracy: 0.3811 - recall_8: 0.3811 - precision_8: 0.381 - ETA: 2:55 - loss: 0.8302 - accuracy: 0.3827 - recall_8: 0.3827 - precision_8: 0.382 - ETA: 2:55 - loss: 0.8296 - accuracy: 0.3843 - recall_8: 0.3843 - precision_8: 0.384 - ETA: 2:55 - loss: 0.8285 - accuracy: 0.3858 - recall_8: 0.3858 - precision_8: 0.385 - ETA: 2:54 - loss: 0.8291 - accuracy: 0.3851 - recall_8: 0.3851 - precision_8: 0.385 - ETA: 2:54 - loss: 0.8285 - accuracy: 0.3874 - recall_8: 0.3874 - precision_8: 0.387 - ETA: 2:54 - loss: 0.8277 - accuracy: 0.3882 - recall_8: 0.3882 - precision_8: 0.388 - ETA: 2:53 - loss: 0.8267 - accuracy: 0.3897 - recall_8: 0.3897 - precision_8: 0.389 - ETA: 2:53 - loss: 0.8263 - accuracy: 0.3897 - recall_8: 0.3897 - precision_8: 0.389 - ETA: 2:53 - loss: 0.8261 - accuracy: 0.3905 - recall_8: 0.3905 - precision_8: 0.390 - ETA: 2:53 - loss: 0.8255 - accuracy: 0.3920 - recall_8: 0.3920 - precision_8: 0.392 - ETA: 2:52 - loss: 0.8249 - accuracy: 0.3928 - recall_8: 0.3928 - precision_8: 0.392 - ETA: 2:52 - loss: 0.8243 - accuracy: 0.3942 - recall_8: 0.3942 - precision_8: 0.394 - ETA: 2:52 - loss: 0.8237 - accuracy: 0.3957 - recall_8: 0.3957 - precision_8: 0.395 - ETA: 2:52 - loss: 0.8222 - accuracy: 0.3978 - recall_8: 0.3978 - precision_8: 0.397 - ETA: 2:51 - loss: 0.8215 - accuracy: 0.4000 - recall_8: 0.4000 - precision_8: 0.400 - ETA: 2:51 - loss: 0.8210 - accuracy: 0.4014 - recall_8: 0.4014 - precision_8: 0.401 - ETA: 2:51 - loss: 0.8207 - accuracy: 0.4007 - recall_8: 0.4007 - precision_8: 0.400 - ETA: 2:50 - loss: 0.8200 - accuracy: 0.4014 - recall_8: 0.4014 - precision_8: 0.401 - ETA: 2:50 - loss: 0.8196 - accuracy: 0.4021 - recall_8: 0.4021 - precision_8: 0.402 - ETA: 2:50 - loss: 0.8190 - accuracy: 0.4028 - recall_8: 0.4028 - precision_8: 0.4028"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/882 [===========>..................] - ETA: 2:50 - loss: 0.8184 - accuracy: 0.4049 - recall_8: 0.4049 - precision_8: 0.404 - ETA: 2:49 - loss: 0.8178 - accuracy: 0.4063 - recall_8: 0.4063 - precision_8: 0.406 - ETA: 2:49 - loss: 0.8172 - accuracy: 0.4069 - recall_8: 0.4069 - precision_8: 0.406 - ETA: 2:49 - loss: 0.8159 - accuracy: 0.4090 - recall_8: 0.4090 - precision_8: 0.409 - ETA: 2:48 - loss: 0.8155 - accuracy: 0.4097 - recall_8: 0.4097 - precision_8: 0.409 - ETA: 2:48 - loss: 0.8149 - accuracy: 0.4110 - recall_8: 0.4110 - precision_8: 0.411 - ETA: 2:48 - loss: 0.8136 - accuracy: 0.4130 - recall_8: 0.4130 - precision_8: 0.413 - ETA: 2:48 - loss: 0.8133 - accuracy: 0.4130 - recall_8: 0.4130 - precision_8: 0.413 - ETA: 2:47 - loss: 0.8128 - accuracy: 0.4143 - recall_8: 0.4143 - precision_8: 0.414 - ETA: 2:47 - loss: 0.8119 - accuracy: 0.4156 - recall_8: 0.4156 - precision_8: 0.415 - ETA: 2:47 - loss: 0.8109 - accuracy: 0.4169 - recall_8: 0.4169 - precision_8: 0.416 - ETA: 2:47 - loss: 0.8114 - accuracy: 0.4162 - recall_8: 0.4162 - precision_8: 0.416 - ETA: 2:46 - loss: 0.8112 - accuracy: 0.4168 - recall_8: 0.4168 - precision_8: 0.416 - ETA: 2:46 - loss: 0.8104 - accuracy: 0.4181 - recall_8: 0.4181 - precision_8: 0.418 - ETA: 2:46 - loss: 0.8107 - accuracy: 0.4180 - recall_8: 0.4180 - precision_8: 0.418 - ETA: 2:45 - loss: 0.8102 - accuracy: 0.4193 - recall_8: 0.4193 - precision_8: 0.419 - ETA: 2:45 - loss: 0.8099 - accuracy: 0.4192 - recall_8: 0.4192 - precision_8: 0.419 - ETA: 2:45 - loss: 0.8093 - accuracy: 0.4205 - recall_8: 0.4205 - precision_8: 0.420 - ETA: 2:45 - loss: 0.8082 - accuracy: 0.4217 - recall_8: 0.4217 - precision_8: 0.421 - ETA: 2:44 - loss: 0.8076 - accuracy: 0.4236 - recall_8: 0.4236 - precision_8: 0.423 - ETA: 2:44 - loss: 0.8060 - accuracy: 0.4255 - recall_8: 0.4255 - precision_8: 0.425 - ETA: 2:44 - loss: 0.8049 - accuracy: 0.4267 - recall_8: 0.4267 - precision_8: 0.426 - ETA: 2:43 - loss: 0.8047 - accuracy: 0.4260 - recall_8: 0.4260 - precision_8: 0.426 - ETA: 2:43 - loss: 0.8040 - accuracy: 0.4278 - recall_8: 0.4278 - precision_8: 0.427 - ETA: 2:43 - loss: 0.8035 - accuracy: 0.4284 - recall_8: 0.4284 - precision_8: 0.428 - ETA: 2:43 - loss: 0.8045 - accuracy: 0.4277 - recall_8: 0.4277 - precision_8: 0.427 - ETA: 2:42 - loss: 0.8040 - accuracy: 0.4288 - recall_8: 0.4288 - precision_8: 0.428 - ETA: 2:42 - loss: 0.8036 - accuracy: 0.4294 - recall_8: 0.4294 - precision_8: 0.429 - ETA: 2:42 - loss: 0.8031 - accuracy: 0.4306 - recall_8: 0.4306 - precision_8: 0.430 - ETA: 2:42 - loss: 0.8025 - accuracy: 0.4311 - recall_8: 0.4311 - precision_8: 0.431 - ETA: 2:41 - loss: 0.8028 - accuracy: 0.4310 - recall_8: 0.4310 - precision_8: 0.431 - ETA: 2:41 - loss: 0.8025 - accuracy: 0.4309 - recall_8: 0.4309 - precision_8: 0.430 - ETA: 2:41 - loss: 0.8016 - accuracy: 0.4321 - recall_8: 0.4321 - precision_8: 0.432 - ETA: 2:40 - loss: 0.8007 - accuracy: 0.4332 - recall_8: 0.4332 - precision_8: 0.433 - ETA: 2:40 - loss: 0.8002 - accuracy: 0.4344 - recall_8: 0.4344 - precision_8: 0.434 - ETA: 2:40 - loss: 0.7997 - accuracy: 0.4355 - recall_8: 0.4355 - precision_8: 0.435 - ETA: 2:40 - loss: 0.8012 - accuracy: 0.4354 - recall_8: 0.4354 - precision_8: 0.435 - ETA: 2:39 - loss: 0.8009 - accuracy: 0.4359 - recall_8: 0.4359 - precision_8: 0.435 - ETA: 2:39 - loss: 0.8002 - accuracy: 0.4377 - recall_8: 0.4377 - precision_8: 0.437 - ETA: 2:39 - loss: 0.7998 - accuracy: 0.4388 - recall_8: 0.4388 - precision_8: 0.438 - ETA: 2:39 - loss: 0.7997 - accuracy: 0.4387 - recall_8: 0.4387 - precision_8: 0.438 - ETA: 2:38 - loss: 0.7991 - accuracy: 0.4404 - recall_8: 0.4404 - precision_8: 0.440 - ETA: 2:38 - loss: 0.7986 - accuracy: 0.4415 - recall_8: 0.4415 - precision_8: 0.441 - ETA: 2:38 - loss: 0.7982 - accuracy: 0.4426 - recall_8: 0.4426 - precision_8: 0.442 - ETA: 2:38 - loss: 0.7980 - accuracy: 0.4418 - recall_8: 0.4418 - precision_8: 0.441 - ETA: 2:37 - loss: 0.7974 - accuracy: 0.4435 - recall_8: 0.4435 - precision_8: 0.443 - ETA: 2:37 - loss: 0.7968 - accuracy: 0.4452 - recall_8: 0.4452 - precision_8: 0.445 - ETA: 2:37 - loss: 0.7965 - accuracy: 0.4456 - recall_8: 0.4456 - precision_8: 0.445 - ETA: 2:36 - loss: 0.7959 - accuracy: 0.4473 - recall_8: 0.4473 - precision_8: 0.447 - ETA: 2:36 - loss: 0.7947 - accuracy: 0.4490 - recall_8: 0.4490 - precision_8: 0.449 - ETA: 2:36 - loss: 0.7936 - accuracy: 0.4500 - recall_8: 0.4500 - precision_8: 0.450 - ETA: 2:36 - loss: 0.7931 - accuracy: 0.4510 - recall_8: 0.4510 - precision_8: 0.451 - ETA: 2:35 - loss: 0.7925 - accuracy: 0.4527 - recall_8: 0.4527 - precision_8: 0.452 - ETA: 2:35 - loss: 0.7918 - accuracy: 0.4537 - recall_8: 0.4537 - precision_8: 0.453 - ETA: 2:35 - loss: 0.7916 - accuracy: 0.4535 - recall_8: 0.4535 - precision_8: 0.453 - ETA: 2:34 - loss: 0.7907 - accuracy: 0.4545 - recall_8: 0.4545 - precision_8: 0.454 - ETA: 2:34 - loss: 0.7902 - accuracy: 0.4556 - recall_8: 0.4556 - precision_8: 0.455 - ETA: 2:34 - loss: 0.7897 - accuracy: 0.4554 - recall_8: 0.4554 - precision_8: 0.455 - ETA: 2:34 - loss: 0.7894 - accuracy: 0.4558 - recall_8: 0.4558 - precision_8: 0.455 - ETA: 2:33 - loss: 0.7885 - accuracy: 0.4568 - recall_8: 0.4568 - precision_8: 0.456 - ETA: 2:33 - loss: 0.7882 - accuracy: 0.4572 - recall_8: 0.4572 - precision_8: 0.457 - ETA: 2:33 - loss: 0.7874 - accuracy: 0.4582 - recall_8: 0.4582 - precision_8: 0.458 - ETA: 2:33 - loss: 0.7871 - accuracy: 0.4586 - recall_8: 0.4586 - precision_8: 0.458 - ETA: 2:32 - loss: 0.7868 - accuracy: 0.4590 - recall_8: 0.4590 - precision_8: 0.459 - ETA: 2:32 - loss: 0.7864 - accuracy: 0.4594 - recall_8: 0.4594 - precision_8: 0.459 - ETA: 2:32 - loss: 0.7858 - accuracy: 0.4610 - recall_8: 0.4610 - precision_8: 0.461 - ETA: 2:31 - loss: 0.7864 - accuracy: 0.4602 - recall_8: 0.4602 - precision_8: 0.460 - ETA: 2:31 - loss: 0.7861 - accuracy: 0.4606 - recall_8: 0.4606 - precision_8: 0.460 - ETA: 2:31 - loss: 0.7856 - accuracy: 0.4616 - recall_8: 0.4616 - precision_8: 0.461 - ETA: 2:31 - loss: 0.7851 - accuracy: 0.4620 - recall_8: 0.4620 - precision_8: 0.462 - ETA: 2:30 - loss: 0.7847 - accuracy: 0.4624 - recall_8: 0.4624 - precision_8: 0.462 - ETA: 2:30 - loss: 0.7841 - accuracy: 0.4639 - recall_8: 0.4639 - precision_8: 0.463 - ETA: 2:30 - loss: 0.7838 - accuracy: 0.4642 - recall_8: 0.4642 - precision_8: 0.464 - ETA: 2:30 - loss: 0.7832 - accuracy: 0.4652 - recall_8: 0.4652 - precision_8: 0.465 - ETA: 2:29 - loss: 0.7827 - accuracy: 0.4661 - recall_8: 0.4661 - precision_8: 0.466 - ETA: 2:29 - loss: 0.7822 - accuracy: 0.4665 - recall_8: 0.4665 - precision_8: 0.466 - ETA: 2:29 - loss: 0.7811 - accuracy: 0.4680 - recall_8: 0.4680 - precision_8: 0.468 - ETA: 2:28 - loss: 0.7805 - accuracy: 0.4683 - recall_8: 0.4683 - precision_8: 0.468 - ETA: 2:28 - loss: 0.7801 - accuracy: 0.4687 - recall_8: 0.4687 - precision_8: 0.468 - ETA: 2:28 - loss: 0.7795 - accuracy: 0.4701 - recall_8: 0.4701 - precision_8: 0.470 - ETA: 2:28 - loss: 0.7794 - accuracy: 0.4699 - recall_8: 0.4699 - precision_8: 0.469 - ETA: 2:27 - loss: 0.7791 - accuracy: 0.4703 - recall_8: 0.4703 - precision_8: 0.470 - ETA: 2:27 - loss: 0.7787 - accuracy: 0.4712 - recall_8: 0.4712 - precision_8: 0.471 - ETA: 2:27 - loss: 0.7782 - accuracy: 0.4721 - recall_8: 0.4721 - precision_8: 0.472 - ETA: 2:27 - loss: 0.7771 - accuracy: 0.4735 - recall_8: 0.4735 - precision_8: 0.473 - ETA: 2:26 - loss: 0.7766 - accuracy: 0.4744 - recall_8: 0.4744 - precision_8: 0.474 - ETA: 2:26 - loss: 0.7762 - accuracy: 0.4753 - recall_8: 0.4753 - precision_8: 0.475 - ETA: 2:26 - loss: 0.7761 - accuracy: 0.4756 - recall_8: 0.4756 - precision_8: 0.475 - ETA: 2:25 - loss: 0.7759 - accuracy: 0.4759 - recall_8: 0.4759 - precision_8: 0.475 - ETA: 2:25 - loss: 0.7758 - accuracy: 0.4757 - recall_8: 0.4757 - precision_8: 0.475 - ETA: 2:25 - loss: 0.7752 - accuracy: 0.4771 - recall_8: 0.4771 - precision_8: 0.477 - ETA: 2:25 - loss: 0.7761 - accuracy: 0.4764 - recall_8: 0.4764 - precision_8: 0.476 - ETA: 2:24 - loss: 0.7769 - accuracy: 0.4762 - recall_8: 0.4762 - precision_8: 0.476 - ETA: 2:24 - loss: 0.7762 - accuracy: 0.4776 - recall_8: 0.4776 - precision_8: 0.477 - ETA: 2:24 - loss: 0.7765 - accuracy: 0.4774 - recall_8: 0.4774 - precision_8: 0.4774"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/882 [===============>..............] - ETA: 2:23 - loss: 0.7763 - accuracy: 0.4777 - recall_8: 0.4777 - precision_8: 0.477 - ETA: 2:23 - loss: 0.7763 - accuracy: 0.4770 - recall_8: 0.4770 - precision_8: 0.477 - ETA: 2:23 - loss: 0.7756 - accuracy: 0.4783 - recall_8: 0.4783 - precision_8: 0.478 - ETA: 2:23 - loss: 0.7774 - accuracy: 0.4781 - recall_8: 0.4781 - precision_8: 0.478 - ETA: 2:22 - loss: 0.7768 - accuracy: 0.4795 - recall_8: 0.4795 - precision_8: 0.479 - ETA: 2:22 - loss: 0.7763 - accuracy: 0.4803 - recall_8: 0.4803 - precision_8: 0.480 - ETA: 2:22 - loss: 0.7760 - accuracy: 0.4801 - recall_8: 0.4801 - precision_8: 0.480 - ETA: 2:21 - loss: 0.7757 - accuracy: 0.4799 - recall_8: 0.4799 - precision_8: 0.479 - ETA: 2:21 - loss: 0.7759 - accuracy: 0.4792 - recall_8: 0.4792 - precision_8: 0.479 - ETA: 2:21 - loss: 0.7755 - accuracy: 0.4800 - recall_8: 0.4800 - precision_8: 0.480 - ETA: 2:21 - loss: 0.7752 - accuracy: 0.4803 - recall_8: 0.4803 - precision_8: 0.480 - ETA: 2:20 - loss: 0.7746 - accuracy: 0.4816 - recall_8: 0.4816 - precision_8: 0.481 - ETA: 2:20 - loss: 0.7740 - accuracy: 0.4830 - recall_8: 0.4830 - precision_8: 0.483 - ETA: 2:20 - loss: 0.7736 - accuracy: 0.4838 - recall_8: 0.4838 - precision_8: 0.483 - ETA: 2:20 - loss: 0.7727 - accuracy: 0.4846 - recall_8: 0.4846 - precision_8: 0.484 - ETA: 2:19 - loss: 0.7723 - accuracy: 0.4848 - recall_8: 0.4848 - precision_8: 0.484 - ETA: 2:19 - loss: 0.7739 - accuracy: 0.4846 - recall_8: 0.4846 - precision_8: 0.484 - ETA: 2:19 - loss: 0.7733 - accuracy: 0.4859 - recall_8: 0.4859 - precision_8: 0.485 - ETA: 2:18 - loss: 0.7729 - accuracy: 0.4867 - recall_8: 0.4867 - precision_8: 0.486 - ETA: 2:18 - loss: 0.7724 - accuracy: 0.4870 - recall_8: 0.4870 - precision_8: 0.487 - ETA: 2:18 - loss: 0.7715 - accuracy: 0.4878 - recall_8: 0.4878 - precision_8: 0.487 - ETA: 2:18 - loss: 0.7736 - accuracy: 0.4871 - recall_8: 0.4871 - precision_8: 0.487 - ETA: 2:17 - loss: 0.7732 - accuracy: 0.4878 - recall_8: 0.4878 - precision_8: 0.487 - ETA: 2:17 - loss: 0.7727 - accuracy: 0.4886 - recall_8: 0.4886 - precision_8: 0.488 - ETA: 2:17 - loss: 0.7723 - accuracy: 0.4894 - recall_8: 0.4894 - precision_8: 0.489 - ETA: 2:16 - loss: 0.7720 - accuracy: 0.4897 - recall_8: 0.4897 - precision_8: 0.489 - ETA: 2:16 - loss: 0.7720 - accuracy: 0.4899 - recall_8: 0.4899 - precision_8: 0.489 - ETA: 2:16 - loss: 0.7714 - accuracy: 0.4912 - recall_8: 0.4912 - precision_8: 0.491 - ETA: 2:16 - loss: 0.7713 - accuracy: 0.4914 - recall_8: 0.4914 - precision_8: 0.491 - ETA: 2:15 - loss: 0.7709 - accuracy: 0.4922 - recall_8: 0.4922 - precision_8: 0.492 - ETA: 2:15 - loss: 0.7704 - accuracy: 0.4929 - recall_8: 0.4929 - precision_8: 0.492 - ETA: 2:15 - loss: 0.7704 - accuracy: 0.4932 - recall_8: 0.4932 - precision_8: 0.493 - ETA: 2:15 - loss: 0.7700 - accuracy: 0.4939 - recall_8: 0.4939 - precision_8: 0.493 - ETA: 2:14 - loss: 0.7696 - accuracy: 0.4947 - recall_8: 0.4947 - precision_8: 0.494 - ETA: 2:14 - loss: 0.7699 - accuracy: 0.4945 - recall_8: 0.4945 - precision_8: 0.494 - ETA: 2:14 - loss: 0.7694 - accuracy: 0.4947 - recall_8: 0.4947 - precision_8: 0.494 - ETA: 2:13 - loss: 0.7693 - accuracy: 0.4950 - recall_8: 0.4950 - precision_8: 0.495 - ETA: 2:13 - loss: 0.7688 - accuracy: 0.4957 - recall_8: 0.4957 - precision_8: 0.495 - ETA: 2:13 - loss: 0.7682 - accuracy: 0.4969 - recall_8: 0.4969 - precision_8: 0.496 - ETA: 2:13 - loss: 0.7684 - accuracy: 0.4962 - recall_8: 0.4962 - precision_8: 0.496 - ETA: 2:12 - loss: 0.7679 - accuracy: 0.4969 - recall_8: 0.4969 - precision_8: 0.496 - ETA: 2:12 - loss: 0.7677 - accuracy: 0.4972 - recall_8: 0.4972 - precision_8: 0.497 - ETA: 2:12 - loss: 0.7673 - accuracy: 0.4979 - recall_8: 0.4979 - precision_8: 0.497 - ETA: 2:12 - loss: 0.7663 - accuracy: 0.4991 - recall_8: 0.4991 - precision_8: 0.499 - ETA: 2:11 - loss: 0.7659 - accuracy: 0.4998 - recall_8: 0.4998 - precision_8: 0.499 - ETA: 2:11 - loss: 0.7657 - accuracy: 0.5000 - recall_8: 0.5000 - precision_8: 0.500 - ETA: 2:11 - loss: 0.7651 - accuracy: 0.5012 - recall_8: 0.5012 - precision_8: 0.501 - ETA: 2:10 - loss: 0.7645 - accuracy: 0.5023 - recall_8: 0.5023 - precision_8: 0.502 - ETA: 2:10 - loss: 0.7639 - accuracy: 0.5035 - recall_8: 0.5035 - precision_8: 0.503 - ETA: 2:10 - loss: 0.7633 - accuracy: 0.5047 - recall_8: 0.5047 - precision_8: 0.504 - ETA: 2:10 - loss: 0.7627 - accuracy: 0.5053 - recall_8: 0.5053 - precision_8: 0.505 - ETA: 2:09 - loss: 0.7621 - accuracy: 0.5065 - recall_8: 0.5065 - precision_8: 0.506 - ETA: 2:09 - loss: 0.7617 - accuracy: 0.5072 - recall_8: 0.5072 - precision_8: 0.507 - ETA: 2:09 - loss: 0.7618 - accuracy: 0.5074 - recall_8: 0.5074 - precision_8: 0.507 - ETA: 2:09 - loss: 0.7612 - accuracy: 0.5076 - recall_8: 0.5076 - precision_8: 0.507 - ETA: 2:08 - loss: 0.7606 - accuracy: 0.5087 - recall_8: 0.5087 - precision_8: 0.508 - ETA: 2:08 - loss: 0.7602 - accuracy: 0.5094 - recall_8: 0.5094 - precision_8: 0.509 - ETA: 2:08 - loss: 0.7598 - accuracy: 0.5100 - recall_8: 0.5100 - precision_8: 0.510 - ETA: 2:07 - loss: 0.7594 - accuracy: 0.5107 - recall_8: 0.5107 - precision_8: 0.510 - ETA: 2:07 - loss: 0.7594 - accuracy: 0.5105 - recall_8: 0.5105 - precision_8: 0.510 - ETA: 2:07 - loss: 0.7597 - accuracy: 0.5102 - recall_8: 0.5102 - precision_8: 0.510 - ETA: 2:07 - loss: 0.7590 - accuracy: 0.5113 - recall_8: 0.5113 - precision_8: 0.511 - ETA: 2:06 - loss: 0.7586 - accuracy: 0.5120 - recall_8: 0.5120 - precision_8: 0.512 - ETA: 2:06 - loss: 0.7580 - accuracy: 0.5131 - recall_8: 0.5131 - precision_8: 0.513 - ETA: 2:06 - loss: 0.7574 - accuracy: 0.5137 - recall_8: 0.5137 - precision_8: 0.513 - ETA: 2:05 - loss: 0.7578 - accuracy: 0.5135 - recall_8: 0.5135 - precision_8: 0.513 - ETA: 2:05 - loss: 0.7586 - accuracy: 0.5132 - recall_8: 0.5132 - precision_8: 0.513 - ETA: 2:05 - loss: 0.7583 - accuracy: 0.5134 - recall_8: 0.5134 - precision_8: 0.513 - ETA: 2:05 - loss: 0.7573 - accuracy: 0.5145 - recall_8: 0.5145 - precision_8: 0.514 - ETA: 2:04 - loss: 0.7563 - accuracy: 0.5156 - recall_8: 0.5156 - precision_8: 0.515 - ETA: 2:04 - loss: 0.7557 - accuracy: 0.5166 - recall_8: 0.5166 - precision_8: 0.516 - ETA: 2:04 - loss: 0.7551 - accuracy: 0.5173 - recall_8: 0.5173 - precision_8: 0.517 - ETA: 2:04 - loss: 0.7549 - accuracy: 0.5174 - recall_8: 0.5174 - precision_8: 0.517 - ETA: 2:03 - loss: 0.7548 - accuracy: 0.5176 - recall_8: 0.5176 - precision_8: 0.517 - ETA: 2:03 - loss: 0.7544 - accuracy: 0.5182 - recall_8: 0.5182 - precision_8: 0.518 - ETA: 2:03 - loss: 0.7544 - accuracy: 0.5184 - recall_8: 0.5184 - precision_8: 0.518 - ETA: 2:02 - loss: 0.7538 - accuracy: 0.5195 - recall_8: 0.5195 - precision_8: 0.519 - ETA: 2:02 - loss: 0.7541 - accuracy: 0.5192 - recall_8: 0.5192 - precision_8: 0.519 - ETA: 2:02 - loss: 0.7541 - accuracy: 0.5194 - recall_8: 0.5194 - precision_8: 0.519 - ETA: 2:02 - loss: 0.7539 - accuracy: 0.5196 - recall_8: 0.5196 - precision_8: 0.519 - ETA: 2:01 - loss: 0.7533 - accuracy: 0.5202 - recall_8: 0.5202 - precision_8: 0.520 - ETA: 2:01 - loss: 0.7532 - accuracy: 0.5203 - recall_8: 0.5203 - precision_8: 0.520 - ETA: 2:01 - loss: 0.7542 - accuracy: 0.5201 - recall_8: 0.5201 - precision_8: 0.520 - ETA: 2:01 - loss: 0.7532 - accuracy: 0.5211 - recall_8: 0.5211 - precision_8: 0.521 - ETA: 2:00 - loss: 0.7523 - accuracy: 0.5222 - recall_8: 0.5222 - precision_8: 0.522 - ETA: 2:00 - loss: 0.7518 - accuracy: 0.5227 - recall_8: 0.5227 - precision_8: 0.522 - ETA: 2:00 - loss: 0.7512 - accuracy: 0.5238 - recall_8: 0.5238 - precision_8: 0.523 - ETA: 1:59 - loss: 0.7510 - accuracy: 0.5239 - recall_8: 0.5239 - precision_8: 0.523 - ETA: 1:59 - loss: 0.7524 - accuracy: 0.5232 - recall_8: 0.5232 - precision_8: 0.523 - ETA: 1:59 - loss: 0.7520 - accuracy: 0.5238 - recall_8: 0.5238 - precision_8: 0.523 - ETA: 1:59 - loss: 0.7519 - accuracy: 0.5240 - recall_8: 0.5240 - precision_8: 0.524 - ETA: 1:58 - loss: 0.7517 - accuracy: 0.5242 - recall_8: 0.5242 - precision_8: 0.524 - ETA: 1:58 - loss: 0.7519 - accuracy: 0.5243 - recall_8: 0.5243 - precision_8: 0.524 - ETA: 1:58 - loss: 0.7519 - accuracy: 0.5241 - recall_8: 0.5241 - precision_8: 0.524 - ETA: 1:57 - loss: 0.7515 - accuracy: 0.5246 - recall_8: 0.5246 - precision_8: 0.5246"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/882 [==================>...........] - ETA: 1:57 - loss: 0.7513 - accuracy: 0.5239 - recall_8: 0.5239 - precision_8: 0.523 - ETA: 1:57 - loss: 0.7512 - accuracy: 0.5245 - recall_8: 0.5245 - precision_8: 0.524 - ETA: 1:57 - loss: 0.7514 - accuracy: 0.5243 - recall_8: 0.5243 - precision_8: 0.524 - ETA: 1:56 - loss: 0.7510 - accuracy: 0.5248 - recall_8: 0.5248 - precision_8: 0.524 - ETA: 1:56 - loss: 0.7508 - accuracy: 0.5254 - recall_8: 0.5254 - precision_8: 0.525 - ETA: 1:56 - loss: 0.7504 - accuracy: 0.5260 - recall_8: 0.5260 - precision_8: 0.526 - ETA: 1:56 - loss: 0.7503 - accuracy: 0.5261 - recall_8: 0.5261 - precision_8: 0.526 - ETA: 1:55 - loss: 0.7500 - accuracy: 0.5259 - recall_8: 0.5259 - precision_8: 0.525 - ETA: 1:55 - loss: 0.7494 - accuracy: 0.5269 - recall_8: 0.5269 - precision_8: 0.526 - ETA: 1:55 - loss: 0.7492 - accuracy: 0.5262 - recall_8: 0.5262 - precision_8: 0.526 - ETA: 1:54 - loss: 0.7495 - accuracy: 0.5259 - recall_8: 0.5259 - precision_8: 0.525 - ETA: 1:54 - loss: 0.7498 - accuracy: 0.5257 - recall_8: 0.5257 - precision_8: 0.525 - ETA: 1:54 - loss: 0.7505 - accuracy: 0.5250 - recall_8: 0.5250 - precision_8: 0.525 - ETA: 1:54 - loss: 0.7504 - accuracy: 0.5252 - recall_8: 0.5252 - precision_8: 0.525 - ETA: 1:53 - loss: 0.7517 - accuracy: 0.5241 - recall_8: 0.5241 - precision_8: 0.524 - ETA: 1:53 - loss: 0.7512 - accuracy: 0.5251 - recall_8: 0.5251 - precision_8: 0.525 - ETA: 1:53 - loss: 0.7510 - accuracy: 0.5248 - recall_8: 0.5248 - precision_8: 0.524 - ETA: 1:52 - loss: 0.7507 - accuracy: 0.5254 - recall_8: 0.5254 - precision_8: 0.525 - ETA: 1:52 - loss: 0.7505 - accuracy: 0.5255 - recall_8: 0.5255 - precision_8: 0.525 - ETA: 1:52 - loss: 0.7499 - accuracy: 0.5257 - recall_8: 0.5257 - precision_8: 0.525 - ETA: 1:52 - loss: 0.7491 - accuracy: 0.5266 - recall_8: 0.5266 - precision_8: 0.526 - ETA: 1:51 - loss: 0.7487 - accuracy: 0.5272 - recall_8: 0.5272 - precision_8: 0.527 - ETA: 1:51 - loss: 0.7482 - accuracy: 0.5277 - recall_8: 0.5277 - precision_8: 0.527 - ETA: 1:51 - loss: 0.7479 - accuracy: 0.5283 - recall_8: 0.5283 - precision_8: 0.528 - ETA: 1:51 - loss: 0.7477 - accuracy: 0.5284 - recall_8: 0.5284 - precision_8: 0.528 - ETA: 1:50 - loss: 0.7474 - accuracy: 0.5289 - recall_8: 0.5289 - precision_8: 0.528 - ETA: 1:50 - loss: 0.7470 - accuracy: 0.5295 - recall_8: 0.5295 - precision_8: 0.529 - ETA: 1:50 - loss: 0.7465 - accuracy: 0.5300 - recall_8: 0.5300 - precision_8: 0.530 - ETA: 1:49 - loss: 0.7458 - accuracy: 0.5306 - recall_8: 0.5306 - precision_8: 0.530 - ETA: 1:49 - loss: 0.7453 - accuracy: 0.5311 - recall_8: 0.5311 - precision_8: 0.531 - ETA: 1:49 - loss: 0.7450 - accuracy: 0.5316 - recall_8: 0.5316 - precision_8: 0.531 - ETA: 1:49 - loss: 0.7447 - accuracy: 0.5314 - recall_8: 0.5314 - precision_8: 0.531 - ETA: 1:48 - loss: 0.7444 - accuracy: 0.5319 - recall_8: 0.5319 - precision_8: 0.531 - ETA: 1:48 - loss: 0.7436 - accuracy: 0.5324 - recall_8: 0.5324 - precision_8: 0.532 - ETA: 1:48 - loss: 0.7428 - accuracy: 0.5333 - recall_8: 0.5333 - precision_8: 0.533 - ETA: 1:47 - loss: 0.7423 - accuracy: 0.5342 - recall_8: 0.5342 - precision_8: 0.534 - ETA: 1:47 - loss: 0.7421 - accuracy: 0.5344 - recall_8: 0.5344 - precision_8: 0.534 - ETA: 1:47 - loss: 0.7413 - accuracy: 0.5353 - recall_8: 0.5353 - precision_8: 0.535 - ETA: 1:47 - loss: 0.7406 - accuracy: 0.5358 - recall_8: 0.5358 - precision_8: 0.535 - ETA: 1:46 - loss: 0.7402 - accuracy: 0.5363 - recall_8: 0.5363 - precision_8: 0.536 - ETA: 1:46 - loss: 0.7399 - accuracy: 0.5368 - recall_8: 0.5368 - precision_8: 0.536 - ETA: 1:46 - loss: 0.7393 - accuracy: 0.5377 - recall_8: 0.5377 - precision_8: 0.537 - ETA: 1:45 - loss: 0.7390 - accuracy: 0.5382 - recall_8: 0.5382 - precision_8: 0.538 - ETA: 1:45 - loss: 0.7385 - accuracy: 0.5387 - recall_8: 0.5387 - precision_8: 0.538 - ETA: 1:45 - loss: 0.7384 - accuracy: 0.5388 - recall_8: 0.5388 - precision_8: 0.538 - ETA: 1:45 - loss: 0.7381 - accuracy: 0.5393 - recall_8: 0.5393 - precision_8: 0.539 - ETA: 1:44 - loss: 0.7379 - accuracy: 0.5395 - recall_8: 0.5395 - precision_8: 0.539 - ETA: 1:44 - loss: 0.7376 - accuracy: 0.5400 - recall_8: 0.5400 - precision_8: 0.540 - ETA: 1:44 - loss: 0.7377 - accuracy: 0.5397 - recall_8: 0.5397 - precision_8: 0.539 - ETA: 1:43 - loss: 0.7373 - accuracy: 0.5402 - recall_8: 0.5402 - precision_8: 0.540 - ETA: 1:43 - loss: 0.7368 - accuracy: 0.5411 - recall_8: 0.5411 - precision_8: 0.541 - ETA: 1:43 - loss: 0.7362 - accuracy: 0.5419 - recall_8: 0.5419 - precision_8: 0.541 - ETA: 1:43 - loss: 0.7363 - accuracy: 0.5413 - recall_8: 0.5413 - precision_8: 0.541 - ETA: 1:42 - loss: 0.7361 - accuracy: 0.5410 - recall_8: 0.5410 - precision_8: 0.541 - ETA: 1:42 - loss: 0.7352 - accuracy: 0.5419 - recall_8: 0.5419 - precision_8: 0.541 - ETA: 1:42 - loss: 0.7348 - accuracy: 0.5424 - recall_8: 0.5424 - precision_8: 0.542 - ETA: 1:41 - loss: 0.7343 - accuracy: 0.5432 - recall_8: 0.5432 - precision_8: 0.543 - ETA: 1:41 - loss: 0.7334 - accuracy: 0.5441 - recall_8: 0.5441 - precision_8: 0.544 - ETA: 1:41 - loss: 0.7338 - accuracy: 0.5438 - recall_8: 0.5438 - precision_8: 0.543 - ETA: 1:41 - loss: 0.7335 - accuracy: 0.5443 - recall_8: 0.5443 - precision_8: 0.544 - ETA: 1:40 - loss: 0.7338 - accuracy: 0.5440 - recall_8: 0.5440 - precision_8: 0.544 - ETA: 1:40 - loss: 0.7330 - accuracy: 0.5449 - recall_8: 0.5449 - precision_8: 0.544 - ETA: 1:40 - loss: 0.7324 - accuracy: 0.5454 - recall_8: 0.5454 - precision_8: 0.545 - ETA: 1:39 - loss: 0.7320 - accuracy: 0.5458 - recall_8: 0.5458 - precision_8: 0.545 - ETA: 1:39 - loss: 0.7313 - accuracy: 0.5463 - recall_8: 0.5463 - precision_8: 0.546 - ETA: 1:39 - loss: 0.7312 - accuracy: 0.5464 - recall_8: 0.5464 - precision_8: 0.546 - ETA: 1:39 - loss: 0.7307 - accuracy: 0.5472 - recall_8: 0.5472 - precision_8: 0.547 - ETA: 1:38 - loss: 0.7307 - accuracy: 0.5473 - recall_8: 0.5473 - precision_8: 0.547 - ETA: 1:38 - loss: 0.7306 - accuracy: 0.5474 - recall_8: 0.5474 - precision_8: 0.547 - ETA: 1:38 - loss: 0.7306 - accuracy: 0.5475 - recall_8: 0.5475 - precision_8: 0.547 - ETA: 1:37 - loss: 0.7301 - accuracy: 0.5484 - recall_8: 0.5484 - precision_8: 0.548 - ETA: 1:37 - loss: 0.7296 - accuracy: 0.5492 - recall_8: 0.5492 - precision_8: 0.549 - ETA: 1:37 - loss: 0.7295 - accuracy: 0.5493 - recall_8: 0.5493 - precision_8: 0.549 - ETA: 1:37 - loss: 0.7295 - accuracy: 0.5494 - recall_8: 0.5494 - precision_8: 0.549 - ETA: 1:36 - loss: 0.7294 - accuracy: 0.5495 - recall_8: 0.5495 - precision_8: 0.549 - ETA: 1:36 - loss: 0.7291 - accuracy: 0.5499 - recall_8: 0.5499 - precision_8: 0.549 - ETA: 1:36 - loss: 0.7288 - accuracy: 0.5500 - recall_8: 0.5500 - precision_8: 0.550 - ETA: 1:35 - loss: 0.7284 - accuracy: 0.5505 - recall_8: 0.5505 - precision_8: 0.550 - ETA: 1:35 - loss: 0.7281 - accuracy: 0.5509 - recall_8: 0.5509 - precision_8: 0.550 - ETA: 1:35 - loss: 0.7278 - accuracy: 0.5510 - recall_8: 0.5510 - precision_8: 0.551 - ETA: 1:35 - loss: 0.7271 - accuracy: 0.5518 - recall_8: 0.5518 - precision_8: 0.551 - ETA: 1:34 - loss: 0.7270 - accuracy: 0.5519 - recall_8: 0.5519 - precision_8: 0.551 - ETA: 1:34 - loss: 0.7265 - accuracy: 0.5527 - recall_8: 0.5527 - precision_8: 0.552 - ETA: 1:34 - loss: 0.7260 - accuracy: 0.5535 - recall_8: 0.5535 - precision_8: 0.553 - ETA: 1:33 - loss: 0.7254 - accuracy: 0.5543 - recall_8: 0.5543 - precision_8: 0.554 - ETA: 1:33 - loss: 0.7250 - accuracy: 0.5547 - recall_8: 0.5547 - precision_8: 0.554 - ETA: 1:33 - loss: 0.7251 - accuracy: 0.5548 - recall_8: 0.5548 - precision_8: 0.554 - ETA: 1:32 - loss: 0.7245 - accuracy: 0.5556 - recall_8: 0.5556 - precision_8: 0.555 - ETA: 1:32 - loss: 0.7248 - accuracy: 0.5553 - recall_8: 0.5553 - precision_8: 0.555 - ETA: 1:32 - loss: 0.7245 - accuracy: 0.5558 - recall_8: 0.5558 - precision_8: 0.555 - ETA: 1:32 - loss: 0.7240 - accuracy: 0.5565 - recall_8: 0.5565 - precision_8: 0.556 - ETA: 1:31 - loss: 0.7238 - accuracy: 0.5566 - recall_8: 0.5566 - precision_8: 0.556 - ETA: 1:31 - loss: 0.7237 - accuracy: 0.5567 - recall_8: 0.5567 - precision_8: 0.556 - ETA: 1:31 - loss: 0.7235 - accuracy: 0.5568 - recall_8: 0.5568 - precision_8: 0.556 - ETA: 1:30 - loss: 0.7237 - accuracy: 0.5568 - recall_8: 0.5568 - precision_8: 0.5568"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/882 [=====================>........] - ETA: 1:30 - loss: 0.7236 - accuracy: 0.5569 - recall_8: 0.5569 - precision_8: 0.556 - ETA: 1:30 - loss: 0.7241 - accuracy: 0.5566 - recall_8: 0.5566 - precision_8: 0.556 - ETA: 1:30 - loss: 0.7240 - accuracy: 0.5567 - recall_8: 0.5567 - precision_8: 0.556 - ETA: 1:29 - loss: 0.7237 - accuracy: 0.5571 - recall_8: 0.5571 - precision_8: 0.557 - ETA: 1:29 - loss: 0.7230 - accuracy: 0.5576 - recall_8: 0.5576 - precision_8: 0.557 - ETA: 1:29 - loss: 0.7227 - accuracy: 0.5580 - recall_8: 0.5580 - precision_8: 0.558 - ETA: 1:28 - loss: 0.7219 - accuracy: 0.5588 - recall_8: 0.5588 - precision_8: 0.558 - ETA: 1:28 - loss: 0.7221 - accuracy: 0.5585 - recall_8: 0.5585 - precision_8: 0.558 - ETA: 1:28 - loss: 0.7220 - accuracy: 0.5585 - recall_8: 0.5585 - precision_8: 0.558 - ETA: 1:28 - loss: 0.7215 - accuracy: 0.5593 - recall_8: 0.5593 - precision_8: 0.559 - ETA: 1:27 - loss: 0.7213 - accuracy: 0.5594 - recall_8: 0.5594 - precision_8: 0.559 - ETA: 1:27 - loss: 0.7207 - accuracy: 0.5598 - recall_8: 0.5598 - precision_8: 0.559 - ETA: 1:27 - loss: 0.7199 - accuracy: 0.5605 - recall_8: 0.5605 - precision_8: 0.560 - ETA: 1:26 - loss: 0.7194 - accuracy: 0.5613 - recall_8: 0.5613 - precision_8: 0.561 - ETA: 1:26 - loss: 0.7187 - accuracy: 0.5617 - recall_8: 0.5617 - precision_8: 0.561 - ETA: 1:26 - loss: 0.7184 - accuracy: 0.5621 - recall_8: 0.5621 - precision_8: 0.562 - ETA: 1:26 - loss: 0.7187 - accuracy: 0.5618 - recall_8: 0.5618 - precision_8: 0.561 - ETA: 1:25 - loss: 0.7179 - accuracy: 0.5626 - recall_8: 0.5626 - precision_8: 0.562 - ETA: 1:25 - loss: 0.7179 - accuracy: 0.5626 - recall_8: 0.5626 - precision_8: 0.562 - ETA: 1:25 - loss: 0.7183 - accuracy: 0.5624 - recall_8: 0.5624 - precision_8: 0.562 - ETA: 1:24 - loss: 0.7182 - accuracy: 0.5624 - recall_8: 0.5624 - precision_8: 0.562 - ETA: 1:24 - loss: 0.7181 - accuracy: 0.5625 - recall_8: 0.5625 - precision_8: 0.562 - ETA: 1:24 - loss: 0.7178 - accuracy: 0.5629 - recall_8: 0.5629 - precision_8: 0.562 - ETA: 1:24 - loss: 0.7175 - accuracy: 0.5633 - recall_8: 0.5633 - precision_8: 0.563 - ETA: 1:23 - loss: 0.7176 - accuracy: 0.5634 - recall_8: 0.5634 - precision_8: 0.563 - ETA: 1:23 - loss: 0.7175 - accuracy: 0.5634 - recall_8: 0.5634 - precision_8: 0.563 - ETA: 1:23 - loss: 0.7174 - accuracy: 0.5635 - recall_8: 0.5635 - precision_8: 0.563 - ETA: 1:22 - loss: 0.7169 - accuracy: 0.5642 - recall_8: 0.5642 - precision_8: 0.564 - ETA: 1:22 - loss: 0.7173 - accuracy: 0.5639 - recall_8: 0.5639 - precision_8: 0.563 - ETA: 1:22 - loss: 0.7165 - accuracy: 0.5647 - recall_8: 0.5647 - precision_8: 0.564 - ETA: 1:22 - loss: 0.7162 - accuracy: 0.5651 - recall_8: 0.5651 - precision_8: 0.565 - ETA: 1:21 - loss: 0.7155 - accuracy: 0.5654 - recall_8: 0.5654 - precision_8: 0.565 - ETA: 1:21 - loss: 0.7155 - accuracy: 0.5655 - recall_8: 0.5655 - precision_8: 0.565 - ETA: 1:21 - loss: 0.7150 - accuracy: 0.5662 - recall_8: 0.5662 - precision_8: 0.566 - ETA: 1:20 - loss: 0.7147 - accuracy: 0.5666 - recall_8: 0.5666 - precision_8: 0.566 - ETA: 1:20 - loss: 0.7140 - accuracy: 0.5670 - recall_8: 0.5670 - precision_8: 0.567 - ETA: 1:20 - loss: 0.7144 - accuracy: 0.5664 - recall_8: 0.5664 - precision_8: 0.566 - ETA: 1:20 - loss: 0.7138 - accuracy: 0.5668 - recall_8: 0.5668 - precision_8: 0.566 - ETA: 1:19 - loss: 0.7132 - accuracy: 0.5672 - recall_8: 0.5672 - precision_8: 0.567 - ETA: 1:19 - loss: 0.7127 - accuracy: 0.5679 - recall_8: 0.5679 - precision_8: 0.567 - ETA: 1:19 - loss: 0.7127 - accuracy: 0.5679 - recall_8: 0.5679 - precision_8: 0.567 - ETA: 1:18 - loss: 0.7121 - accuracy: 0.5686 - recall_8: 0.5686 - precision_8: 0.568 - ETA: 1:18 - loss: 0.7119 - accuracy: 0.5690 - recall_8: 0.5690 - precision_8: 0.569 - ETA: 1:18 - loss: 0.7120 - accuracy: 0.5691 - recall_8: 0.5691 - precision_8: 0.569 - ETA: 1:17 - loss: 0.7119 - accuracy: 0.5691 - recall_8: 0.5691 - precision_8: 0.569 - ETA: 1:17 - loss: 0.7123 - accuracy: 0.5688 - recall_8: 0.5688 - precision_8: 0.568 - ETA: 1:17 - loss: 0.7122 - accuracy: 0.5689 - recall_8: 0.5689 - precision_8: 0.568 - ETA: 1:17 - loss: 0.7119 - accuracy: 0.5693 - recall_8: 0.5693 - precision_8: 0.569 - ETA: 1:16 - loss: 0.7119 - accuracy: 0.5693 - recall_8: 0.5693 - precision_8: 0.569 - ETA: 1:16 - loss: 0.7118 - accuracy: 0.5694 - recall_8: 0.5694 - precision_8: 0.569 - ETA: 1:16 - loss: 0.7116 - accuracy: 0.5697 - recall_8: 0.5697 - precision_8: 0.569 - ETA: 1:15 - loss: 0.7111 - accuracy: 0.5704 - recall_8: 0.5704 - precision_8: 0.570 - ETA: 1:15 - loss: 0.7110 - accuracy: 0.5705 - recall_8: 0.5705 - precision_8: 0.570 - ETA: 1:15 - loss: 0.7108 - accuracy: 0.5708 - recall_8: 0.5708 - precision_8: 0.570 - ETA: 1:15 - loss: 0.7100 - accuracy: 0.5715 - recall_8: 0.5715 - precision_8: 0.571 - ETA: 1:14 - loss: 0.7097 - accuracy: 0.5719 - recall_8: 0.5719 - precision_8: 0.571 - ETA: 1:14 - loss: 0.7090 - accuracy: 0.5726 - recall_8: 0.5726 - precision_8: 0.572 - ETA: 1:14 - loss: 0.7085 - accuracy: 0.5732 - recall_8: 0.5732 - precision_8: 0.573 - ETA: 1:13 - loss: 0.7082 - accuracy: 0.5736 - recall_8: 0.5736 - precision_8: 0.573 - ETA: 1:13 - loss: 0.7082 - accuracy: 0.5737 - recall_8: 0.5737 - precision_8: 0.573 - ETA: 1:13 - loss: 0.7080 - accuracy: 0.5740 - recall_8: 0.5740 - precision_8: 0.574 - ETA: 1:13 - loss: 0.7080 - accuracy: 0.5741 - recall_8: 0.5741 - precision_8: 0.574 - ETA: 1:12 - loss: 0.7072 - accuracy: 0.5747 - recall_8: 0.5747 - precision_8: 0.574 - ETA: 1:12 - loss: 0.7072 - accuracy: 0.5748 - recall_8: 0.5748 - precision_8: 0.574 - ETA: 1:12 - loss: 0.7069 - accuracy: 0.5751 - recall_8: 0.5751 - precision_8: 0.575 - ETA: 1:11 - loss: 0.7062 - accuracy: 0.5758 - recall_8: 0.5758 - precision_8: 0.575 - ETA: 1:11 - loss: 0.7059 - accuracy: 0.5761 - recall_8: 0.5761 - precision_8: 0.576 - ETA: 1:11 - loss: 0.7056 - accuracy: 0.5765 - recall_8: 0.5765 - precision_8: 0.576 - ETA: 1:11 - loss: 0.7056 - accuracy: 0.5765 - recall_8: 0.5765 - precision_8: 0.576 - ETA: 1:10 - loss: 0.7059 - accuracy: 0.5766 - recall_8: 0.5766 - precision_8: 0.576 - ETA: 1:10 - loss: 0.7056 - accuracy: 0.5769 - recall_8: 0.5769 - precision_8: 0.576 - ETA: 1:10 - loss: 0.7049 - accuracy: 0.5776 - recall_8: 0.5776 - precision_8: 0.577 - ETA: 1:09 - loss: 0.7046 - accuracy: 0.5779 - recall_8: 0.5779 - precision_8: 0.577 - ETA: 1:09 - loss: 0.7048 - accuracy: 0.5780 - recall_8: 0.5780 - precision_8: 0.578 - ETA: 1:09 - loss: 0.7045 - accuracy: 0.5783 - recall_8: 0.5783 - precision_8: 0.578 - ETA: 1:09 - loss: 0.7044 - accuracy: 0.5783 - recall_8: 0.5783 - precision_8: 0.578 - ETA: 1:08 - loss: 0.7038 - accuracy: 0.5790 - recall_8: 0.5790 - precision_8: 0.579 - ETA: 1:08 - loss: 0.7037 - accuracy: 0.5790 - recall_8: 0.5790 - precision_8: 0.579 - ETA: 1:08 - loss: 0.7032 - accuracy: 0.5797 - recall_8: 0.5797 - precision_8: 0.579 - ETA: 1:07 - loss: 0.7030 - accuracy: 0.5800 - recall_8: 0.5800 - precision_8: 0.580 - ETA: 1:07 - loss: 0.7027 - accuracy: 0.5803 - recall_8: 0.5803 - precision_8: 0.580 - ETA: 1:07 - loss: 0.7024 - accuracy: 0.5807 - recall_8: 0.5807 - precision_8: 0.580 - ETA: 1:06 - loss: 0.7022 - accuracy: 0.5810 - recall_8: 0.5810 - precision_8: 0.581 - ETA: 1:06 - loss: 0.7014 - accuracy: 0.5817 - recall_8: 0.5817 - precision_8: 0.581 - ETA: 1:06 - loss: 0.7012 - accuracy: 0.5820 - recall_8: 0.5820 - precision_8: 0.582 - ETA: 1:06 - loss: 0.7011 - accuracy: 0.5820 - recall_8: 0.5820 - precision_8: 0.582 - ETA: 1:05 - loss: 0.7009 - accuracy: 0.5823 - recall_8: 0.5823 - precision_8: 0.582 - ETA: 1:05 - loss: 0.7008 - accuracy: 0.5824 - recall_8: 0.5824 - precision_8: 0.582 - ETA: 1:05 - loss: 0.7004 - accuracy: 0.5827 - recall_8: 0.5827 - precision_8: 0.582 - ETA: 1:04 - loss: 0.7000 - accuracy: 0.5833 - recall_8: 0.5833 - precision_8: 0.583 - ETA: 1:04 - loss: 0.6995 - accuracy: 0.5840 - recall_8: 0.5840 - precision_8: 0.584 - ETA: 1:04 - loss: 0.6996 - accuracy: 0.5840 - recall_8: 0.5840 - precision_8: 0.584 - ETA: 1:04 - loss: 0.6989 - accuracy: 0.5846 - recall_8: 0.5846 - precision_8: 0.584 - ETA: 1:03 - loss: 0.6984 - accuracy: 0.5852 - recall_8: 0.5852 - precision_8: 0.585 - ETA: 1:03 - loss: 0.6984 - accuracy: 0.5853 - recall_8: 0.5853 - precision_8: 0.5853"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/882 [========================>.....] - ETA: 1:03 - loss: 0.6981 - accuracy: 0.5856 - recall_8: 0.5856 - precision_8: 0.585 - ETA: 1:02 - loss: 0.6979 - accuracy: 0.5859 - recall_8: 0.5859 - precision_8: 0.585 - ETA: 1:02 - loss: 0.6980 - accuracy: 0.5859 - recall_8: 0.5859 - precision_8: 0.585 - ETA: 1:02 - loss: 0.6976 - accuracy: 0.5865 - recall_8: 0.5865 - precision_8: 0.586 - ETA: 1:02 - loss: 0.6970 - accuracy: 0.5872 - recall_8: 0.5872 - precision_8: 0.587 - ETA: 1:01 - loss: 0.6967 - accuracy: 0.5875 - recall_8: 0.5875 - precision_8: 0.587 - ETA: 1:01 - loss: 0.6962 - accuracy: 0.5881 - recall_8: 0.5881 - precision_8: 0.588 - ETA: 1:01 - loss: 0.6958 - accuracy: 0.5887 - recall_8: 0.5887 - precision_8: 0.588 - ETA: 1:00 - loss: 0.6951 - accuracy: 0.5893 - recall_8: 0.5893 - precision_8: 0.589 - ETA: 1:00 - loss: 0.6959 - accuracy: 0.5887 - recall_8: 0.5887 - precision_8: 0.588 - ETA: 1:00 - loss: 0.6958 - accuracy: 0.5888 - recall_8: 0.5888 - precision_8: 0.588 - ETA: 1:00 - loss: 0.6958 - accuracy: 0.5888 - recall_8: 0.5888 - precision_8: 0.588 - ETA: 59s - loss: 0.6958 - accuracy: 0.5888 - recall_8: 0.5888 - precision_8: 0.588 - ETA: 59s - loss: 0.6952 - accuracy: 0.5894 - recall_8: 0.5894 - precision_8: 0.58 - ETA: 59s - loss: 0.6946 - accuracy: 0.5900 - recall_8: 0.5900 - precision_8: 0.59 - ETA: 58s - loss: 0.6943 - accuracy: 0.5903 - recall_8: 0.5903 - precision_8: 0.59 - ETA: 58s - loss: 0.6943 - accuracy: 0.5903 - recall_8: 0.5903 - precision_8: 0.59 - ETA: 58s - loss: 0.6940 - accuracy: 0.5906 - recall_8: 0.5906 - precision_8: 0.59 - ETA: 57s - loss: 0.6938 - accuracy: 0.5909 - recall_8: 0.5909 - precision_8: 0.59 - ETA: 57s - loss: 0.6938 - accuracy: 0.5909 - recall_8: 0.5909 - precision_8: 0.59 - ETA: 57s - loss: 0.6938 - accuracy: 0.5910 - recall_8: 0.5910 - precision_8: 0.59 - ETA: 57s - loss: 0.6936 - accuracy: 0.5913 - recall_8: 0.5913 - precision_8: 0.59 - ETA: 56s - loss: 0.6936 - accuracy: 0.5913 - recall_8: 0.5913 - precision_8: 0.59 - ETA: 56s - loss: 0.6933 - accuracy: 0.5916 - recall_8: 0.5916 - precision_8: 0.59 - ETA: 56s - loss: 0.6929 - accuracy: 0.5922 - recall_8: 0.5922 - precision_8: 0.59 - ETA: 55s - loss: 0.6926 - accuracy: 0.5925 - recall_8: 0.5925 - precision_8: 0.59 - ETA: 55s - loss: 0.6919 - accuracy: 0.5931 - recall_8: 0.5931 - precision_8: 0.59 - ETA: 55s - loss: 0.6920 - accuracy: 0.5931 - recall_8: 0.5931 - precision_8: 0.59 - ETA: 55s - loss: 0.6922 - accuracy: 0.5928 - recall_8: 0.5928 - precision_8: 0.59 - ETA: 54s - loss: 0.6920 - accuracy: 0.5931 - recall_8: 0.5931 - precision_8: 0.59 - ETA: 54s - loss: 0.6916 - accuracy: 0.5934 - recall_8: 0.5934 - precision_8: 0.59 - ETA: 54s - loss: 0.6911 - accuracy: 0.5937 - recall_8: 0.5937 - precision_8: 0.59 - ETA: 53s - loss: 0.6911 - accuracy: 0.5937 - recall_8: 0.5937 - precision_8: 0.59 - ETA: 53s - loss: 0.6923 - accuracy: 0.5931 - recall_8: 0.5931 - precision_8: 0.59 - ETA: 53s - loss: 0.6918 - accuracy: 0.5937 - recall_8: 0.5937 - precision_8: 0.59 - ETA: 53s - loss: 0.6916 - accuracy: 0.5940 - recall_8: 0.5940 - precision_8: 0.59 - ETA: 52s - loss: 0.6912 - accuracy: 0.5946 - recall_8: 0.5946 - precision_8: 0.59 - ETA: 52s - loss: 0.6913 - accuracy: 0.5946 - recall_8: 0.5946 - precision_8: 0.59 - ETA: 52s - loss: 0.6911 - accuracy: 0.5949 - recall_8: 0.5949 - precision_8: 0.59 - ETA: 51s - loss: 0.6908 - accuracy: 0.5952 - recall_8: 0.5952 - precision_8: 0.59 - ETA: 51s - loss: 0.6902 - accuracy: 0.5958 - recall_8: 0.5958 - precision_8: 0.59 - ETA: 51s - loss: 0.6899 - accuracy: 0.5960 - recall_8: 0.5960 - precision_8: 0.59 - ETA: 50s - loss: 0.6897 - accuracy: 0.5963 - recall_8: 0.5963 - precision_8: 0.59 - ETA: 50s - loss: 0.6898 - accuracy: 0.5963 - recall_8: 0.5963 - precision_8: 0.59 - ETA: 50s - loss: 0.6896 - accuracy: 0.5966 - recall_8: 0.5966 - precision_8: 0.59 - ETA: 50s - loss: 0.6891 - accuracy: 0.5972 - recall_8: 0.5972 - precision_8: 0.59 - ETA: 49s - loss: 0.6893 - accuracy: 0.5969 - recall_8: 0.5969 - precision_8: 0.59 - ETA: 49s - loss: 0.6891 - accuracy: 0.5972 - recall_8: 0.5972 - precision_8: 0.59 - ETA: 49s - loss: 0.6889 - accuracy: 0.5975 - recall_8: 0.5975 - precision_8: 0.59 - ETA: 48s - loss: 0.6886 - accuracy: 0.5978 - recall_8: 0.5978 - precision_8: 0.59 - ETA: 48s - loss: 0.6879 - accuracy: 0.5983 - recall_8: 0.5983 - precision_8: 0.59 - ETA: 48s - loss: 0.6875 - accuracy: 0.5989 - recall_8: 0.5989 - precision_8: 0.59 - ETA: 48s - loss: 0.6872 - accuracy: 0.5992 - recall_8: 0.5992 - precision_8: 0.59 - ETA: 47s - loss: 0.6868 - accuracy: 0.5997 - recall_8: 0.5997 - precision_8: 0.59 - ETA: 47s - loss: 0.6865 - accuracy: 0.6000 - recall_8: 0.6000 - precision_8: 0.60 - ETA: 47s - loss: 0.6860 - accuracy: 0.6003 - recall_8: 0.6003 - precision_8: 0.60 - ETA: 46s - loss: 0.6856 - accuracy: 0.6008 - recall_8: 0.6008 - precision_8: 0.60 - ETA: 46s - loss: 0.6853 - accuracy: 0.6011 - recall_8: 0.6011 - precision_8: 0.60 - ETA: 46s - loss: 0.6851 - accuracy: 0.6014 - recall_8: 0.6014 - precision_8: 0.60 - ETA: 46s - loss: 0.6844 - accuracy: 0.6019 - recall_8: 0.6019 - precision_8: 0.60 - ETA: 45s - loss: 0.6838 - accuracy: 0.6025 - recall_8: 0.6025 - precision_8: 0.60 - ETA: 45s - loss: 0.6831 - accuracy: 0.6030 - recall_8: 0.6030 - precision_8: 0.60 - ETA: 45s - loss: 0.6827 - accuracy: 0.6036 - recall_8: 0.6036 - precision_8: 0.60 - ETA: 44s - loss: 0.6825 - accuracy: 0.6038 - recall_8: 0.6038 - precision_8: 0.60 - ETA: 44s - loss: 0.6823 - accuracy: 0.6041 - recall_8: 0.6041 - precision_8: 0.60 - ETA: 44s - loss: 0.6821 - accuracy: 0.6044 - recall_8: 0.6044 - precision_8: 0.60 - ETA: 43s - loss: 0.6821 - accuracy: 0.6044 - recall_8: 0.6044 - precision_8: 0.60 - ETA: 43s - loss: 0.6816 - accuracy: 0.6049 - recall_8: 0.6049 - precision_8: 0.60 - ETA: 43s - loss: 0.6814 - accuracy: 0.6052 - recall_8: 0.6052 - precision_8: 0.60 - ETA: 43s - loss: 0.6814 - accuracy: 0.6052 - recall_8: 0.6052 - precision_8: 0.60 - ETA: 42s - loss: 0.6813 - accuracy: 0.6054 - recall_8: 0.6054 - precision_8: 0.60 - ETA: 42s - loss: 0.6806 - accuracy: 0.6060 - recall_8: 0.6060 - precision_8: 0.60 - ETA: 42s - loss: 0.6804 - accuracy: 0.6062 - recall_8: 0.6062 - precision_8: 0.60 - ETA: 41s - loss: 0.6804 - accuracy: 0.6062 - recall_8: 0.6062 - precision_8: 0.60 - ETA: 41s - loss: 0.6805 - accuracy: 0.6062 - recall_8: 0.6062 - precision_8: 0.60 - ETA: 41s - loss: 0.6802 - accuracy: 0.6065 - recall_8: 0.6065 - precision_8: 0.60 - ETA: 41s - loss: 0.6799 - accuracy: 0.6067 - recall_8: 0.6067 - precision_8: 0.60 - ETA: 40s - loss: 0.6796 - accuracy: 0.6070 - recall_8: 0.6070 - precision_8: 0.60 - ETA: 40s - loss: 0.6793 - accuracy: 0.6073 - recall_8: 0.6073 - precision_8: 0.60 - ETA: 40s - loss: 0.6795 - accuracy: 0.6072 - recall_8: 0.6072 - precision_8: 0.60 - ETA: 39s - loss: 0.6790 - accuracy: 0.6078 - recall_8: 0.6078 - precision_8: 0.60 - ETA: 39s - loss: 0.6786 - accuracy: 0.6083 - recall_8: 0.6083 - precision_8: 0.60 - ETA: 39s - loss: 0.6784 - accuracy: 0.6086 - recall_8: 0.6086 - precision_8: 0.60 - ETA: 39s - loss: 0.6784 - accuracy: 0.6085 - recall_8: 0.6085 - precision_8: 0.60 - ETA: 38s - loss: 0.6782 - accuracy: 0.6088 - recall_8: 0.6088 - precision_8: 0.60 - ETA: 38s - loss: 0.6779 - accuracy: 0.6091 - recall_8: 0.6091 - precision_8: 0.60 - ETA: 38s - loss: 0.6777 - accuracy: 0.6093 - recall_8: 0.6093 - precision_8: 0.60 - ETA: 37s - loss: 0.6772 - accuracy: 0.6098 - recall_8: 0.6098 - precision_8: 0.60 - ETA: 37s - loss: 0.6767 - accuracy: 0.6103 - recall_8: 0.6103 - precision_8: 0.61 - ETA: 37s - loss: 0.6765 - accuracy: 0.6106 - recall_8: 0.6106 - precision_8: 0.61 - ETA: 36s - loss: 0.6763 - accuracy: 0.6108 - recall_8: 0.6108 - precision_8: 0.61 - ETA: 36s - loss: 0.6760 - accuracy: 0.6111 - recall_8: 0.6111 - precision_8: 0.61 - ETA: 36s - loss: 0.6761 - accuracy: 0.6111 - recall_8: 0.6111 - precision_8: 0.61 - ETA: 36s - loss: 0.6759 - accuracy: 0.6113 - recall_8: 0.6113 - precision_8: 0.61 - ETA: 35s - loss: 0.6761 - accuracy: 0.6111 - recall_8: 0.6111 - precision_8: 0.61 - ETA: 35s - loss: 0.6759 - accuracy: 0.6113 - recall_8: 0.6113 - precision_8: 0.61 - ETA: 35s - loss: 0.6759 - accuracy: 0.6113 - recall_8: 0.6113 - precision_8: 0.6113"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/882 [============================>.] - ETA: 34s - loss: 0.6753 - accuracy: 0.6118 - recall_8: 0.6118 - precision_8: 0.61 - ETA: 34s - loss: 0.6747 - accuracy: 0.6123 - recall_8: 0.6123 - precision_8: 0.61 - ETA: 34s - loss: 0.6745 - accuracy: 0.6125 - recall_8: 0.6125 - precision_8: 0.61 - ETA: 34s - loss: 0.6739 - accuracy: 0.6131 - recall_8: 0.6131 - precision_8: 0.61 - ETA: 33s - loss: 0.6745 - accuracy: 0.6128 - recall_8: 0.6128 - precision_8: 0.61 - ETA: 33s - loss: 0.6746 - accuracy: 0.6128 - recall_8: 0.6128 - precision_8: 0.61 - ETA: 33s - loss: 0.6740 - accuracy: 0.6133 - recall_8: 0.6133 - precision_8: 0.61 - ETA: 32s - loss: 0.6742 - accuracy: 0.6130 - recall_8: 0.6130 - precision_8: 0.61 - ETA: 32s - loss: 0.6738 - accuracy: 0.6135 - recall_8: 0.6135 - precision_8: 0.61 - ETA: 32s - loss: 0.6739 - accuracy: 0.6135 - recall_8: 0.6135 - precision_8: 0.61 - ETA: 32s - loss: 0.6734 - accuracy: 0.6140 - recall_8: 0.6140 - precision_8: 0.61 - ETA: 31s - loss: 0.6729 - accuracy: 0.6145 - recall_8: 0.6145 - precision_8: 0.61 - ETA: 31s - loss: 0.6727 - accuracy: 0.6147 - recall_8: 0.6147 - precision_8: 0.61 - ETA: 31s - loss: 0.6725 - accuracy: 0.6149 - recall_8: 0.6149 - precision_8: 0.61 - ETA: 30s - loss: 0.6727 - accuracy: 0.6149 - recall_8: 0.6149 - precision_8: 0.61 - ETA: 30s - loss: 0.6721 - accuracy: 0.6154 - recall_8: 0.6154 - precision_8: 0.61 - ETA: 30s - loss: 0.6715 - accuracy: 0.6159 - recall_8: 0.6159 - precision_8: 0.61 - ETA: 29s - loss: 0.6713 - accuracy: 0.6162 - recall_8: 0.6162 - precision_8: 0.61 - ETA: 29s - loss: 0.6711 - accuracy: 0.6164 - recall_8: 0.6164 - precision_8: 0.61 - ETA: 29s - loss: 0.6712 - accuracy: 0.6164 - recall_8: 0.6164 - precision_8: 0.61 - ETA: 29s - loss: 0.6710 - accuracy: 0.6166 - recall_8: 0.6166 - precision_8: 0.61 - ETA: 28s - loss: 0.6704 - accuracy: 0.6171 - recall_8: 0.6171 - precision_8: 0.61 - ETA: 28s - loss: 0.6699 - accuracy: 0.6176 - recall_8: 0.6176 - precision_8: 0.61 - ETA: 28s - loss: 0.6699 - accuracy: 0.6176 - recall_8: 0.6176 - precision_8: 0.61 - ETA: 27s - loss: 0.6701 - accuracy: 0.6175 - recall_8: 0.6175 - precision_8: 0.61 - ETA: 27s - loss: 0.6699 - accuracy: 0.6178 - recall_8: 0.6178 - precision_8: 0.61 - ETA: 27s - loss: 0.6699 - accuracy: 0.6177 - recall_8: 0.6177 - precision_8: 0.61 - ETA: 27s - loss: 0.6694 - accuracy: 0.6182 - recall_8: 0.6182 - precision_8: 0.61 - ETA: 26s - loss: 0.6688 - accuracy: 0.6187 - recall_8: 0.6187 - precision_8: 0.61 - ETA: 26s - loss: 0.6686 - accuracy: 0.6189 - recall_8: 0.6189 - precision_8: 0.61 - ETA: 26s - loss: 0.6684 - accuracy: 0.6192 - recall_8: 0.6192 - precision_8: 0.61 - ETA: 25s - loss: 0.6685 - accuracy: 0.6191 - recall_8: 0.6191 - precision_8: 0.61 - ETA: 25s - loss: 0.6685 - accuracy: 0.6191 - recall_8: 0.6191 - precision_8: 0.61 - ETA: 25s - loss: 0.6683 - accuracy: 0.6193 - recall_8: 0.6193 - precision_8: 0.61 - ETA: 24s - loss: 0.6683 - accuracy: 0.6193 - recall_8: 0.6193 - precision_8: 0.61 - ETA: 24s - loss: 0.6683 - accuracy: 0.6193 - recall_8: 0.6193 - precision_8: 0.61 - ETA: 24s - loss: 0.6681 - accuracy: 0.6195 - recall_8: 0.6195 - precision_8: 0.61 - ETA: 24s - loss: 0.6676 - accuracy: 0.6200 - recall_8: 0.6200 - precision_8: 0.62 - ETA: 23s - loss: 0.6677 - accuracy: 0.6200 - recall_8: 0.6200 - precision_8: 0.62 - ETA: 23s - loss: 0.6671 - accuracy: 0.6204 - recall_8: 0.6204 - precision_8: 0.62 - ETA: 23s - loss: 0.6665 - accuracy: 0.6209 - recall_8: 0.6209 - precision_8: 0.62 - ETA: 22s - loss: 0.6669 - accuracy: 0.6206 - recall_8: 0.6206 - precision_8: 0.62 - ETA: 22s - loss: 0.6668 - accuracy: 0.6209 - recall_8: 0.6209 - precision_8: 0.62 - ETA: 22s - loss: 0.6666 - accuracy: 0.6211 - recall_8: 0.6211 - precision_8: 0.62 - ETA: 22s - loss: 0.6666 - accuracy: 0.6211 - recall_8: 0.6211 - precision_8: 0.62 - ETA: 21s - loss: 0.6671 - accuracy: 0.6208 - recall_8: 0.6208 - precision_8: 0.62 - ETA: 21s - loss: 0.6667 - accuracy: 0.6213 - recall_8: 0.6213 - precision_8: 0.62 - ETA: 21s - loss: 0.6663 - accuracy: 0.6217 - recall_8: 0.6217 - precision_8: 0.62 - ETA: 20s - loss: 0.6659 - accuracy: 0.6222 - recall_8: 0.6222 - precision_8: 0.62 - ETA: 20s - loss: 0.6657 - accuracy: 0.6224 - recall_8: 0.6224 - precision_8: 0.62 - ETA: 20s - loss: 0.6653 - accuracy: 0.6229 - recall_8: 0.6229 - precision_8: 0.62 - ETA: 19s - loss: 0.6651 - accuracy: 0.6231 - recall_8: 0.6231 - precision_8: 0.62 - ETA: 19s - loss: 0.6650 - accuracy: 0.6233 - recall_8: 0.6233 - precision_8: 0.62 - ETA: 19s - loss: 0.6648 - accuracy: 0.6235 - recall_8: 0.6235 - precision_8: 0.62 - ETA: 19s - loss: 0.6646 - accuracy: 0.6237 - recall_8: 0.6237 - precision_8: 0.62 - ETA: 18s - loss: 0.6647 - accuracy: 0.6237 - recall_8: 0.6237 - precision_8: 0.62 - ETA: 18s - loss: 0.6641 - accuracy: 0.6242 - recall_8: 0.6242 - precision_8: 0.62 - ETA: 18s - loss: 0.6639 - accuracy: 0.6244 - recall_8: 0.6244 - precision_8: 0.62 - ETA: 17s - loss: 0.6647 - accuracy: 0.6241 - recall_8: 0.6241 - precision_8: 0.62 - ETA: 17s - loss: 0.6642 - accuracy: 0.6246 - recall_8: 0.6246 - precision_8: 0.62 - ETA: 17s - loss: 0.6640 - accuracy: 0.6248 - recall_8: 0.6248 - precision_8: 0.62 - ETA: 17s - loss: 0.6640 - accuracy: 0.6248 - recall_8: 0.6248 - precision_8: 0.62 - ETA: 16s - loss: 0.6642 - accuracy: 0.6247 - recall_8: 0.6247 - precision_8: 0.62 - ETA: 16s - loss: 0.6636 - accuracy: 0.6252 - recall_8: 0.6252 - precision_8: 0.62 - ETA: 16s - loss: 0.6634 - accuracy: 0.6254 - recall_8: 0.6254 - precision_8: 0.62 - ETA: 15s - loss: 0.6638 - accuracy: 0.6251 - recall_8: 0.6251 - precision_8: 0.62 - ETA: 15s - loss: 0.6633 - accuracy: 0.6256 - recall_8: 0.6256 - precision_8: 0.62 - ETA: 15s - loss: 0.6631 - accuracy: 0.6258 - recall_8: 0.6258 - precision_8: 0.62 - ETA: 14s - loss: 0.6627 - accuracy: 0.6262 - recall_8: 0.6262 - precision_8: 0.62 - ETA: 14s - loss: 0.6636 - accuracy: 0.6262 - recall_8: 0.6262 - precision_8: 0.62 - ETA: 14s - loss: 0.6642 - accuracy: 0.6259 - recall_8: 0.6259 - precision_8: 0.62 - ETA: 14s - loss: 0.6640 - accuracy: 0.6261 - recall_8: 0.6261 - precision_8: 0.62 - ETA: 13s - loss: 0.6641 - accuracy: 0.6261 - recall_8: 0.6261 - precision_8: 0.62 - ETA: 13s - loss: 0.6637 - accuracy: 0.6266 - recall_8: 0.6266 - precision_8: 0.62 - ETA: 13s - loss: 0.6635 - accuracy: 0.6268 - recall_8: 0.6268 - precision_8: 0.62 - ETA: 12s - loss: 0.6631 - accuracy: 0.6272 - recall_8: 0.6272 - precision_8: 0.62 - ETA: 12s - loss: 0.6630 - accuracy: 0.6274 - recall_8: 0.6274 - precision_8: 0.62 - ETA: 12s - loss: 0.6626 - accuracy: 0.6279 - recall_8: 0.6279 - precision_8: 0.62 - ETA: 12s - loss: 0.6620 - accuracy: 0.6283 - recall_8: 0.6283 - precision_8: 0.62 - ETA: 11s - loss: 0.6615 - accuracy: 0.6287 - recall_8: 0.6287 - precision_8: 0.62 - ETA: 11s - loss: 0.6613 - accuracy: 0.6289 - recall_8: 0.6289 - precision_8: 0.62 - ETA: 11s - loss: 0.6614 - accuracy: 0.6289 - recall_8: 0.6289 - precision_8: 0.62 - ETA: 10s - loss: 0.6610 - accuracy: 0.6293 - recall_8: 0.6293 - precision_8: 0.62 - ETA: 10s - loss: 0.6605 - accuracy: 0.6298 - recall_8: 0.6298 - precision_8: 0.62 - ETA: 10s - loss: 0.6605 - accuracy: 0.6298 - recall_8: 0.6298 - precision_8: 0.62 - ETA: 10s - loss: 0.6601 - accuracy: 0.6302 - recall_8: 0.6302 - precision_8: 0.63 - ETA: 9s - loss: 0.6604 - accuracy: 0.6302 - recall_8: 0.6302 - precision_8: 0.6302 - ETA: 9s - loss: 0.6602 - accuracy: 0.6304 - recall_8: 0.6304 - precision_8: 0.630 - ETA: 9s - loss: 0.6600 - accuracy: 0.6306 - recall_8: 0.6306 - precision_8: 0.630 - ETA: 8s - loss: 0.6603 - accuracy: 0.6303 - recall_8: 0.6303 - precision_8: 0.630 - ETA: 8s - loss: 0.6602 - accuracy: 0.6305 - recall_8: 0.6305 - precision_8: 0.630 - ETA: 8s - loss: 0.6596 - accuracy: 0.6309 - recall_8: 0.6309 - precision_8: 0.630 - ETA: 7s - loss: 0.6594 - accuracy: 0.6311 - recall_8: 0.6311 - precision_8: 0.631 - ETA: 7s - loss: 0.6593 - accuracy: 0.6313 - recall_8: 0.6313 - precision_8: 0.631 - ETA: 7s - loss: 0.6591 - accuracy: 0.6315 - recall_8: 0.6315 - precision_8: 0.631 - ETA: 7s - loss: 0.6589 - accuracy: 0.6317 - recall_8: 0.6317 - precision_8: 0.631 - ETA: 6s - loss: 0.6592 - accuracy: 0.6314 - recall_8: 0.6314 - precision_8: 0.631 - ETA: 6s - loss: 0.6590 - accuracy: 0.6316 - recall_8: 0.6316 - precision_8: 0.6316"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882/882 [==============================] - ETA: 6s - loss: 0.6586 - accuracy: 0.6321 - recall_8: 0.6321 - precision_8: 0.632 - ETA: 5s - loss: 0.6591 - accuracy: 0.6316 - recall_8: 0.6316 - precision_8: 0.631 - ETA: 5s - loss: 0.6593 - accuracy: 0.6315 - recall_8: 0.6315 - precision_8: 0.631 - ETA: 5s - loss: 0.6589 - accuracy: 0.6319 - recall_8: 0.6319 - precision_8: 0.631 - ETA: 5s - loss: 0.6585 - accuracy: 0.6324 - recall_8: 0.6324 - precision_8: 0.632 - ETA: 4s - loss: 0.6588 - accuracy: 0.6323 - recall_8: 0.6323 - precision_8: 0.632 - ETA: 4s - loss: 0.6591 - accuracy: 0.6323 - recall_8: 0.6323 - precision_8: 0.632 - ETA: 4s - loss: 0.6589 - accuracy: 0.6325 - recall_8: 0.6325 - precision_8: 0.632 - ETA: 3s - loss: 0.6585 - accuracy: 0.6329 - recall_8: 0.6329 - precision_8: 0.632 - ETA: 3s - loss: 0.6583 - accuracy: 0.6331 - recall_8: 0.6331 - precision_8: 0.633 - ETA: 3s - loss: 0.6585 - accuracy: 0.6331 - recall_8: 0.6331 - precision_8: 0.633 - ETA: 2s - loss: 0.6581 - accuracy: 0.6335 - recall_8: 0.6335 - precision_8: 0.633 - ETA: 2s - loss: 0.6579 - accuracy: 0.6337 - recall_8: 0.6337 - precision_8: 0.633 - ETA: 2s - loss: 0.6577 - accuracy: 0.6339 - recall_8: 0.6339 - precision_8: 0.633 - ETA: 2s - loss: 0.6578 - accuracy: 0.6338 - recall_8: 0.6338 - precision_8: 0.633 - ETA: 1s - loss: 0.6573 - accuracy: 0.6342 - recall_8: 0.6342 - precision_8: 0.634 - ETA: 1s - loss: 0.6573 - accuracy: 0.6342 - recall_8: 0.6342 - precision_8: 0.634 - ETA: 1s - loss: 0.6573 - accuracy: 0.6344 - recall_8: 0.6344 - precision_8: 0.634 - ETA: 0s - loss: 0.6571 - accuracy: 0.6346 - recall_8: 0.6346 - precision_8: 0.634 - ETA: 0s - loss: 0.6566 - accuracy: 0.6350 - recall_8: 0.6350 - precision_8: 0.635 - ETA: 0s - loss: 0.6571 - accuracy: 0.6347 - recall_8: 0.6347 - precision_8: 0.634 - ETA: 0s - loss: 0.6567 - accuracy: 0.6351 - recall_8: 0.6351 - precision_8: 0.635 - 260s 294ms/step - loss: 0.6567 - accuracy: 0.6351 - recall_8: 0.6351 - precision_8: 0.6351\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/882 [==>...........................] - ETA: 0s - loss: 0.3205 - accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.000 - ETA: 2:11 - loss: 0.5152 - accuracy: 0.8000 - recall_8: 0.8000 - precision_8: 0.800 - ETA: 2:55 - loss: 0.5802 - accuracy: 0.7333 - recall_8: 0.7333 - precision_8: 0.733 - ETA: 3:19 - loss: 0.4875 - accuracy: 0.8000 - recall_8: 0.8000 - precision_8: 0.800 - ETA: 3:33 - loss: 0.4930 - accuracy: 0.8000 - recall_8: 0.8000 - precision_8: 0.800 - ETA: 3:40 - loss: 0.5617 - accuracy: 0.7333 - recall_8: 0.7333 - precision_8: 0.733 - ETA: 3:45 - loss: 0.5550 - accuracy: 0.7429 - recall_8: 0.7429 - precision_8: 0.742 - ETA: 3:49 - loss: 0.5572 - accuracy: 0.7500 - recall_8: 0.7500 - precision_8: 0.750 - ETA: 3:53 - loss: 0.5495 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 3:56 - loss: 0.5476 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 3:58 - loss: 0.5420 - accuracy: 0.7636 - recall_8: 0.7636 - precision_8: 0.763 - ETA: 4:00 - loss: 0.5903 - accuracy: 0.7333 - recall_8: 0.7333 - precision_8: 0.733 - ETA: 4:01 - loss: 0.5995 - accuracy: 0.7231 - recall_8: 0.7231 - precision_8: 0.723 - ETA: 4:02 - loss: 0.6173 - accuracy: 0.7143 - recall_8: 0.7143 - precision_8: 0.714 - ETA: 4:04 - loss: 0.5975 - accuracy: 0.7333 - recall_8: 0.7333 - precision_8: 0.733 - ETA: 4:04 - loss: 0.6000 - accuracy: 0.7375 - recall_8: 0.7375 - precision_8: 0.737 - ETA: 4:05 - loss: 0.5934 - accuracy: 0.7412 - recall_8: 0.7412 - precision_8: 0.741 - ETA: 4:05 - loss: 0.6106 - accuracy: 0.7222 - recall_8: 0.7222 - precision_8: 0.722 - ETA: 4:06 - loss: 0.6158 - accuracy: 0.7158 - recall_8: 0.7158 - precision_8: 0.715 - ETA: 4:06 - loss: 0.6012 - accuracy: 0.7300 - recall_8: 0.7300 - precision_8: 0.730 - ETA: 4:06 - loss: 0.6063 - accuracy: 0.7238 - recall_8: 0.7238 - precision_8: 0.723 - ETA: 4:07 - loss: 0.6022 - accuracy: 0.7273 - recall_8: 0.7273 - precision_8: 0.727 - ETA: 4:07 - loss: 0.5850 - accuracy: 0.7391 - recall_8: 0.7391 - precision_8: 0.739 - ETA: 4:07 - loss: 0.5693 - accuracy: 0.7500 - recall_8: 0.7500 - precision_8: 0.750 - ETA: 4:07 - loss: 0.5749 - accuracy: 0.7440 - recall_8: 0.7440 - precision_8: 0.744 - ETA: 4:08 - loss: 0.5608 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 4:08 - loss: 0.5582 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 4:08 - loss: 0.5566 - accuracy: 0.7571 - recall_8: 0.7571 - precision_8: 0.757 - ETA: 4:08 - loss: 0.5447 - accuracy: 0.7655 - recall_8: 0.7655 - precision_8: 0.765 - ETA: 4:08 - loss: 0.5502 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 4:08 - loss: 0.5595 - accuracy: 0.7548 - recall_8: 0.7548 - precision_8: 0.754 - ETA: 4:08 - loss: 0.5593 - accuracy: 0.7563 - recall_8: 0.7563 - precision_8: 0.756 - ETA: 4:08 - loss: 0.5671 - accuracy: 0.7515 - recall_8: 0.7515 - precision_8: 0.751 - ETA: 4:07 - loss: 0.5599 - accuracy: 0.7588 - recall_8: 0.7588 - precision_8: 0.758 - ETA: 4:07 - loss: 0.5596 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 4:07 - loss: 0.5690 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 4:07 - loss: 0.5623 - accuracy: 0.7622 - recall_8: 0.7622 - precision_8: 0.762 - ETA: 4:07 - loss: 0.5611 - accuracy: 0.7632 - recall_8: 0.7632 - precision_8: 0.763 - ETA: 4:07 - loss: 0.5550 - accuracy: 0.7692 - recall_8: 0.7692 - precision_8: 0.769 - ETA: 4:07 - loss: 0.5534 - accuracy: 0.7700 - recall_8: 0.7700 - precision_8: 0.770 - ETA: 4:07 - loss: 0.5600 - accuracy: 0.7659 - recall_8: 0.7659 - precision_8: 0.765 - ETA: 4:07 - loss: 0.5517 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 4:07 - loss: 0.5554 - accuracy: 0.7674 - recall_8: 0.7674 - precision_8: 0.767 - ETA: 4:06 - loss: 0.5668 - accuracy: 0.7591 - recall_8: 0.7591 - precision_8: 0.759 - ETA: 4:06 - loss: 0.5657 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 4:06 - loss: 0.5646 - accuracy: 0.7609 - recall_8: 0.7609 - precision_8: 0.760 - ETA: 4:06 - loss: 0.5594 - accuracy: 0.7660 - recall_8: 0.7660 - precision_8: 0.766 - ETA: 4:05 - loss: 0.5581 - accuracy: 0.7667 - recall_8: 0.7667 - precision_8: 0.766 - ETA: 4:05 - loss: 0.5510 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 4:05 - loss: 0.5464 - accuracy: 0.7760 - recall_8: 0.7760 - precision_8: 0.776 - ETA: 4:05 - loss: 0.5458 - accuracy: 0.7765 - recall_8: 0.7765 - precision_8: 0.776 - ETA: 4:05 - loss: 0.5402 - accuracy: 0.7808 - recall_8: 0.7808 - precision_8: 0.780 - ETA: 4:04 - loss: 0.5361 - accuracy: 0.7849 - recall_8: 0.7849 - precision_8: 0.784 - ETA: 4:04 - loss: 0.5412 - accuracy: 0.7815 - recall_8: 0.7815 - precision_8: 0.781 - ETA: 4:04 - loss: 0.5477 - accuracy: 0.7782 - recall_8: 0.7782 - precision_8: 0.778 - ETA: 4:04 - loss: 0.5467 - accuracy: 0.7786 - recall_8: 0.7786 - precision_8: 0.778 - ETA: 4:04 - loss: 0.5458 - accuracy: 0.7789 - recall_8: 0.7789 - precision_8: 0.778 - ETA: 4:04 - loss: 0.5449 - accuracy: 0.7793 - recall_8: 0.7793 - precision_8: 0.779 - ETA: 4:03 - loss: 0.5446 - accuracy: 0.7797 - recall_8: 0.7797 - precision_8: 0.779 - ETA: 4:03 - loss: 0.5409 - accuracy: 0.7833 - recall_8: 0.7833 - precision_8: 0.783 - ETA: 4:03 - loss: 0.5412 - accuracy: 0.7836 - recall_8: 0.7836 - precision_8: 0.783 - ETA: 4:02 - loss: 0.5472 - accuracy: 0.7774 - recall_8: 0.7774 - precision_8: 0.777 - ETA: 4:02 - loss: 0.5561 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 4:02 - loss: 0.5583 - accuracy: 0.7688 - recall_8: 0.7688 - precision_8: 0.768 - ETA: 4:02 - loss: 0.5530 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 4:02 - loss: 0.5655 - accuracy: 0.7636 - recall_8: 0.7636 - precision_8: 0.763 - ETA: 4:02 - loss: 0.5677 - accuracy: 0.7612 - recall_8: 0.7612 - precision_8: 0.761 - ETA: 4:02 - loss: 0.5727 - accuracy: 0.7559 - recall_8: 0.7559 - precision_8: 0.755 - ETA: 4:02 - loss: 0.5718 - accuracy: 0.7565 - recall_8: 0.7565 - precision_8: 0.756 - ETA: 4:01 - loss: 0.5738 - accuracy: 0.7543 - recall_8: 0.7543 - precision_8: 0.754 - ETA: 4:01 - loss: 0.5730 - accuracy: 0.7549 - recall_8: 0.7549 - precision_8: 0.754 - ETA: 4:01 - loss: 0.5749 - accuracy: 0.7528 - recall_8: 0.7528 - precision_8: 0.752 - ETA: 4:01 - loss: 0.5742 - accuracy: 0.7534 - recall_8: 0.7534 - precision_8: 0.753 - ETA: 4:00 - loss: 0.5760 - accuracy: 0.7514 - recall_8: 0.7514 - precision_8: 0.751 - ETA: 4:00 - loss: 0.5726 - accuracy: 0.7547 - recall_8: 0.7547 - precision_8: 0.754 - ETA: 4:00 - loss: 0.5694 - accuracy: 0.7579 - recall_8: 0.7579 - precision_8: 0.757 - ETA: 3:59 - loss: 0.5712 - accuracy: 0.7558 - recall_8: 0.7558 - precision_8: 0.755 - ETA: 3:59 - loss: 0.5725 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 3:59 - loss: 0.5726 - accuracy: 0.7544 - recall_8: 0.7544 - precision_8: 0.754 - ETA: 3:59 - loss: 0.5716 - accuracy: 0.7550 - recall_8: 0.7550 - precision_8: 0.755 - ETA: 3:59 - loss: 0.5709 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 3:58 - loss: 0.5703 - accuracy: 0.7561 - recall_8: 0.7561 - precision_8: 0.756 - ETA: 3:58 - loss: 0.5708 - accuracy: 0.7566 - recall_8: 0.7566 - precision_8: 0.756 - ETA: 3:58 - loss: 0.5733 - accuracy: 0.7548 - recall_8: 0.7548 - precision_8: 0.754 - ETA: 3:58 - loss: 0.5688 - accuracy: 0.7576 - recall_8: 0.7576 - precision_8: 0.757 - ETA: 3:57 - loss: 0.5679 - accuracy: 0.7581 - recall_8: 0.7581 - precision_8: 0.758 - ETA: 3:57 - loss: 0.5707 - accuracy: 0.7563 - recall_8: 0.7563 - precision_8: 0.756 - ETA: 3:57 - loss: 0.5742 - accuracy: 0.7545 - recall_8: 0.7545 - precision_8: 0.754 - ETA: 3:57 - loss: 0.5714 - accuracy: 0.7573 - recall_8: 0.7573 - precision_8: 0.757 - ETA: 3:56 - loss: 0.5729 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 3:56 - loss: 0.5744 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 3:56 - loss: 0.5766 - accuracy: 0.7522 - recall_8: 0.7522 - precision_8: 0.752 - ETA: 3:55 - loss: 0.5738 - accuracy: 0.7548 - recall_8: 0.7548 - precision_8: 0.754 - ETA: 3:55 - loss: 0.5793 - accuracy: 0.7511 - recall_8: 0.7511 - precision_8: 0.751 - ETA: 3:55 - loss: 0.5830 - accuracy: 0.7495 - recall_8: 0.7495 - precision_8: 0.7495190/882 [=====>........................] - ETA: 3:55 - loss: 0.5863 - accuracy: 0.7479 - recall_8: 0.7479 - precision_8: 0.747 - ETA: 3:55 - loss: 0.5837 - accuracy: 0.7505 - recall_8: 0.7505 - precision_8: 0.750 - ETA: 3:54 - loss: 0.5871 - accuracy: 0.7490 - recall_8: 0.7490 - precision_8: 0.749 - ETA: 3:54 - loss: 0.5897 - accuracy: 0.7475 - recall_8: 0.7475 - precision_8: 0.747 - ETA: 3:54 - loss: 0.5909 - accuracy: 0.7460 - recall_8: 0.7460 - precision_8: 0.746 - ETA: 3:53 - loss: 0.5883 - accuracy: 0.7485 - recall_8: 0.7485 - precision_8: 0.748 - ETA: 3:53 - loss: 0.5926 - accuracy: 0.7451 - recall_8: 0.7451 - precision_8: 0.745 - ETA: 3:53 - loss: 0.5890 - accuracy: 0.7476 - recall_8: 0.7476 - precision_8: 0.747 - ETA: 3:52 - loss: 0.5936 - accuracy: 0.7442 - recall_8: 0.7442 - precision_8: 0.744 - ETA: 3:52 - loss: 0.5964 - accuracy: 0.7410 - recall_8: 0.7410 - precision_8: 0.741 - ETA: 3:52 - loss: 0.5939 - accuracy: 0.7434 - recall_8: 0.7434 - precision_8: 0.743 - ETA: 3:52 - loss: 0.5930 - accuracy: 0.7439 - recall_8: 0.7439 - precision_8: 0.743 - ETA: 3:51 - loss: 0.5924 - accuracy: 0.7444 - recall_8: 0.7444 - precision_8: 0.744 - ETA: 3:51 - loss: 0.5943 - accuracy: 0.7431 - recall_8: 0.7431 - precision_8: 0.743 - ETA: 3:51 - loss: 0.5953 - accuracy: 0.7418 - recall_8: 0.7418 - precision_8: 0.741 - ETA: 3:51 - loss: 0.5963 - accuracy: 0.7405 - recall_8: 0.7405 - precision_8: 0.740 - ETA: 3:50 - loss: 0.5956 - accuracy: 0.7411 - recall_8: 0.7411 - precision_8: 0.741 - ETA: 3:50 - loss: 0.5993 - accuracy: 0.7381 - recall_8: 0.7381 - precision_8: 0.738 - ETA: 3:50 - loss: 0.5987 - accuracy: 0.7386 - recall_8: 0.7386 - precision_8: 0.738 - ETA: 3:50 - loss: 0.5964 - accuracy: 0.7409 - recall_8: 0.7409 - precision_8: 0.740 - ETA: 3:49 - loss: 0.5973 - accuracy: 0.7397 - recall_8: 0.7397 - precision_8: 0.739 - ETA: 3:49 - loss: 0.5941 - accuracy: 0.7419 - recall_8: 0.7419 - precision_8: 0.741 - ETA: 3:49 - loss: 0.5979 - accuracy: 0.7390 - recall_8: 0.7390 - precision_8: 0.739 - ETA: 3:49 - loss: 0.5957 - accuracy: 0.7412 - recall_8: 0.7412 - precision_8: 0.741 - ETA: 3:48 - loss: 0.5970 - accuracy: 0.7400 - recall_8: 0.7400 - precision_8: 0.740 - ETA: 3:48 - loss: 0.5942 - accuracy: 0.7421 - recall_8: 0.7421 - precision_8: 0.742 - ETA: 3:48 - loss: 0.5981 - accuracy: 0.7377 - recall_8: 0.7377 - precision_8: 0.737 - ETA: 3:48 - loss: 0.5989 - accuracy: 0.7366 - recall_8: 0.7366 - precision_8: 0.736 - ETA: 3:47 - loss: 0.5968 - accuracy: 0.7387 - recall_8: 0.7387 - precision_8: 0.738 - ETA: 3:47 - loss: 0.5962 - accuracy: 0.7392 - recall_8: 0.7392 - precision_8: 0.739 - ETA: 3:47 - loss: 0.5974 - accuracy: 0.7381 - recall_8: 0.7381 - precision_8: 0.738 - ETA: 3:46 - loss: 0.5968 - accuracy: 0.7386 - recall_8: 0.7386 - precision_8: 0.738 - ETA: 3:46 - loss: 0.5962 - accuracy: 0.7391 - recall_8: 0.7391 - precision_8: 0.739 - ETA: 3:46 - loss: 0.5971 - accuracy: 0.7380 - recall_8: 0.7380 - precision_8: 0.738 - ETA: 3:45 - loss: 0.5965 - accuracy: 0.7385 - recall_8: 0.7385 - precision_8: 0.738 - ETA: 3:45 - loss: 0.6001 - accuracy: 0.7359 - recall_8: 0.7359 - precision_8: 0.735 - ETA: 3:45 - loss: 0.5993 - accuracy: 0.7364 - recall_8: 0.7364 - precision_8: 0.736 - ETA: 3:45 - loss: 0.6001 - accuracy: 0.7353 - recall_8: 0.7353 - precision_8: 0.735 - ETA: 3:44 - loss: 0.5981 - accuracy: 0.7373 - recall_8: 0.7373 - precision_8: 0.737 - ETA: 3:44 - loss: 0.5975 - accuracy: 0.7378 - recall_8: 0.7378 - precision_8: 0.737 - ETA: 3:44 - loss: 0.5956 - accuracy: 0.7397 - recall_8: 0.7397 - precision_8: 0.739 - ETA: 3:43 - loss: 0.5949 - accuracy: 0.7401 - recall_8: 0.7401 - precision_8: 0.740 - ETA: 3:43 - loss: 0.5931 - accuracy: 0.7420 - recall_8: 0.7420 - precision_8: 0.742 - ETA: 3:43 - loss: 0.5925 - accuracy: 0.7424 - recall_8: 0.7424 - precision_8: 0.742 - ETA: 3:43 - loss: 0.5900 - accuracy: 0.7443 - recall_8: 0.7443 - precision_8: 0.744 - ETA: 3:42 - loss: 0.5894 - accuracy: 0.7447 - recall_8: 0.7447 - precision_8: 0.744 - ETA: 3:42 - loss: 0.5876 - accuracy: 0.7465 - recall_8: 0.7465 - precision_8: 0.746 - ETA: 3:42 - loss: 0.5863 - accuracy: 0.7469 - recall_8: 0.7469 - precision_8: 0.746 - ETA: 3:41 - loss: 0.5857 - accuracy: 0.7472 - recall_8: 0.7472 - precision_8: 0.747 - ETA: 3:41 - loss: 0.5886 - accuracy: 0.7448 - recall_8: 0.7448 - precision_8: 0.744 - ETA: 3:41 - loss: 0.5869 - accuracy: 0.7466 - recall_8: 0.7466 - precision_8: 0.746 - ETA: 3:41 - loss: 0.5845 - accuracy: 0.7483 - recall_8: 0.7483 - precision_8: 0.748 - ETA: 3:40 - loss: 0.5828 - accuracy: 0.7500 - recall_8: 0.7500 - precision_8: 0.750 - ETA: 3:40 - loss: 0.5824 - accuracy: 0.7503 - recall_8: 0.7503 - precision_8: 0.750 - ETA: 3:40 - loss: 0.5820 - accuracy: 0.7507 - recall_8: 0.7507 - precision_8: 0.750 - ETA: 3:40 - loss: 0.5816 - accuracy: 0.7510 - recall_8: 0.7510 - precision_8: 0.751 - ETA: 3:39 - loss: 0.5809 - accuracy: 0.7513 - recall_8: 0.7513 - precision_8: 0.751 - ETA: 3:39 - loss: 0.5792 - accuracy: 0.7529 - recall_8: 0.7529 - precision_8: 0.752 - ETA: 3:39 - loss: 0.5787 - accuracy: 0.7532 - recall_8: 0.7532 - precision_8: 0.753 - ETA: 3:39 - loss: 0.5783 - accuracy: 0.7535 - recall_8: 0.7535 - precision_8: 0.753 - ETA: 3:38 - loss: 0.5779 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 3:38 - loss: 0.5774 - accuracy: 0.7541 - recall_8: 0.7541 - precision_8: 0.754 - ETA: 3:38 - loss: 0.5785 - accuracy: 0.7532 - recall_8: 0.7532 - precision_8: 0.753 - ETA: 3:38 - loss: 0.5799 - accuracy: 0.7522 - recall_8: 0.7522 - precision_8: 0.752 - ETA: 3:37 - loss: 0.5793 - accuracy: 0.7525 - recall_8: 0.7525 - precision_8: 0.752 - ETA: 3:37 - loss: 0.5801 - accuracy: 0.7516 - recall_8: 0.7516 - precision_8: 0.751 - ETA: 3:37 - loss: 0.5797 - accuracy: 0.7519 - recall_8: 0.7519 - precision_8: 0.751 - ETA: 3:36 - loss: 0.5808 - accuracy: 0.7509 - recall_8: 0.7509 - precision_8: 0.750 - ETA: 3:36 - loss: 0.5802 - accuracy: 0.7512 - recall_8: 0.7512 - precision_8: 0.751 - ETA: 3:36 - loss: 0.5799 - accuracy: 0.7515 - recall_8: 0.7515 - precision_8: 0.751 - ETA: 3:36 - loss: 0.5803 - accuracy: 0.7518 - recall_8: 0.7518 - precision_8: 0.751 - ETA: 3:35 - loss: 0.5799 - accuracy: 0.7521 - recall_8: 0.7521 - precision_8: 0.752 - ETA: 3:35 - loss: 0.5815 - accuracy: 0.7512 - recall_8: 0.7512 - precision_8: 0.751 - ETA: 3:35 - loss: 0.5800 - accuracy: 0.7527 - recall_8: 0.7527 - precision_8: 0.752 - ETA: 3:35 - loss: 0.5807 - accuracy: 0.7518 - recall_8: 0.7518 - precision_8: 0.751 - ETA: 3:34 - loss: 0.5801 - accuracy: 0.7520 - recall_8: 0.7520 - precision_8: 0.752 - ETA: 3:34 - loss: 0.5808 - accuracy: 0.7512 - recall_8: 0.7512 - precision_8: 0.751 - ETA: 3:34 - loss: 0.5805 - accuracy: 0.7514 - recall_8: 0.7514 - precision_8: 0.751 - ETA: 3:33 - loss: 0.5801 - accuracy: 0.7517 - recall_8: 0.7517 - precision_8: 0.751 - ETA: 3:33 - loss: 0.5797 - accuracy: 0.7520 - recall_8: 0.7520 - precision_8: 0.752 - ETA: 3:33 - loss: 0.5794 - accuracy: 0.7523 - recall_8: 0.7523 - precision_8: 0.752 - ETA: 3:33 - loss: 0.5777 - accuracy: 0.7537 - recall_8: 0.7537 - precision_8: 0.753 - ETA: 3:32 - loss: 0.5773 - accuracy: 0.7539 - recall_8: 0.7539 - precision_8: 0.753 - ETA: 3:32 - loss: 0.5754 - accuracy: 0.7553 - recall_8: 0.7553 - precision_8: 0.755 - ETA: 3:32 - loss: 0.5751 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 3:31 - loss: 0.5747 - accuracy: 0.7558 - recall_8: 0.7558 - precision_8: 0.755 - ETA: 3:31 - loss: 0.5734 - accuracy: 0.7571 - recall_8: 0.7571 - precision_8: 0.757 - ETA: 3:31 - loss: 0.5752 - accuracy: 0.7552 - recall_8: 0.7552 - precision_8: 0.755 - ETA: 3:30 - loss: 0.5738 - accuracy: 0.7565 - recall_8: 0.7565 - precision_8: 0.756 - ETA: 3:30 - loss: 0.5735 - accuracy: 0.7568 - recall_8: 0.7568 - precision_8: 0.756 - ETA: 3:30 - loss: 0.5732 - accuracy: 0.7570 - recall_8: 0.7570 - precision_8: 0.757 - ETA: 3:30 - loss: 0.5729 - accuracy: 0.7572 - recall_8: 0.7572 - precision_8: 0.757 - ETA: 3:29 - loss: 0.5715 - accuracy: 0.7585 - recall_8: 0.7585 - precision_8: 0.758 - ETA: 3:29 - loss: 0.5712 - accuracy: 0.7587 - recall_8: 0.7587 - precision_8: 0.758 - ETA: 3:29 - loss: 0.5709 - accuracy: 0.7589 - recall_8: 0.7589 - precision_8: 0.7589"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/882 [========>.....................] - ETA: 3:28 - loss: 0.5696 - accuracy: 0.7602 - recall_8: 0.7602 - precision_8: 0.760 - ETA: 3:28 - loss: 0.5683 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 3:28 - loss: 0.5670 - accuracy: 0.7627 - recall_8: 0.7627 - precision_8: 0.762 - ETA: 3:28 - loss: 0.5667 - accuracy: 0.7629 - recall_8: 0.7629 - precision_8: 0.762 - ETA: 3:27 - loss: 0.5677 - accuracy: 0.7621 - recall_8: 0.7621 - precision_8: 0.762 - ETA: 3:27 - loss: 0.5675 - accuracy: 0.7622 - recall_8: 0.7622 - precision_8: 0.762 - ETA: 3:27 - loss: 0.5682 - accuracy: 0.7614 - recall_8: 0.7614 - precision_8: 0.761 - ETA: 3:26 - loss: 0.5707 - accuracy: 0.7596 - recall_8: 0.7596 - precision_8: 0.759 - ETA: 3:26 - loss: 0.5692 - accuracy: 0.7608 - recall_8: 0.7608 - precision_8: 0.760 - ETA: 3:26 - loss: 0.5694 - accuracy: 0.7610 - recall_8: 0.7610 - precision_8: 0.761 - ETA: 3:26 - loss: 0.5690 - accuracy: 0.7612 - recall_8: 0.7612 - precision_8: 0.761 - ETA: 3:25 - loss: 0.5686 - accuracy: 0.7614 - recall_8: 0.7614 - precision_8: 0.761 - ETA: 3:25 - loss: 0.5697 - accuracy: 0.7606 - recall_8: 0.7606 - precision_8: 0.760 - ETA: 3:25 - loss: 0.5694 - accuracy: 0.7608 - recall_8: 0.7608 - precision_8: 0.760 - ETA: 3:24 - loss: 0.5728 - accuracy: 0.7580 - recall_8: 0.7580 - precision_8: 0.758 - ETA: 3:24 - loss: 0.5733 - accuracy: 0.7573 - recall_8: 0.7573 - precision_8: 0.757 - ETA: 3:24 - loss: 0.5731 - accuracy: 0.7575 - recall_8: 0.7575 - precision_8: 0.757 - ETA: 3:24 - loss: 0.5718 - accuracy: 0.7587 - recall_8: 0.7587 - precision_8: 0.758 - ETA: 3:23 - loss: 0.5725 - accuracy: 0.7579 - recall_8: 0.7579 - precision_8: 0.757 - ETA: 3:23 - loss: 0.5709 - accuracy: 0.7590 - recall_8: 0.7590 - precision_8: 0.759 - ETA: 3:23 - loss: 0.5706 - accuracy: 0.7592 - recall_8: 0.7592 - precision_8: 0.759 - ETA: 3:22 - loss: 0.5690 - accuracy: 0.7604 - recall_8: 0.7604 - precision_8: 0.760 - ETA: 3:22 - loss: 0.5674 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 3:22 - loss: 0.5662 - accuracy: 0.7626 - recall_8: 0.7626 - precision_8: 0.762 - ETA: 3:21 - loss: 0.5669 - accuracy: 0.7619 - recall_8: 0.7619 - precision_8: 0.761 - ETA: 3:21 - loss: 0.5667 - accuracy: 0.7620 - recall_8: 0.7620 - precision_8: 0.762 - ETA: 3:21 - loss: 0.5663 - accuracy: 0.7622 - recall_8: 0.7622 - precision_8: 0.762 - ETA: 3:21 - loss: 0.5685 - accuracy: 0.7606 - recall_8: 0.7606 - precision_8: 0.760 - ETA: 3:20 - loss: 0.5682 - accuracy: 0.7607 - recall_8: 0.7607 - precision_8: 0.760 - ETA: 3:20 - loss: 0.5690 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 3:20 - loss: 0.5674 - accuracy: 0.7611 - recall_8: 0.7611 - precision_8: 0.761 - ETA: 3:19 - loss: 0.5681 - accuracy: 0.7604 - recall_8: 0.7604 - precision_8: 0.760 - ETA: 3:19 - loss: 0.5678 - accuracy: 0.7605 - recall_8: 0.7605 - precision_8: 0.760 - ETA: 3:19 - loss: 0.5676 - accuracy: 0.7607 - recall_8: 0.7607 - precision_8: 0.760 - ETA: 3:19 - loss: 0.5692 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 3:18 - loss: 0.5698 - accuracy: 0.7593 - recall_8: 0.7593 - precision_8: 0.759 - ETA: 3:18 - loss: 0.5696 - accuracy: 0.7595 - recall_8: 0.7595 - precision_8: 0.759 - ETA: 3:18 - loss: 0.5693 - accuracy: 0.7596 - recall_8: 0.7596 - precision_8: 0.759 - ETA: 3:17 - loss: 0.5691 - accuracy: 0.7598 - recall_8: 0.7598 - precision_8: 0.759 - ETA: 3:17 - loss: 0.5700 - accuracy: 0.7591 - recall_8: 0.7591 - precision_8: 0.759 - ETA: 3:17 - loss: 0.5721 - accuracy: 0.7576 - recall_8: 0.7576 - precision_8: 0.757 - ETA: 3:16 - loss: 0.5705 - accuracy: 0.7586 - recall_8: 0.7586 - precision_8: 0.758 - ETA: 3:16 - loss: 0.5705 - accuracy: 0.7588 - recall_8: 0.7588 - precision_8: 0.758 - ETA: 3:16 - loss: 0.5691 - accuracy: 0.7598 - recall_8: 0.7598 - precision_8: 0.759 - ETA: 3:15 - loss: 0.5699 - accuracy: 0.7591 - recall_8: 0.7591 - precision_8: 0.759 - ETA: 3:15 - loss: 0.5688 - accuracy: 0.7602 - recall_8: 0.7602 - precision_8: 0.760 - ETA: 3:15 - loss: 0.5674 - accuracy: 0.7612 - recall_8: 0.7612 - precision_8: 0.761 - ETA: 3:15 - loss: 0.5672 - accuracy: 0.7613 - recall_8: 0.7613 - precision_8: 0.761 - ETA: 3:14 - loss: 0.5669 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 3:14 - loss: 0.5655 - accuracy: 0.7625 - recall_8: 0.7625 - precision_8: 0.762 - ETA: 3:14 - loss: 0.5653 - accuracy: 0.7627 - recall_8: 0.7627 - precision_8: 0.762 - ETA: 3:13 - loss: 0.5638 - accuracy: 0.7636 - recall_8: 0.7636 - precision_8: 0.763 - ETA: 3:13 - loss: 0.5657 - accuracy: 0.7621 - recall_8: 0.7621 - precision_8: 0.762 - ETA: 3:13 - loss: 0.5664 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 3:12 - loss: 0.5650 - accuracy: 0.7624 - recall_8: 0.7624 - precision_8: 0.762 - ETA: 3:12 - loss: 0.5669 - accuracy: 0.7610 - recall_8: 0.7610 - precision_8: 0.761 - ETA: 3:12 - loss: 0.5659 - accuracy: 0.7619 - recall_8: 0.7619 - precision_8: 0.761 - ETA: 3:12 - loss: 0.5657 - accuracy: 0.7621 - recall_8: 0.7621 - precision_8: 0.762 - ETA: 3:11 - loss: 0.5663 - accuracy: 0.7614 - recall_8: 0.7614 - precision_8: 0.761 - ETA: 3:11 - loss: 0.5661 - accuracy: 0.7616 - recall_8: 0.7616 - precision_8: 0.761 - ETA: 3:11 - loss: 0.5667 - accuracy: 0.7610 - recall_8: 0.7610 - precision_8: 0.761 - ETA: 3:10 - loss: 0.5664 - accuracy: 0.7611 - recall_8: 0.7611 - precision_8: 0.761 - ETA: 3:10 - loss: 0.5672 - accuracy: 0.7605 - recall_8: 0.7605 - precision_8: 0.760 - ETA: 3:10 - loss: 0.5678 - accuracy: 0.7598 - recall_8: 0.7598 - precision_8: 0.759 - ETA: 3:09 - loss: 0.5676 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 3:09 - loss: 0.5690 - accuracy: 0.7594 - recall_8: 0.7594 - precision_8: 0.759 - ETA: 3:09 - loss: 0.5680 - accuracy: 0.7603 - recall_8: 0.7603 - precision_8: 0.760 - ETA: 3:09 - loss: 0.5718 - accuracy: 0.7581 - recall_8: 0.7581 - precision_8: 0.758 - ETA: 3:08 - loss: 0.5708 - accuracy: 0.7591 - recall_8: 0.7591 - precision_8: 0.759 - ETA: 3:08 - loss: 0.5695 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 3:08 - loss: 0.5693 - accuracy: 0.7602 - recall_8: 0.7602 - precision_8: 0.760 - ETA: 3:07 - loss: 0.5701 - accuracy: 0.7595 - recall_8: 0.7595 - precision_8: 0.759 - ETA: 3:07 - loss: 0.5688 - accuracy: 0.7605 - recall_8: 0.7605 - precision_8: 0.760 - ETA: 3:07 - loss: 0.5686 - accuracy: 0.7606 - recall_8: 0.7606 - precision_8: 0.760 - ETA: 3:06 - loss: 0.5682 - accuracy: 0.7608 - recall_8: 0.7608 - precision_8: 0.760 - ETA: 3:06 - loss: 0.5680 - accuracy: 0.7609 - recall_8: 0.7609 - precision_8: 0.760 - ETA: 3:06 - loss: 0.5678 - accuracy: 0.7610 - recall_8: 0.7610 - precision_8: 0.761 - ETA: 3:06 - loss: 0.5668 - accuracy: 0.7619 - recall_8: 0.7619 - precision_8: 0.761 - ETA: 3:05 - loss: 0.5666 - accuracy: 0.7621 - recall_8: 0.7621 - precision_8: 0.762 - ETA: 3:05 - loss: 0.5671 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 3:05 - loss: 0.5669 - accuracy: 0.7616 - recall_8: 0.7616 - precision_8: 0.761 - ETA: 3:04 - loss: 0.5669 - accuracy: 0.7618 - recall_8: 0.7618 - precision_8: 0.761 - ETA: 3:04 - loss: 0.5667 - accuracy: 0.7619 - recall_8: 0.7619 - precision_8: 0.761 - ETA: 3:04 - loss: 0.5665 - accuracy: 0.7620 - recall_8: 0.7620 - precision_8: 0.762 - ETA: 3:04 - loss: 0.5678 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 3:03 - loss: 0.5669 - accuracy: 0.7623 - recall_8: 0.7623 - precision_8: 0.762 - ETA: 3:03 - loss: 0.5660 - accuracy: 0.7632 - recall_8: 0.7632 - precision_8: 0.763 - ETA: 3:03 - loss: 0.5667 - accuracy: 0.7626 - recall_8: 0.7626 - precision_8: 0.762 - ETA: 3:02 - loss: 0.5668 - accuracy: 0.7627 - recall_8: 0.7627 - precision_8: 0.762 - ETA: 3:02 - loss: 0.5675 - accuracy: 0.7621 - recall_8: 0.7621 - precision_8: 0.762 - ETA: 3:02 - loss: 0.5663 - accuracy: 0.7630 - recall_8: 0.7630 - precision_8: 0.763 - ETA: 3:01 - loss: 0.5674 - accuracy: 0.7624 - recall_8: 0.7624 - precision_8: 0.762 - ETA: 3:01 - loss: 0.5672 - accuracy: 0.7625 - recall_8: 0.7625 - precision_8: 0.762 - ETA: 3:01 - loss: 0.5674 - accuracy: 0.7627 - recall_8: 0.7627 - precision_8: 0.762 - ETA: 3:01 - loss: 0.5686 - accuracy: 0.7614 - recall_8: 0.7614 - precision_8: 0.7614"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/882 [===========>..................] - ETA: 3:00 - loss: 0.5693 - accuracy: 0.7608 - recall_8: 0.7608 - precision_8: 0.760 - ETA: 3:00 - loss: 0.5691 - accuracy: 0.7610 - recall_8: 0.7610 - precision_8: 0.761 - ETA: 3:00 - loss: 0.5696 - accuracy: 0.7604 - recall_8: 0.7604 - precision_8: 0.760 - ETA: 2:59 - loss: 0.5690 - accuracy: 0.7606 - recall_8: 0.7606 - precision_8: 0.760 - ETA: 2:59 - loss: 0.5688 - accuracy: 0.7607 - recall_8: 0.7607 - precision_8: 0.760 - ETA: 2:59 - loss: 0.5682 - accuracy: 0.7608 - recall_8: 0.7608 - precision_8: 0.760 - ETA: 2:58 - loss: 0.5680 - accuracy: 0.7610 - recall_8: 0.7610 - precision_8: 0.761 - ETA: 2:58 - loss: 0.5678 - accuracy: 0.7611 - recall_8: 0.7611 - precision_8: 0.761 - ETA: 2:58 - loss: 0.5690 - accuracy: 0.7599 - recall_8: 0.7599 - precision_8: 0.759 - ETA: 2:57 - loss: 0.5678 - accuracy: 0.7607 - recall_8: 0.7607 - precision_8: 0.760 - ETA: 2:57 - loss: 0.5676 - accuracy: 0.7608 - recall_8: 0.7608 - precision_8: 0.760 - ETA: 2:57 - loss: 0.5665 - accuracy: 0.7616 - recall_8: 0.7616 - precision_8: 0.761 - ETA: 2:57 - loss: 0.5657 - accuracy: 0.7624 - recall_8: 0.7624 - precision_8: 0.762 - ETA: 2:56 - loss: 0.5647 - accuracy: 0.7625 - recall_8: 0.7625 - precision_8: 0.762 - ETA: 2:56 - loss: 0.5652 - accuracy: 0.7620 - recall_8: 0.7620 - precision_8: 0.762 - ETA: 2:56 - loss: 0.5644 - accuracy: 0.7628 - recall_8: 0.7628 - precision_8: 0.762 - ETA: 2:55 - loss: 0.5633 - accuracy: 0.7636 - recall_8: 0.7636 - precision_8: 0.763 - ETA: 2:55 - loss: 0.5631 - accuracy: 0.7637 - recall_8: 0.7637 - precision_8: 0.763 - ETA: 2:55 - loss: 0.5636 - accuracy: 0.7632 - recall_8: 0.7632 - precision_8: 0.763 - ETA: 2:54 - loss: 0.5626 - accuracy: 0.7639 - recall_8: 0.7639 - precision_8: 0.763 - ETA: 2:54 - loss: 0.5616 - accuracy: 0.7647 - recall_8: 0.7647 - precision_8: 0.764 - ETA: 2:54 - loss: 0.5607 - accuracy: 0.7655 - recall_8: 0.7655 - precision_8: 0.765 - ETA: 2:54 - loss: 0.5606 - accuracy: 0.7656 - recall_8: 0.7656 - precision_8: 0.765 - ETA: 2:53 - loss: 0.5612 - accuracy: 0.7650 - recall_8: 0.7650 - precision_8: 0.765 - ETA: 2:53 - loss: 0.5610 - accuracy: 0.7652 - recall_8: 0.7652 - precision_8: 0.765 - ETA: 2:53 - loss: 0.5600 - accuracy: 0.7659 - recall_8: 0.7659 - precision_8: 0.765 - ETA: 2:52 - loss: 0.5592 - accuracy: 0.7667 - recall_8: 0.7667 - precision_8: 0.766 - ETA: 2:52 - loss: 0.5597 - accuracy: 0.7661 - recall_8: 0.7661 - precision_8: 0.766 - ETA: 2:52 - loss: 0.5602 - accuracy: 0.7656 - recall_8: 0.7656 - precision_8: 0.765 - ETA: 2:51 - loss: 0.5594 - accuracy: 0.7663 - recall_8: 0.7663 - precision_8: 0.766 - ETA: 2:51 - loss: 0.5592 - accuracy: 0.7665 - recall_8: 0.7665 - precision_8: 0.766 - ETA: 2:51 - loss: 0.5599 - accuracy: 0.7659 - recall_8: 0.7659 - precision_8: 0.765 - ETA: 2:50 - loss: 0.5606 - accuracy: 0.7654 - recall_8: 0.7654 - precision_8: 0.765 - ETA: 2:50 - loss: 0.5605 - accuracy: 0.7655 - recall_8: 0.7655 - precision_8: 0.765 - ETA: 2:50 - loss: 0.5603 - accuracy: 0.7656 - recall_8: 0.7656 - precision_8: 0.765 - ETA: 2:50 - loss: 0.5601 - accuracy: 0.7657 - recall_8: 0.7657 - precision_8: 0.765 - ETA: 2:49 - loss: 0.5606 - accuracy: 0.7652 - recall_8: 0.7652 - precision_8: 0.765 - ETA: 2:49 - loss: 0.5604 - accuracy: 0.7653 - recall_8: 0.7653 - precision_8: 0.765 - ETA: 2:49 - loss: 0.5595 - accuracy: 0.7660 - recall_8: 0.7660 - precision_8: 0.766 - ETA: 2:48 - loss: 0.5594 - accuracy: 0.7662 - recall_8: 0.7662 - precision_8: 0.766 - ETA: 2:48 - loss: 0.5592 - accuracy: 0.7663 - recall_8: 0.7663 - precision_8: 0.766 - ETA: 2:48 - loss: 0.5582 - accuracy: 0.7670 - recall_8: 0.7670 - precision_8: 0.767 - ETA: 2:47 - loss: 0.5594 - accuracy: 0.7659 - recall_8: 0.7659 - precision_8: 0.765 - ETA: 2:47 - loss: 0.5593 - accuracy: 0.7660 - recall_8: 0.7660 - precision_8: 0.766 - ETA: 2:47 - loss: 0.5585 - accuracy: 0.7667 - recall_8: 0.7667 - precision_8: 0.766 - ETA: 2:47 - loss: 0.5583 - accuracy: 0.7668 - recall_8: 0.7668 - precision_8: 0.766 - ETA: 2:46 - loss: 0.5582 - accuracy: 0.7669 - recall_8: 0.7669 - precision_8: 0.766 - ETA: 2:46 - loss: 0.5581 - accuracy: 0.7670 - recall_8: 0.7670 - precision_8: 0.767 - ETA: 2:46 - loss: 0.5581 - accuracy: 0.7671 - recall_8: 0.7671 - precision_8: 0.767 - ETA: 2:45 - loss: 0.5579 - accuracy: 0.7672 - recall_8: 0.7672 - precision_8: 0.767 - ETA: 2:45 - loss: 0.5589 - accuracy: 0.7667 - recall_8: 0.7667 - precision_8: 0.766 - ETA: 2:45 - loss: 0.5584 - accuracy: 0.7668 - recall_8: 0.7668 - precision_8: 0.766 - ETA: 2:44 - loss: 0.5602 - accuracy: 0.7657 - recall_8: 0.7657 - precision_8: 0.765 - ETA: 2:44 - loss: 0.5600 - accuracy: 0.7658 - recall_8: 0.7658 - precision_8: 0.765 - ETA: 2:44 - loss: 0.5605 - accuracy: 0.7653 - recall_8: 0.7653 - precision_8: 0.765 - ETA: 2:44 - loss: 0.5609 - accuracy: 0.7648 - recall_8: 0.7648 - precision_8: 0.764 - ETA: 2:43 - loss: 0.5600 - accuracy: 0.7655 - recall_8: 0.7655 - precision_8: 0.765 - ETA: 2:43 - loss: 0.5604 - accuracy: 0.7650 - recall_8: 0.7650 - precision_8: 0.765 - ETA: 2:43 - loss: 0.5603 - accuracy: 0.7651 - recall_8: 0.7651 - precision_8: 0.765 - ETA: 2:42 - loss: 0.5601 - accuracy: 0.7652 - recall_8: 0.7652 - precision_8: 0.765 - ETA: 2:42 - loss: 0.5600 - accuracy: 0.7653 - recall_8: 0.7653 - precision_8: 0.765 - ETA: 2:42 - loss: 0.5606 - accuracy: 0.7648 - recall_8: 0.7648 - precision_8: 0.764 - ETA: 2:41 - loss: 0.5599 - accuracy: 0.7655 - recall_8: 0.7655 - precision_8: 0.765 - ETA: 2:41 - loss: 0.5604 - accuracy: 0.7650 - recall_8: 0.7650 - precision_8: 0.765 - ETA: 2:41 - loss: 0.5599 - accuracy: 0.7651 - recall_8: 0.7651 - precision_8: 0.765 - ETA: 2:40 - loss: 0.5592 - accuracy: 0.7658 - recall_8: 0.7658 - precision_8: 0.765 - ETA: 2:40 - loss: 0.5590 - accuracy: 0.7659 - recall_8: 0.7659 - precision_8: 0.765 - ETA: 2:40 - loss: 0.5583 - accuracy: 0.7666 - recall_8: 0.7666 - precision_8: 0.766 - ETA: 2:40 - loss: 0.5590 - accuracy: 0.7661 - recall_8: 0.7661 - precision_8: 0.766 - ETA: 2:39 - loss: 0.5587 - accuracy: 0.7662 - recall_8: 0.7662 - precision_8: 0.766 - ETA: 2:39 - loss: 0.5586 - accuracy: 0.7663 - recall_8: 0.7663 - precision_8: 0.766 - ETA: 2:39 - loss: 0.5579 - accuracy: 0.7669 - recall_8: 0.7669 - precision_8: 0.766 - ETA: 2:38 - loss: 0.5577 - accuracy: 0.7670 - recall_8: 0.7670 - precision_8: 0.767 - ETA: 2:38 - loss: 0.5577 - accuracy: 0.7671 - recall_8: 0.7671 - precision_8: 0.767 - ETA: 2:38 - loss: 0.5581 - accuracy: 0.7667 - recall_8: 0.7667 - precision_8: 0.766 - ETA: 2:37 - loss: 0.5586 - accuracy: 0.7662 - recall_8: 0.7662 - precision_8: 0.766 - ETA: 2:37 - loss: 0.5590 - accuracy: 0.7657 - recall_8: 0.7657 - precision_8: 0.765 - ETA: 2:37 - loss: 0.5581 - accuracy: 0.7664 - recall_8: 0.7664 - precision_8: 0.766 - ETA: 2:37 - loss: 0.5585 - accuracy: 0.7659 - recall_8: 0.7659 - precision_8: 0.765 - ETA: 2:36 - loss: 0.5591 - accuracy: 0.7655 - recall_8: 0.7655 - precision_8: 0.765 - ETA: 2:36 - loss: 0.5582 - accuracy: 0.7661 - recall_8: 0.7661 - precision_8: 0.766 - ETA: 2:36 - loss: 0.5581 - accuracy: 0.7662 - recall_8: 0.7662 - precision_8: 0.766 - ETA: 2:35 - loss: 0.5572 - accuracy: 0.7668 - recall_8: 0.7668 - precision_8: 0.766 - ETA: 2:35 - loss: 0.5565 - accuracy: 0.7675 - recall_8: 0.7675 - precision_8: 0.767 - ETA: 2:35 - loss: 0.5564 - accuracy: 0.7676 - recall_8: 0.7676 - precision_8: 0.767 - ETA: 2:34 - loss: 0.5557 - accuracy: 0.7682 - recall_8: 0.7682 - precision_8: 0.768 - ETA: 2:34 - loss: 0.5550 - accuracy: 0.7688 - recall_8: 0.7688 - precision_8: 0.768 - ETA: 2:34 - loss: 0.5542 - accuracy: 0.7694 - recall_8: 0.7694 - precision_8: 0.769 - ETA: 2:33 - loss: 0.5534 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:33 - loss: 0.5533 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:33 - loss: 0.5529 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 2:33 - loss: 0.5522 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 2:32 - loss: 0.5516 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 2:32 - loss: 0.5515 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.771 - ETA: 2:32 - loss: 0.5508 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.7721"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/882 [===============>..............] - ETA: 2:31 - loss: 0.5516 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 2:31 - loss: 0.5507 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 2:31 - loss: 0.5505 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 2:30 - loss: 0.5517 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 2:30 - loss: 0.5522 - accuracy: 0.7709 - recall_8: 0.7709 - precision_8: 0.770 - ETA: 2:30 - loss: 0.5527 - accuracy: 0.7705 - recall_8: 0.7705 - precision_8: 0.770 - ETA: 2:30 - loss: 0.5540 - accuracy: 0.7695 - recall_8: 0.7695 - precision_8: 0.769 - ETA: 2:29 - loss: 0.5545 - accuracy: 0.7691 - recall_8: 0.7691 - precision_8: 0.769 - ETA: 2:29 - loss: 0.5550 - accuracy: 0.7686 - recall_8: 0.7686 - precision_8: 0.768 - ETA: 2:29 - loss: 0.5548 - accuracy: 0.7687 - recall_8: 0.7687 - precision_8: 0.768 - ETA: 2:28 - loss: 0.5546 - accuracy: 0.7688 - recall_8: 0.7688 - precision_8: 0.768 - ETA: 2:28 - loss: 0.5550 - accuracy: 0.7684 - recall_8: 0.7684 - precision_8: 0.768 - ETA: 2:28 - loss: 0.5549 - accuracy: 0.7684 - recall_8: 0.7684 - precision_8: 0.768 - ETA: 2:27 - loss: 0.5543 - accuracy: 0.7690 - recall_8: 0.7690 - precision_8: 0.769 - ETA: 2:27 - loss: 0.5536 - accuracy: 0.7696 - recall_8: 0.7696 - precision_8: 0.769 - ETA: 2:27 - loss: 0.5535 - accuracy: 0.7697 - recall_8: 0.7697 - precision_8: 0.769 - ETA: 2:26 - loss: 0.5529 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 2:26 - loss: 0.5533 - accuracy: 0.7698 - recall_8: 0.7698 - precision_8: 0.769 - ETA: 2:26 - loss: 0.5525 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 2:26 - loss: 0.5517 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 2:25 - loss: 0.5535 - accuracy: 0.7696 - recall_8: 0.7696 - precision_8: 0.769 - ETA: 2:25 - loss: 0.5542 - accuracy: 0.7692 - recall_8: 0.7692 - precision_8: 0.769 - ETA: 2:25 - loss: 0.5540 - accuracy: 0.7692 - recall_8: 0.7692 - precision_8: 0.769 - ETA: 2:24 - loss: 0.5539 - accuracy: 0.7693 - recall_8: 0.7693 - precision_8: 0.769 - ETA: 2:24 - loss: 0.5538 - accuracy: 0.7694 - recall_8: 0.7694 - precision_8: 0.769 - ETA: 2:24 - loss: 0.5537 - accuracy: 0.7695 - recall_8: 0.7695 - precision_8: 0.769 - ETA: 2:23 - loss: 0.5530 - accuracy: 0.7700 - recall_8: 0.7700 - precision_8: 0.770 - ETA: 2:23 - loss: 0.5528 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:23 - loss: 0.5535 - accuracy: 0.7697 - recall_8: 0.7697 - precision_8: 0.769 - ETA: 2:23 - loss: 0.5527 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 2:22 - loss: 0.5531 - accuracy: 0.7698 - recall_8: 0.7698 - precision_8: 0.769 - ETA: 2:22 - loss: 0.5530 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 2:22 - loss: 0.5524 - accuracy: 0.7705 - recall_8: 0.7705 - precision_8: 0.770 - ETA: 2:21 - loss: 0.5523 - accuracy: 0.7705 - recall_8: 0.7705 - precision_8: 0.770 - ETA: 2:21 - loss: 0.5533 - accuracy: 0.7696 - recall_8: 0.7696 - precision_8: 0.769 - ETA: 2:21 - loss: 0.5529 - accuracy: 0.7697 - recall_8: 0.7697 - precision_8: 0.769 - ETA: 2:20 - loss: 0.5528 - accuracy: 0.7698 - recall_8: 0.7698 - precision_8: 0.769 - ETA: 2:20 - loss: 0.5527 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 2:20 - loss: 0.5526 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 2:20 - loss: 0.5530 - accuracy: 0.7695 - recall_8: 0.7695 - precision_8: 0.769 - ETA: 2:19 - loss: 0.5522 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:19 - loss: 0.5521 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:19 - loss: 0.5520 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 2:18 - loss: 0.5519 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 2:18 - loss: 0.5523 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 2:18 - loss: 0.5517 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 2:17 - loss: 0.5516 - accuracy: 0.7705 - recall_8: 0.7705 - precision_8: 0.770 - ETA: 2:17 - loss: 0.5522 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:17 - loss: 0.5514 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 2:17 - loss: 0.5513 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 2:16 - loss: 0.5506 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 2:16 - loss: 0.5510 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 2:16 - loss: 0.5514 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 2:15 - loss: 0.5513 - accuracy: 0.7705 - recall_8: 0.7705 - precision_8: 0.770 - ETA: 2:15 - loss: 0.5506 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 2:15 - loss: 0.5511 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 2:14 - loss: 0.5514 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 2:14 - loss: 0.5508 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 2:14 - loss: 0.5502 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.771 - ETA: 2:14 - loss: 0.5496 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 2:13 - loss: 0.5490 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 2:13 - loss: 0.5489 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 2:13 - loss: 0.5489 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 2:12 - loss: 0.5494 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 2:12 - loss: 0.5493 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 2:12 - loss: 0.5492 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 2:11 - loss: 0.5492 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 2:11 - loss: 0.5491 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 2:11 - loss: 0.5508 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.771 - ETA: 2:11 - loss: 0.5507 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 2:10 - loss: 0.5511 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 2:10 - loss: 0.5522 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 2:10 - loss: 0.5514 - accuracy: 0.7709 - recall_8: 0.7709 - precision_8: 0.770 - ETA: 2:09 - loss: 0.5514 - accuracy: 0.7709 - recall_8: 0.7709 - precision_8: 0.770 - ETA: 2:09 - loss: 0.5508 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 2:09 - loss: 0.5507 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.771 - ETA: 2:08 - loss: 0.5520 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 2:08 - loss: 0.5528 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 2:08 - loss: 0.5527 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 2:08 - loss: 0.5520 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 2:07 - loss: 0.5524 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:07 - loss: 0.5517 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 2:07 - loss: 0.5519 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 2:06 - loss: 0.5527 - accuracy: 0.7694 - recall_8: 0.7694 - precision_8: 0.769 - ETA: 2:06 - loss: 0.5522 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 2:06 - loss: 0.5525 - accuracy: 0.7695 - recall_8: 0.7695 - precision_8: 0.769 - ETA: 2:06 - loss: 0.5524 - accuracy: 0.7696 - recall_8: 0.7696 - precision_8: 0.769 - ETA: 2:05 - loss: 0.5518 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:05 - loss: 0.5517 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:05 - loss: 0.5516 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 2:04 - loss: 0.5515 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 2:04 - loss: 0.5517 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 2:04 - loss: 0.5516 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 2:03 - loss: 0.5521 - accuracy: 0.7700 - recall_8: 0.7700 - precision_8: 0.770 - ETA: 2:03 - loss: 0.5524 - accuracy: 0.7697 - recall_8: 0.7697 - precision_8: 0.7697"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/882 [==================>...........] - ETA: 2:03 - loss: 0.5519 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 2:03 - loss: 0.5513 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 2:02 - loss: 0.5518 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 2:02 - loss: 0.5517 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 2:02 - loss: 0.5521 - accuracy: 0.7700 - recall_8: 0.7700 - precision_8: 0.770 - ETA: 2:01 - loss: 0.5526 - accuracy: 0.7696 - recall_8: 0.7696 - precision_8: 0.769 - ETA: 2:01 - loss: 0.5519 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 2:01 - loss: 0.5524 - accuracy: 0.7698 - recall_8: 0.7698 - precision_8: 0.769 - ETA: 2:00 - loss: 0.5533 - accuracy: 0.7690 - recall_8: 0.7690 - precision_8: 0.769 - ETA: 2:00 - loss: 0.5527 - accuracy: 0.7695 - recall_8: 0.7695 - precision_8: 0.769 - ETA: 2:00 - loss: 0.5531 - accuracy: 0.7691 - recall_8: 0.7691 - precision_8: 0.769 - ETA: 2:00 - loss: 0.5525 - accuracy: 0.7696 - recall_8: 0.7696 - precision_8: 0.769 - ETA: 1:59 - loss: 0.5525 - accuracy: 0.7697 - recall_8: 0.7697 - precision_8: 0.769 - ETA: 1:59 - loss: 0.5524 - accuracy: 0.7697 - recall_8: 0.7697 - precision_8: 0.769 - ETA: 1:59 - loss: 0.5523 - accuracy: 0.7698 - recall_8: 0.7698 - precision_8: 0.769 - ETA: 1:58 - loss: 0.5522 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 1:58 - loss: 0.5517 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 1:58 - loss: 0.5512 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 1:57 - loss: 0.5511 - accuracy: 0.7709 - recall_8: 0.7709 - precision_8: 0.770 - ETA: 1:57 - loss: 0.5510 - accuracy: 0.7709 - recall_8: 0.7709 - precision_8: 0.770 - ETA: 1:57 - loss: 0.5519 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 1:56 - loss: 0.5518 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 1:56 - loss: 0.5517 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 1:56 - loss: 0.5517 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 1:56 - loss: 0.5521 - accuracy: 0.7700 - recall_8: 0.7700 - precision_8: 0.770 - ETA: 1:55 - loss: 0.5520 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 1:55 - loss: 0.5519 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 1:55 - loss: 0.5518 - accuracy: 0.7702 - recall_8: 0.7702 - precision_8: 0.770 - ETA: 1:54 - loss: 0.5512 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 1:54 - loss: 0.5506 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:54 - loss: 0.5505 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:53 - loss: 0.5504 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 1:53 - loss: 0.5498 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:53 - loss: 0.5498 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:53 - loss: 0.5503 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 1:52 - loss: 0.5506 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 1:52 - loss: 0.5505 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:52 - loss: 0.5513 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 1:51 - loss: 0.5512 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 1:51 - loss: 0.5511 - accuracy: 0.7705 - recall_8: 0.7705 - precision_8: 0.770 - ETA: 1:51 - loss: 0.5525 - accuracy: 0.7694 - recall_8: 0.7694 - precision_8: 0.769 - ETA: 1:50 - loss: 0.5525 - accuracy: 0.7694 - recall_8: 0.7694 - precision_8: 0.769 - ETA: 1:50 - loss: 0.5519 - accuracy: 0.7699 - recall_8: 0.7699 - precision_8: 0.769 - ETA: 1:50 - loss: 0.5513 - accuracy: 0.7703 - recall_8: 0.7703 - precision_8: 0.770 - ETA: 1:50 - loss: 0.5519 - accuracy: 0.7700 - recall_8: 0.7700 - precision_8: 0.770 - ETA: 1:49 - loss: 0.5519 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 1:49 - loss: 0.5518 - accuracy: 0.7701 - recall_8: 0.7701 - precision_8: 0.770 - ETA: 1:49 - loss: 0.5513 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 1:48 - loss: 0.5513 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 1:48 - loss: 0.5512 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 1:48 - loss: 0.5511 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 1:47 - loss: 0.5512 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 1:47 - loss: 0.5511 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 1:47 - loss: 0.5506 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:47 - loss: 0.5515 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 1:46 - loss: 0.5514 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.770 - ETA: 1:46 - loss: 0.5514 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 1:46 - loss: 0.5512 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 1:45 - loss: 0.5516 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 1:45 - loss: 0.5511 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 1:45 - loss: 0.5507 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:44 - loss: 0.5501 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:44 - loss: 0.5500 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:44 - loss: 0.5503 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 1:44 - loss: 0.5507 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:43 - loss: 0.5507 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 1:43 - loss: 0.5501 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 1:43 - loss: 0.5504 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:42 - loss: 0.5508 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 1:42 - loss: 0.5508 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 1:42 - loss: 0.5507 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:41 - loss: 0.5507 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:41 - loss: 0.5506 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 1:41 - loss: 0.5505 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 1:41 - loss: 0.5500 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 1:40 - loss: 0.5500 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:40 - loss: 0.5495 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.772 - ETA: 1:40 - loss: 0.5494 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 1:39 - loss: 0.5493 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 1:39 - loss: 0.5508 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 1:39 - loss: 0.5505 - accuracy: 0.7709 - recall_8: 0.7709 - precision_8: 0.770 - ETA: 1:38 - loss: 0.5501 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:38 - loss: 0.5500 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:38 - loss: 0.5495 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:37 - loss: 0.5496 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 1:37 - loss: 0.5490 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.771 - ETA: 1:37 - loss: 0.5490 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.771 - ETA: 1:37 - loss: 0.5489 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.771 - ETA: 1:36 - loss: 0.5483 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 1:36 - loss: 0.5482 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:36 - loss: 0.5482 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:35 - loss: 0.5477 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:35 - loss: 0.5476 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 1:35 - loss: 0.5472 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.773 - ETA: 1:34 - loss: 0.5471 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.7733"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/882 [=====================>........] - ETA: 1:34 - loss: 0.5474 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:34 - loss: 0.5469 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.773 - ETA: 1:34 - loss: 0.5464 - accuracy: 0.7738 - recall_8: 0.7738 - precision_8: 0.773 - ETA: 1:33 - loss: 0.5463 - accuracy: 0.7739 - recall_8: 0.7739 - precision_8: 0.773 - ETA: 1:33 - loss: 0.5462 - accuracy: 0.7739 - recall_8: 0.7739 - precision_8: 0.773 - ETA: 1:33 - loss: 0.5462 - accuracy: 0.7740 - recall_8: 0.7740 - precision_8: 0.774 - ETA: 1:32 - loss: 0.5469 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.773 - ETA: 1:32 - loss: 0.5477 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 1:32 - loss: 0.5481 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:31 - loss: 0.5476 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:31 - loss: 0.5485 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.772 - ETA: 1:31 - loss: 0.5488 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.771 - ETA: 1:30 - loss: 0.5497 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 1:30 - loss: 0.5492 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 1:30 - loss: 0.5491 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 1:30 - loss: 0.5496 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:29 - loss: 0.5499 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 1:29 - loss: 0.5503 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 1:29 - loss: 0.5502 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 1:28 - loss: 0.5506 - accuracy: 0.7705 - recall_8: 0.7705 - precision_8: 0.770 - ETA: 1:28 - loss: 0.5501 - accuracy: 0.7709 - recall_8: 0.7709 - precision_8: 0.770 - ETA: 1:28 - loss: 0.5497 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:27 - loss: 0.5500 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 1:27 - loss: 0.5503 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.770 - ETA: 1:27 - loss: 0.5506 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.770 - ETA: 1:27 - loss: 0.5501 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.770 - ETA: 1:26 - loss: 0.5496 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 1:26 - loss: 0.5492 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 1:26 - loss: 0.5495 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:25 - loss: 0.5493 - accuracy: 0.7713 - recall_8: 0.7713 - precision_8: 0.771 - ETA: 1:25 - loss: 0.5496 - accuracy: 0.7710 - recall_8: 0.7710 - precision_8: 0.771 - ETA: 1:25 - loss: 0.5495 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:24 - loss: 0.5495 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.771 - ETA: 1:24 - loss: 0.5494 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.771 - ETA: 1:24 - loss: 0.5489 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 1:23 - loss: 0.5488 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.771 - ETA: 1:23 - loss: 0.5488 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:23 - loss: 0.5487 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:23 - loss: 0.5482 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.772 - ETA: 1:22 - loss: 0.5481 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.772 - ETA: 1:22 - loss: 0.5476 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 1:22 - loss: 0.5471 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 1:21 - loss: 0.5470 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 1:21 - loss: 0.5469 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:21 - loss: 0.5464 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.773 - ETA: 1:20 - loss: 0.5476 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:20 - loss: 0.5472 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:20 - loss: 0.5476 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 1:20 - loss: 0.5479 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 1:19 - loss: 0.5478 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 1:19 - loss: 0.5477 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 1:19 - loss: 0.5473 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 1:18 - loss: 0.5476 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:18 - loss: 0.5483 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.771 - ETA: 1:18 - loss: 0.5479 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 1:17 - loss: 0.5479 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 1:17 - loss: 0.5482 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.771 - ETA: 1:17 - loss: 0.5485 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:16 - loss: 0.5480 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.772 - ETA: 1:16 - loss: 0.5483 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.771 - ETA: 1:16 - loss: 0.5486 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.771 - ETA: 1:16 - loss: 0.5481 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.771 - ETA: 1:15 - loss: 0.5476 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 1:15 - loss: 0.5476 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 1:15 - loss: 0.5471 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 1:14 - loss: 0.5470 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 1:14 - loss: 0.5465 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:14 - loss: 0.5464 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:13 - loss: 0.5464 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.773 - ETA: 1:13 - loss: 0.5463 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.773 - ETA: 1:13 - loss: 0.5462 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.773 - ETA: 1:13 - loss: 0.5458 - accuracy: 0.7735 - recall_8: 0.7735 - precision_8: 0.773 - ETA: 1:12 - loss: 0.5454 - accuracy: 0.7739 - recall_8: 0.7739 - precision_8: 0.773 - ETA: 1:12 - loss: 0.5453 - accuracy: 0.7739 - recall_8: 0.7739 - precision_8: 0.773 - ETA: 1:12 - loss: 0.5461 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.773 - ETA: 1:11 - loss: 0.5471 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:11 - loss: 0.5470 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 1:11 - loss: 0.5469 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 1:10 - loss: 0.5465 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 1:10 - loss: 0.5468 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 1:10 - loss: 0.5467 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 1:10 - loss: 0.5473 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:09 - loss: 0.5468 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 1:09 - loss: 0.5473 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 1:09 - loss: 0.5472 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 1:08 - loss: 0.5472 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 1:08 - loss: 0.5467 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 1:08 - loss: 0.5466 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 1:07 - loss: 0.5469 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 1:07 - loss: 0.5465 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:07 - loss: 0.5468 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:07 - loss: 0.5468 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:06 - loss: 0.5464 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.773 - ETA: 1:06 - loss: 0.5464 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.773 - ETA: 1:06 - loss: 0.5467 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.7729"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762/882 [========================>.....] - ETA: 1:05 - loss: 0.5467 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:05 - loss: 0.5466 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:05 - loss: 0.5465 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.773 - ETA: 1:04 - loss: 0.5468 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:04 - loss: 0.5467 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:04 - loss: 0.5470 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 1:03 - loss: 0.5466 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 1:03 - loss: 0.5465 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:03 - loss: 0.5468 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 1:03 - loss: 0.5464 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1:02 - loss: 0.5467 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 1:02 - loss: 0.5470 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.772 - ETA: 1:02 - loss: 0.5469 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 1:01 - loss: 0.5468 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 1:01 - loss: 0.5471 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:01 - loss: 0.5471 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 1:00 - loss: 0.5466 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 1:00 - loss: 0.5462 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.773 - ETA: 1:00 - loss: 0.5458 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.773 - ETA: 1:00 - loss: 0.5457 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.773 - ETA: 59s - loss: 0.5456 - accuracy: 0.7735 - recall_8: 0.7735 - precision_8: 0.773 - ETA: 59s - loss: 0.5460 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.77 - ETA: 59s - loss: 0.5459 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 58s - loss: 0.5459 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 58s - loss: 0.5462 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 58s - loss: 0.5461 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 57s - loss: 0.5461 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 57s - loss: 0.5465 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 57s - loss: 0.5468 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.77 - ETA: 56s - loss: 0.5464 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 56s - loss: 0.5463 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 56s - loss: 0.5459 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 56s - loss: 0.5458 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.77 - ETA: 55s - loss: 0.5458 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.77 - ETA: 55s - loss: 0.5464 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 55s - loss: 0.5463 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 54s - loss: 0.5462 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 54s - loss: 0.5468 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 54s - loss: 0.5468 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 53s - loss: 0.5470 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.77 - ETA: 53s - loss: 0.5470 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.77 - ETA: 53s - loss: 0.5469 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.77 - ETA: 53s - loss: 0.5465 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.77 - ETA: 52s - loss: 0.5470 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.77 - ETA: 52s - loss: 0.5473 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.77 - ETA: 52s - loss: 0.5473 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.77 - ETA: 51s - loss: 0.5469 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.77 - ETA: 51s - loss: 0.5468 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.77 - ETA: 51s - loss: 0.5467 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.77 - ETA: 50s - loss: 0.5470 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.77 - ETA: 50s - loss: 0.5465 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.77 - ETA: 50s - loss: 0.5471 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.77 - ETA: 49s - loss: 0.5470 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.77 - ETA: 49s - loss: 0.5473 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.77 - ETA: 49s - loss: 0.5477 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.77 - ETA: 49s - loss: 0.5480 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.77 - ETA: 48s - loss: 0.5485 - accuracy: 0.7706 - recall_8: 0.7706 - precision_8: 0.77 - ETA: 48s - loss: 0.5488 - accuracy: 0.7704 - recall_8: 0.7704 - precision_8: 0.77 - ETA: 48s - loss: 0.5483 - accuracy: 0.7707 - recall_8: 0.7707 - precision_8: 0.77 - ETA: 47s - loss: 0.5482 - accuracy: 0.7708 - recall_8: 0.7708 - precision_8: 0.77 - ETA: 47s - loss: 0.5478 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.77 - ETA: 47s - loss: 0.5478 - accuracy: 0.7711 - recall_8: 0.7711 - precision_8: 0.77 - ETA: 46s - loss: 0.5477 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.77 - ETA: 46s - loss: 0.5474 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.77 - ETA: 46s - loss: 0.5473 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.77 - ETA: 46s - loss: 0.5472 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.77 - ETA: 45s - loss: 0.5468 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.77 - ETA: 45s - loss: 0.5467 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.77 - ETA: 45s - loss: 0.5473 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.77 - ETA: 44s - loss: 0.5468 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.77 - ETA: 44s - loss: 0.5465 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.77 - ETA: 44s - loss: 0.5461 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.77 - ETA: 43s - loss: 0.5460 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 43s - loss: 0.5460 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 43s - loss: 0.5460 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 42s - loss: 0.5459 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.77 - ETA: 42s - loss: 0.5459 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.77 - ETA: 42s - loss: 0.5455 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.77 - ETA: 42s - loss: 0.5458 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.77 - ETA: 41s - loss: 0.5454 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 41s - loss: 0.5450 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.77 - ETA: 41s - loss: 0.5452 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 40s - loss: 0.5452 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 40s - loss: 0.5447 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 40s - loss: 0.5447 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 39s - loss: 0.5449 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 39s - loss: 0.5452 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 39s - loss: 0.5451 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 38s - loss: 0.5454 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.77 - ETA: 38s - loss: 0.5450 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 38s - loss: 0.5446 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 38s - loss: 0.5443 - accuracy: 0.7736 - recall_8: 0.7736 - precision_8: 0.77 - ETA: 37s - loss: 0.5445 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.77 - ETA: 37s - loss: 0.5441 - accuracy: 0.7736 - recall_8: 0.7736 - precision_8: 0.77 - ETA: 37s - loss: 0.5446 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.77 - ETA: 36s - loss: 0.5446 - accuracy: 0.7735 - recall_8: 0.7735 - precision_8: 0.77 - ETA: 36s - loss: 0.5445 - accuracy: 0.7735 - recall_8: 0.7735 - precision_8: 0.7735"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/882 [============================>.] - ETA: 36s - loss: 0.5445 - accuracy: 0.7735 - recall_8: 0.7735 - precision_8: 0.77 - ETA: 35s - loss: 0.5441 - accuracy: 0.7738 - recall_8: 0.7738 - precision_8: 0.77 - ETA: 35s - loss: 0.5444 - accuracy: 0.7736 - recall_8: 0.7736 - precision_8: 0.77 - ETA: 35s - loss: 0.5446 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.77 - ETA: 35s - loss: 0.5449 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 34s - loss: 0.5452 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 34s - loss: 0.5451 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 34s - loss: 0.5453 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.77 - ETA: 33s - loss: 0.5453 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.77 - ETA: 33s - loss: 0.5460 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.77 - ETA: 33s - loss: 0.5463 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.77 - ETA: 32s - loss: 0.5465 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.77 - ETA: 32s - loss: 0.5461 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.77 - ETA: 32s - loss: 0.5464 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.77 - ETA: 31s - loss: 0.5473 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.77 - ETA: 31s - loss: 0.5472 - accuracy: 0.7712 - recall_8: 0.7712 - precision_8: 0.77 - ETA: 31s - loss: 0.5469 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.77 - ETA: 31s - loss: 0.5468 - accuracy: 0.7715 - recall_8: 0.7715 - precision_8: 0.77 - ETA: 30s - loss: 0.5467 - accuracy: 0.7716 - recall_8: 0.7716 - precision_8: 0.77 - ETA: 30s - loss: 0.5464 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.77 - ETA: 30s - loss: 0.5464 - accuracy: 0.7719 - recall_8: 0.7719 - precision_8: 0.77 - ETA: 29s - loss: 0.5466 - accuracy: 0.7717 - recall_8: 0.7717 - precision_8: 0.77 - ETA: 29s - loss: 0.5463 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.77 - ETA: 29s - loss: 0.5462 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.77 - ETA: 28s - loss: 0.5465 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.77 - ETA: 28s - loss: 0.5461 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.77 - ETA: 28s - loss: 0.5458 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 28s - loss: 0.5459 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.77 - ETA: 27s - loss: 0.5456 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 27s - loss: 0.5455 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.77 - ETA: 27s - loss: 0.5459 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.77 - ETA: 26s - loss: 0.5462 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.77 - ETA: 26s - loss: 0.5462 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.77 - ETA: 26s - loss: 0.5458 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 25s - loss: 0.5455 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.77 - ETA: 25s - loss: 0.5454 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.77 - ETA: 25s - loss: 0.5451 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 24s - loss: 0.5448 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.77 - ETA: 24s - loss: 0.5447 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 24s - loss: 0.5453 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.77 - ETA: 24s - loss: 0.5453 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 23s - loss: 0.5452 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 23s - loss: 0.5455 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.77 - ETA: 23s - loss: 0.5455 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.77 - ETA: 22s - loss: 0.5451 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 22s - loss: 0.5448 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.77 - ETA: 22s - loss: 0.5450 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 21s - loss: 0.5450 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 21s - loss: 0.5452 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 21s - loss: 0.5449 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.77 - ETA: 21s - loss: 0.5445 - accuracy: 0.7734 - recall_8: 0.7734 - precision_8: 0.77 - ETA: 20s - loss: 0.5444 - accuracy: 0.7735 - recall_8: 0.7735 - precision_8: 0.77 - ETA: 20s - loss: 0.5441 - accuracy: 0.7737 - recall_8: 0.7737 - precision_8: 0.77 - ETA: 20s - loss: 0.5438 - accuracy: 0.7740 - recall_8: 0.7740 - precision_8: 0.77 - ETA: 19s - loss: 0.5437 - accuracy: 0.7741 - recall_8: 0.7741 - precision_8: 0.77 - ETA: 19s - loss: 0.5437 - accuracy: 0.7741 - recall_8: 0.7741 - precision_8: 0.77 - ETA: 19s - loss: 0.5433 - accuracy: 0.7744 - recall_8: 0.7744 - precision_8: 0.77 - ETA: 18s - loss: 0.5430 - accuracy: 0.7746 - recall_8: 0.7746 - precision_8: 0.77 - ETA: 18s - loss: 0.5430 - accuracy: 0.7747 - recall_8: 0.7747 - precision_8: 0.77 - ETA: 18s - loss: 0.5429 - accuracy: 0.7747 - recall_8: 0.7747 - precision_8: 0.77 - ETA: 17s - loss: 0.5429 - accuracy: 0.7747 - recall_8: 0.7747 - precision_8: 0.77 - ETA: 17s - loss: 0.5432 - accuracy: 0.7745 - recall_8: 0.7745 - precision_8: 0.77 - ETA: 17s - loss: 0.5431 - accuracy: 0.7745 - recall_8: 0.7745 - precision_8: 0.77 - ETA: 17s - loss: 0.5431 - accuracy: 0.7746 - recall_8: 0.7746 - precision_8: 0.77 - ETA: 16s - loss: 0.5433 - accuracy: 0.7744 - recall_8: 0.7744 - precision_8: 0.77 - ETA: 16s - loss: 0.5430 - accuracy: 0.7746 - recall_8: 0.7746 - precision_8: 0.77 - ETA: 16s - loss: 0.5438 - accuracy: 0.7739 - recall_8: 0.7739 - precision_8: 0.77 - ETA: 15s - loss: 0.5443 - accuracy: 0.7735 - recall_8: 0.7735 - precision_8: 0.77 - ETA: 15s - loss: 0.5448 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 15s - loss: 0.5448 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 14s - loss: 0.5450 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.77 - ETA: 14s - loss: 0.5447 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.77 - ETA: 14s - loss: 0.5446 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.77 - ETA: 14s - loss: 0.5446 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.77 - ETA: 13s - loss: 0.5448 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.77 - ETA: 13s - loss: 0.5451 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.77 - ETA: 13s - loss: 0.5453 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.77 - ETA: 12s - loss: 0.5453 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.77 - ETA: 12s - loss: 0.5456 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 12s - loss: 0.5455 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 11s - loss: 0.5455 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.77 - ETA: 11s - loss: 0.5454 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.77 - ETA: 11s - loss: 0.5456 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.77 - ETA: 10s - loss: 0.5459 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.77 - ETA: 10s - loss: 0.5455 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 10s - loss: 0.5455 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.77 - ETA: 10s - loss: 0.5452 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.77 - ETA: 9s - loss: 0.5453 - accuracy: 0.7725 - recall_8: 0.7725 - precision_8: 0.7725 - ETA: 9s - loss: 0.5450 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 9s - loss: 0.5447 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 8s - loss: 0.5446 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 8s - loss: 0.5451 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 8s - loss: 0.5451 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 7s - loss: 0.5451 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 7s - loss: 0.5451 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 7s - loss: 0.5456 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 7s - loss: 0.5459 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.772 - ETA: 6s - loss: 0.5459 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.7721"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882/882 [==============================] - ETA: 6s - loss: 0.5455 - accuracy: 0.7724 - recall_8: 0.7724 - precision_8: 0.772 - ETA: 6s - loss: 0.5457 - accuracy: 0.7722 - recall_8: 0.7722 - precision_8: 0.772 - ETA: 5s - loss: 0.5459 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.772 - ETA: 5s - loss: 0.5462 - accuracy: 0.7718 - recall_8: 0.7718 - precision_8: 0.771 - ETA: 5s - loss: 0.5459 - accuracy: 0.7720 - recall_8: 0.7720 - precision_8: 0.772 - ETA: 4s - loss: 0.5458 - accuracy: 0.7721 - recall_8: 0.7721 - precision_8: 0.772 - ETA: 4s - loss: 0.5455 - accuracy: 0.7723 - recall_8: 0.7723 - precision_8: 0.772 - ETA: 4s - loss: 0.5452 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 3s - loss: 0.5452 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 3s - loss: 0.5451 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - ETA: 3s - loss: 0.5448 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 3s - loss: 0.5447 - accuracy: 0.7729 - recall_8: 0.7729 - precision_8: 0.772 - ETA: 2s - loss: 0.5447 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 2s - loss: 0.5446 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 2s - loss: 0.5446 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 1s - loss: 0.5442 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.773 - ETA: 1s - loss: 0.5444 - accuracy: 0.7731 - recall_8: 0.7731 - precision_8: 0.773 - ETA: 1s - loss: 0.5441 - accuracy: 0.7733 - recall_8: 0.7733 - precision_8: 0.773 - ETA: 0s - loss: 0.5443 - accuracy: 0.7732 - recall_8: 0.7732 - precision_8: 0.773 - ETA: 0s - loss: 0.5446 - accuracy: 0.7730 - recall_8: 0.7730 - precision_8: 0.773 - ETA: 0s - loss: 0.5448 - accuracy: 0.7728 - recall_8: 0.7728 - precision_8: 0.772 - ETA: 0s - loss: 0.5450 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.772 - 269s 305ms/step - loss: 0.5450 - accuracy: 0.7726 - recall_8: 0.7726 - precision_8: 0.7726\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/882 [==>...........................] - ETA: 0s - loss: 0.5057 - accuracy: 0.8000 - recall_8: 0.8000 - precision_8: 0.800 - ETA: 2:14 - loss: 0.3734 - accuracy: 0.9000 - recall_8: 0.9000 - precision_8: 0.900 - ETA: 2:57 - loss: 0.3286 - accuracy: 0.9333 - recall_8: 0.9333 - precision_8: 0.933 - ETA: 3:20 - loss: 0.3666 - accuracy: 0.9000 - recall_8: 0.9000 - precision_8: 0.900 - ETA: 3:32 - loss: 0.3944 - accuracy: 0.8800 - recall_8: 0.8800 - precision_8: 0.880 - ETA: 3:40 - loss: 0.3683 - accuracy: 0.9000 - recall_8: 0.9000 - precision_8: 0.900 - ETA: 3:45 - loss: 0.3845 - accuracy: 0.8857 - recall_8: 0.8857 - precision_8: 0.885 - ETA: 3:51 - loss: 0.4475 - accuracy: 0.8500 - recall_8: 0.8500 - precision_8: 0.850 - ETA: 3:55 - loss: 0.5050 - accuracy: 0.8000 - recall_8: 0.8000 - precision_8: 0.800 - ETA: 3:58 - loss: 0.4783 - accuracy: 0.8200 - recall_8: 0.8200 - precision_8: 0.820 - ETA: 3:59 - loss: 0.4807 - accuracy: 0.8182 - recall_8: 0.8182 - precision_8: 0.818 - ETA: 4:01 - loss: 0.5029 - accuracy: 0.8000 - recall_8: 0.8000 - precision_8: 0.800 - ETA: 4:02 - loss: 0.5378 - accuracy: 0.7692 - recall_8: 0.7692 - precision_8: 0.769 - ETA: 4:04 - loss: 0.5333 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 4:06 - loss: 0.5428 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 4:07 - loss: 0.5240 - accuracy: 0.7750 - recall_8: 0.7750 - precision_8: 0.775 - ETA: 4:07 - loss: 0.5095 - accuracy: 0.7882 - recall_8: 0.7882 - precision_8: 0.788 - ETA: 4:08 - loss: 0.5300 - accuracy: 0.7778 - recall_8: 0.7778 - precision_8: 0.777 - ETA: 4:09 - loss: 0.5167 - accuracy: 0.7895 - recall_8: 0.7895 - precision_8: 0.789 - ETA: 4:09 - loss: 0.5276 - accuracy: 0.7800 - recall_8: 0.7800 - precision_8: 0.780 - ETA: 4:09 - loss: 0.5375 - accuracy: 0.7714 - recall_8: 0.7714 - precision_8: 0.771 - ETA: 4:10 - loss: 0.5361 - accuracy: 0.7727 - recall_8: 0.7727 - precision_8: 0.772 - ETA: 4:10 - loss: 0.5248 - accuracy: 0.7826 - recall_8: 0.7826 - precision_8: 0.782 - ETA: 4:10 - loss: 0.5430 - accuracy: 0.7667 - recall_8: 0.7667 - precision_8: 0.766 - ETA: 4:10 - loss: 0.5415 - accuracy: 0.7680 - recall_8: 0.7680 - precision_8: 0.768 - ETA: 4:10 - loss: 0.5401 - accuracy: 0.7692 - recall_8: 0.7692 - precision_8: 0.769 - ETA: 4:10 - loss: 0.5472 - accuracy: 0.7630 - recall_8: 0.7630 - precision_8: 0.763 - ETA: 4:09 - loss: 0.5539 - accuracy: 0.7571 - recall_8: 0.7571 - precision_8: 0.757 - ETA: 4:10 - loss: 0.5431 - accuracy: 0.7655 - recall_8: 0.7655 - precision_8: 0.765 - ETA: 4:09 - loss: 0.5419 - accuracy: 0.7667 - recall_8: 0.7667 - precision_8: 0.766 - ETA: 4:09 - loss: 0.5410 - accuracy: 0.7677 - recall_8: 0.7677 - precision_8: 0.767 - ETA: 4:09 - loss: 0.5401 - accuracy: 0.7688 - recall_8: 0.7688 - precision_8: 0.768 - ETA: 4:09 - loss: 0.5376 - accuracy: 0.7697 - recall_8: 0.7697 - precision_8: 0.769 - ETA: 4:09 - loss: 0.5434 - accuracy: 0.7647 - recall_8: 0.7647 - precision_8: 0.764 - ETA: 4:09 - loss: 0.5502 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 4:09 - loss: 0.5553 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 4:08 - loss: 0.5615 - accuracy: 0.7514 - recall_8: 0.7514 - precision_8: 0.751 - ETA: 4:08 - loss: 0.5600 - accuracy: 0.7526 - recall_8: 0.7526 - precision_8: 0.752 - ETA: 4:08 - loss: 0.5586 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 4:08 - loss: 0.5575 - accuracy: 0.7550 - recall_8: 0.7550 - precision_8: 0.755 - ETA: 4:09 - loss: 0.5529 - accuracy: 0.7561 - recall_8: 0.7561 - precision_8: 0.756 - ETA: 4:08 - loss: 0.5458 - accuracy: 0.7619 - recall_8: 0.7619 - precision_8: 0.761 - ETA: 4:08 - loss: 0.5528 - accuracy: 0.7581 - recall_8: 0.7581 - precision_8: 0.758 - ETA: 4:08 - loss: 0.5459 - accuracy: 0.7636 - recall_8: 0.7636 - precision_8: 0.763 - ETA: 4:08 - loss: 0.5402 - accuracy: 0.7644 - recall_8: 0.7644 - precision_8: 0.764 - ETA: 4:08 - loss: 0.5455 - accuracy: 0.7609 - recall_8: 0.7609 - precision_8: 0.760 - ETA: 4:08 - loss: 0.5494 - accuracy: 0.7574 - recall_8: 0.7574 - precision_8: 0.757 - ETA: 4:08 - loss: 0.5485 - accuracy: 0.7583 - recall_8: 0.7583 - precision_8: 0.758 - ETA: 4:08 - loss: 0.5433 - accuracy: 0.7633 - recall_8: 0.7633 - precision_8: 0.763 - ETA: 4:08 - loss: 0.5471 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 4:07 - loss: 0.5465 - accuracy: 0.7608 - recall_8: 0.7608 - precision_8: 0.760 - ETA: 4:07 - loss: 0.5550 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 4:07 - loss: 0.5584 - accuracy: 0.7509 - recall_8: 0.7509 - precision_8: 0.750 - ETA: 4:07 - loss: 0.5615 - accuracy: 0.7481 - recall_8: 0.7481 - precision_8: 0.748 - ETA: 4:07 - loss: 0.5687 - accuracy: 0.7418 - recall_8: 0.7418 - precision_8: 0.741 - ETA: 4:06 - loss: 0.5676 - accuracy: 0.7429 - recall_8: 0.7429 - precision_8: 0.742 - ETA: 4:06 - loss: 0.5626 - accuracy: 0.7474 - recall_8: 0.7474 - precision_8: 0.747 - ETA: 4:06 - loss: 0.5653 - accuracy: 0.7448 - recall_8: 0.7448 - precision_8: 0.744 - ETA: 4:06 - loss: 0.5681 - accuracy: 0.7424 - recall_8: 0.7424 - precision_8: 0.742 - ETA: 4:05 - loss: 0.5708 - accuracy: 0.7400 - recall_8: 0.7400 - precision_8: 0.740 - ETA: 4:05 - loss: 0.5655 - accuracy: 0.7443 - recall_8: 0.7443 - precision_8: 0.744 - ETA: 4:05 - loss: 0.5605 - accuracy: 0.7484 - recall_8: 0.7484 - precision_8: 0.748 - ETA: 4:04 - loss: 0.5561 - accuracy: 0.7524 - recall_8: 0.7524 - precision_8: 0.752 - ETA: 4:04 - loss: 0.5545 - accuracy: 0.7531 - recall_8: 0.7531 - precision_8: 0.753 - ETA: 4:04 - loss: 0.5539 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 4:04 - loss: 0.5565 - accuracy: 0.7515 - recall_8: 0.7515 - precision_8: 0.751 - ETA: 4:03 - loss: 0.5525 - accuracy: 0.7552 - recall_8: 0.7552 - precision_8: 0.755 - ETA: 4:03 - loss: 0.5518 - accuracy: 0.7559 - recall_8: 0.7559 - precision_8: 0.755 - ETA: 4:03 - loss: 0.5512 - accuracy: 0.7565 - recall_8: 0.7565 - precision_8: 0.756 - ETA: 4:02 - loss: 0.5543 - accuracy: 0.7543 - recall_8: 0.7543 - precision_8: 0.754 - ETA: 4:02 - loss: 0.5566 - accuracy: 0.7521 - recall_8: 0.7521 - precision_8: 0.752 - ETA: 4:02 - loss: 0.5589 - accuracy: 0.7500 - recall_8: 0.7500 - precision_8: 0.750 - ETA: 4:02 - loss: 0.5582 - accuracy: 0.7507 - recall_8: 0.7507 - precision_8: 0.750 - ETA: 4:02 - loss: 0.5613 - accuracy: 0.7486 - recall_8: 0.7486 - precision_8: 0.748 - ETA: 4:01 - loss: 0.5611 - accuracy: 0.7493 - recall_8: 0.7493 - precision_8: 0.749 - ETA: 4:01 - loss: 0.5666 - accuracy: 0.7447 - recall_8: 0.7447 - precision_8: 0.744 - ETA: 4:01 - loss: 0.5716 - accuracy: 0.7403 - recall_8: 0.7403 - precision_8: 0.740 - ETA: 4:00 - loss: 0.5792 - accuracy: 0.7333 - recall_8: 0.7333 - precision_8: 0.733 - ETA: 4:00 - loss: 0.5785 - accuracy: 0.7342 - recall_8: 0.7342 - precision_8: 0.734 - ETA: 4:00 - loss: 0.5830 - accuracy: 0.7300 - recall_8: 0.7300 - precision_8: 0.730 - ETA: 4:00 - loss: 0.5822 - accuracy: 0.7309 - recall_8: 0.7309 - precision_8: 0.730 - ETA: 3:59 - loss: 0.5869 - accuracy: 0.7268 - recall_8: 0.7268 - precision_8: 0.726 - ETA: 3:59 - loss: 0.5884 - accuracy: 0.7253 - recall_8: 0.7253 - precision_8: 0.725 - ETA: 3:59 - loss: 0.5906 - accuracy: 0.7238 - recall_8: 0.7238 - precision_8: 0.723 - ETA: 3:59 - loss: 0.5919 - accuracy: 0.7224 - recall_8: 0.7224 - precision_8: 0.722 - ETA: 3:58 - loss: 0.5885 - accuracy: 0.7256 - recall_8: 0.7256 - precision_8: 0.725 - ETA: 3:58 - loss: 0.5876 - accuracy: 0.7264 - recall_8: 0.7264 - precision_8: 0.726 - ETA: 3:58 - loss: 0.5867 - accuracy: 0.7273 - recall_8: 0.7273 - precision_8: 0.727 - ETA: 3:57 - loss: 0.5834 - accuracy: 0.7303 - recall_8: 0.7303 - precision_8: 0.730 - ETA: 3:57 - loss: 0.5850 - accuracy: 0.7289 - recall_8: 0.7289 - precision_8: 0.728 - ETA: 3:57 - loss: 0.5885 - accuracy: 0.7253 - recall_8: 0.7253 - precision_8: 0.725 - ETA: 3:56 - loss: 0.5851 - accuracy: 0.7283 - recall_8: 0.7283 - precision_8: 0.728 - ETA: 3:56 - loss: 0.5865 - accuracy: 0.7269 - recall_8: 0.7269 - precision_8: 0.726 - ETA: 3:56 - loss: 0.5885 - accuracy: 0.7255 - recall_8: 0.7255 - precision_8: 0.725 - ETA: 3:56 - loss: 0.5877 - accuracy: 0.7263 - recall_8: 0.7263 - precision_8: 0.7263190/882 [=====>........................] - ETA: 3:55 - loss: 0.5847 - accuracy: 0.7292 - recall_8: 0.7292 - precision_8: 0.729 - ETA: 3:55 - loss: 0.5861 - accuracy: 0.7278 - recall_8: 0.7278 - precision_8: 0.727 - ETA: 3:55 - loss: 0.5875 - accuracy: 0.7265 - recall_8: 0.7265 - precision_8: 0.726 - ETA: 3:54 - loss: 0.5867 - accuracy: 0.7273 - recall_8: 0.7273 - precision_8: 0.727 - ETA: 3:54 - loss: 0.5859 - accuracy: 0.7280 - recall_8: 0.7280 - precision_8: 0.728 - ETA: 3:54 - loss: 0.5873 - accuracy: 0.7267 - recall_8: 0.7267 - precision_8: 0.726 - ETA: 3:54 - loss: 0.5842 - accuracy: 0.7294 - recall_8: 0.7294 - precision_8: 0.729 - ETA: 3:53 - loss: 0.5836 - accuracy: 0.7301 - recall_8: 0.7301 - precision_8: 0.730 - ETA: 3:53 - loss: 0.5805 - accuracy: 0.7327 - recall_8: 0.7327 - precision_8: 0.732 - ETA: 3:53 - loss: 0.5824 - accuracy: 0.7314 - recall_8: 0.7314 - precision_8: 0.731 - ETA: 3:52 - loss: 0.5818 - accuracy: 0.7321 - recall_8: 0.7321 - precision_8: 0.732 - ETA: 3:52 - loss: 0.5812 - accuracy: 0.7327 - recall_8: 0.7327 - precision_8: 0.732 - ETA: 3:52 - loss: 0.5845 - accuracy: 0.7296 - recall_8: 0.7296 - precision_8: 0.729 - ETA: 3:52 - loss: 0.5862 - accuracy: 0.7284 - recall_8: 0.7284 - precision_8: 0.728 - ETA: 3:51 - loss: 0.5856 - accuracy: 0.7291 - recall_8: 0.7291 - precision_8: 0.729 - ETA: 3:51 - loss: 0.5872 - accuracy: 0.7279 - recall_8: 0.7279 - precision_8: 0.727 - ETA: 3:51 - loss: 0.5866 - accuracy: 0.7286 - recall_8: 0.7286 - precision_8: 0.728 - ETA: 3:50 - loss: 0.5859 - accuracy: 0.7292 - recall_8: 0.7292 - precision_8: 0.729 - ETA: 3:50 - loss: 0.5834 - accuracy: 0.7316 - recall_8: 0.7316 - precision_8: 0.731 - ETA: 3:50 - loss: 0.5828 - accuracy: 0.7322 - recall_8: 0.7322 - precision_8: 0.732 - ETA: 3:49 - loss: 0.5838 - accuracy: 0.7310 - recall_8: 0.7310 - precision_8: 0.731 - ETA: 3:49 - loss: 0.5853 - accuracy: 0.7299 - recall_8: 0.7299 - precision_8: 0.729 - ETA: 3:49 - loss: 0.5838 - accuracy: 0.7305 - recall_8: 0.7305 - precision_8: 0.730 - ETA: 3:49 - loss: 0.5833 - accuracy: 0.7311 - recall_8: 0.7311 - precision_8: 0.731 - ETA: 3:48 - loss: 0.5806 - accuracy: 0.7333 - recall_8: 0.7333 - precision_8: 0.733 - ETA: 3:48 - loss: 0.5781 - accuracy: 0.7355 - recall_8: 0.7355 - precision_8: 0.735 - ETA: 3:48 - loss: 0.5755 - accuracy: 0.7377 - recall_8: 0.7377 - precision_8: 0.737 - ETA: 3:47 - loss: 0.5733 - accuracy: 0.7398 - recall_8: 0.7398 - precision_8: 0.739 - ETA: 3:47 - loss: 0.5728 - accuracy: 0.7403 - recall_8: 0.7403 - precision_8: 0.740 - ETA: 3:47 - loss: 0.5723 - accuracy: 0.7408 - recall_8: 0.7408 - precision_8: 0.740 - ETA: 3:46 - loss: 0.5753 - accuracy: 0.7381 - recall_8: 0.7381 - precision_8: 0.738 - ETA: 3:46 - loss: 0.5732 - accuracy: 0.7402 - recall_8: 0.7402 - precision_8: 0.740 - ETA: 3:46 - loss: 0.5727 - accuracy: 0.7406 - recall_8: 0.7406 - precision_8: 0.740 - ETA: 3:46 - loss: 0.5754 - accuracy: 0.7380 - recall_8: 0.7380 - precision_8: 0.738 - ETA: 3:45 - loss: 0.5765 - accuracy: 0.7369 - recall_8: 0.7369 - precision_8: 0.736 - ETA: 3:45 - loss: 0.5760 - accuracy: 0.7374 - recall_8: 0.7374 - precision_8: 0.737 - ETA: 3:45 - loss: 0.5739 - accuracy: 0.7394 - recall_8: 0.7394 - precision_8: 0.739 - ETA: 3:45 - loss: 0.5734 - accuracy: 0.7398 - recall_8: 0.7398 - precision_8: 0.739 - ETA: 3:44 - loss: 0.5713 - accuracy: 0.7418 - recall_8: 0.7418 - precision_8: 0.741 - ETA: 3:44 - loss: 0.5691 - accuracy: 0.7437 - recall_8: 0.7437 - precision_8: 0.743 - ETA: 3:44 - loss: 0.5691 - accuracy: 0.7441 - recall_8: 0.7441 - precision_8: 0.744 - ETA: 3:43 - loss: 0.5687 - accuracy: 0.7445 - recall_8: 0.7445 - precision_8: 0.744 - ETA: 3:43 - loss: 0.5683 - accuracy: 0.7449 - recall_8: 0.7449 - precision_8: 0.744 - ETA: 3:43 - loss: 0.5709 - accuracy: 0.7424 - recall_8: 0.7424 - precision_8: 0.742 - ETA: 3:42 - loss: 0.5705 - accuracy: 0.7429 - recall_8: 0.7429 - precision_8: 0.742 - ETA: 3:42 - loss: 0.5685 - accuracy: 0.7447 - recall_8: 0.7447 - precision_8: 0.744 - ETA: 3:42 - loss: 0.5681 - accuracy: 0.7451 - recall_8: 0.7451 - precision_8: 0.745 - ETA: 3:42 - loss: 0.5662 - accuracy: 0.7469 - recall_8: 0.7469 - precision_8: 0.746 - ETA: 3:41 - loss: 0.5673 - accuracy: 0.7458 - recall_8: 0.7458 - precision_8: 0.745 - ETA: 3:41 - loss: 0.5684 - accuracy: 0.7448 - recall_8: 0.7448 - precision_8: 0.744 - ETA: 3:41 - loss: 0.5709 - accuracy: 0.7425 - recall_8: 0.7425 - precision_8: 0.742 - ETA: 3:40 - loss: 0.5720 - accuracy: 0.7415 - recall_8: 0.7415 - precision_8: 0.741 - ETA: 3:40 - loss: 0.5716 - accuracy: 0.7419 - recall_8: 0.7419 - precision_8: 0.741 - ETA: 3:40 - loss: 0.5712 - accuracy: 0.7423 - recall_8: 0.7423 - precision_8: 0.742 - ETA: 3:39 - loss: 0.5721 - accuracy: 0.7413 - recall_8: 0.7413 - precision_8: 0.741 - ETA: 3:39 - loss: 0.5717 - accuracy: 0.7417 - recall_8: 0.7417 - precision_8: 0.741 - ETA: 3:39 - loss: 0.5713 - accuracy: 0.7421 - recall_8: 0.7421 - precision_8: 0.742 - ETA: 3:38 - loss: 0.5693 - accuracy: 0.7438 - recall_8: 0.7438 - precision_8: 0.743 - ETA: 3:38 - loss: 0.5675 - accuracy: 0.7455 - recall_8: 0.7455 - precision_8: 0.745 - ETA: 3:38 - loss: 0.5657 - accuracy: 0.7471 - recall_8: 0.7471 - precision_8: 0.747 - ETA: 3:38 - loss: 0.5667 - accuracy: 0.7462 - recall_8: 0.7462 - precision_8: 0.746 - ETA: 3:37 - loss: 0.5648 - accuracy: 0.7478 - recall_8: 0.7478 - precision_8: 0.747 - ETA: 3:37 - loss: 0.5645 - accuracy: 0.7481 - recall_8: 0.7481 - precision_8: 0.748 - ETA: 3:37 - loss: 0.5641 - accuracy: 0.7484 - recall_8: 0.7484 - precision_8: 0.748 - ETA: 3:36 - loss: 0.5656 - accuracy: 0.7462 - recall_8: 0.7462 - precision_8: 0.746 - ETA: 3:36 - loss: 0.5681 - accuracy: 0.7441 - recall_8: 0.7441 - precision_8: 0.744 - ETA: 3:36 - loss: 0.5662 - accuracy: 0.7457 - recall_8: 0.7457 - precision_8: 0.745 - ETA: 3:35 - loss: 0.5659 - accuracy: 0.7460 - recall_8: 0.7460 - precision_8: 0.746 - ETA: 3:35 - loss: 0.5640 - accuracy: 0.7476 - recall_8: 0.7476 - precision_8: 0.747 - ETA: 3:35 - loss: 0.5634 - accuracy: 0.7479 - recall_8: 0.7479 - precision_8: 0.747 - ETA: 3:34 - loss: 0.5644 - accuracy: 0.7470 - recall_8: 0.7470 - precision_8: 0.747 - ETA: 3:34 - loss: 0.5627 - accuracy: 0.7485 - recall_8: 0.7485 - precision_8: 0.748 - ETA: 3:34 - loss: 0.5624 - accuracy: 0.7488 - recall_8: 0.7488 - precision_8: 0.748 - ETA: 3:34 - loss: 0.5612 - accuracy: 0.7491 - recall_8: 0.7491 - precision_8: 0.749 - ETA: 3:33 - loss: 0.5640 - accuracy: 0.7471 - recall_8: 0.7471 - precision_8: 0.747 - ETA: 3:33 - loss: 0.5637 - accuracy: 0.7474 - recall_8: 0.7474 - precision_8: 0.747 - ETA: 3:33 - loss: 0.5621 - accuracy: 0.7488 - recall_8: 0.7488 - precision_8: 0.748 - ETA: 3:32 - loss: 0.5618 - accuracy: 0.7491 - recall_8: 0.7491 - precision_8: 0.749 - ETA: 3:32 - loss: 0.5600 - accuracy: 0.7506 - recall_8: 0.7506 - precision_8: 0.750 - ETA: 3:32 - loss: 0.5616 - accuracy: 0.7497 - recall_8: 0.7497 - precision_8: 0.749 - ETA: 3:31 - loss: 0.5613 - accuracy: 0.7500 - recall_8: 0.7500 - precision_8: 0.750 - ETA: 3:31 - loss: 0.5610 - accuracy: 0.7503 - recall_8: 0.7503 - precision_8: 0.750 - ETA: 3:31 - loss: 0.5619 - accuracy: 0.7494 - recall_8: 0.7494 - precision_8: 0.749 - ETA: 3:31 - loss: 0.5616 - accuracy: 0.7497 - recall_8: 0.7497 - precision_8: 0.749 - ETA: 3:30 - loss: 0.5625 - accuracy: 0.7489 - recall_8: 0.7489 - precision_8: 0.748 - ETA: 3:30 - loss: 0.5608 - accuracy: 0.7503 - recall_8: 0.7503 - precision_8: 0.750 - ETA: 3:30 - loss: 0.5593 - accuracy: 0.7516 - recall_8: 0.7516 - precision_8: 0.751 - ETA: 3:29 - loss: 0.5597 - accuracy: 0.7508 - recall_8: 0.7508 - precision_8: 0.750 - ETA: 3:29 - loss: 0.5582 - accuracy: 0.7522 - recall_8: 0.7522 - precision_8: 0.752 - ETA: 3:29 - loss: 0.5580 - accuracy: 0.7524 - recall_8: 0.7524 - precision_8: 0.752 - ETA: 3:28 - loss: 0.5602 - accuracy: 0.7505 - recall_8: 0.7505 - precision_8: 0.750 - ETA: 3:28 - loss: 0.5611 - accuracy: 0.7497 - recall_8: 0.7497 - precision_8: 0.749 - ETA: 3:28 - loss: 0.5632 - accuracy: 0.7479 - recall_8: 0.7479 - precision_8: 0.747 - ETA: 3:28 - loss: 0.5652 - accuracy: 0.7460 - recall_8: 0.7460 - precision_8: 0.746 - ETA: 3:27 - loss: 0.5636 - accuracy: 0.7474 - recall_8: 0.7474 - precision_8: 0.7474"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/882 [========>.....................] - ETA: 3:27 - loss: 0.5645 - accuracy: 0.7466 - recall_8: 0.7466 - precision_8: 0.746 - ETA: 3:27 - loss: 0.5646 - accuracy: 0.7469 - recall_8: 0.7469 - precision_8: 0.746 - ETA: 3:26 - loss: 0.5656 - accuracy: 0.7461 - recall_8: 0.7461 - precision_8: 0.746 - ETA: 3:26 - loss: 0.5659 - accuracy: 0.7454 - recall_8: 0.7454 - precision_8: 0.745 - ETA: 3:26 - loss: 0.5678 - accuracy: 0.7436 - recall_8: 0.7436 - precision_8: 0.743 - ETA: 3:25 - loss: 0.5675 - accuracy: 0.7439 - recall_8: 0.7439 - precision_8: 0.743 - ETA: 3:25 - loss: 0.5694 - accuracy: 0.7421 - recall_8: 0.7421 - precision_8: 0.742 - ETA: 3:25 - loss: 0.5679 - accuracy: 0.7434 - recall_8: 0.7434 - precision_8: 0.743 - ETA: 3:25 - loss: 0.5676 - accuracy: 0.7437 - recall_8: 0.7437 - precision_8: 0.743 - ETA: 3:24 - loss: 0.5673 - accuracy: 0.7440 - recall_8: 0.7440 - precision_8: 0.744 - ETA: 3:24 - loss: 0.5681 - accuracy: 0.7433 - recall_8: 0.7433 - precision_8: 0.743 - ETA: 3:24 - loss: 0.5667 - accuracy: 0.7446 - recall_8: 0.7446 - precision_8: 0.744 - ETA: 3:23 - loss: 0.5664 - accuracy: 0.7448 - recall_8: 0.7448 - precision_8: 0.744 - ETA: 3:23 - loss: 0.5661 - accuracy: 0.7451 - recall_8: 0.7451 - precision_8: 0.745 - ETA: 3:23 - loss: 0.5658 - accuracy: 0.7454 - recall_8: 0.7454 - precision_8: 0.745 - ETA: 3:23 - loss: 0.5656 - accuracy: 0.7456 - recall_8: 0.7456 - precision_8: 0.745 - ETA: 3:22 - loss: 0.5643 - accuracy: 0.7469 - recall_8: 0.7469 - precision_8: 0.746 - ETA: 3:22 - loss: 0.5628 - accuracy: 0.7481 - recall_8: 0.7481 - precision_8: 0.748 - ETA: 3:22 - loss: 0.5629 - accuracy: 0.7483 - recall_8: 0.7483 - precision_8: 0.748 - ETA: 3:21 - loss: 0.5637 - accuracy: 0.7476 - recall_8: 0.7476 - precision_8: 0.747 - ETA: 3:21 - loss: 0.5624 - accuracy: 0.7488 - recall_8: 0.7488 - precision_8: 0.748 - ETA: 3:21 - loss: 0.5632 - accuracy: 0.7481 - recall_8: 0.7481 - precision_8: 0.748 - ETA: 3:20 - loss: 0.5617 - accuracy: 0.7493 - recall_8: 0.7493 - precision_8: 0.749 - ETA: 3:20 - loss: 0.5636 - accuracy: 0.7477 - recall_8: 0.7477 - precision_8: 0.747 - ETA: 3:20 - loss: 0.5634 - accuracy: 0.7479 - recall_8: 0.7479 - precision_8: 0.747 - ETA: 3:20 - loss: 0.5631 - accuracy: 0.7481 - recall_8: 0.7481 - precision_8: 0.748 - ETA: 3:19 - loss: 0.5619 - accuracy: 0.7493 - recall_8: 0.7493 - precision_8: 0.749 - ETA: 3:19 - loss: 0.5626 - accuracy: 0.7486 - recall_8: 0.7486 - precision_8: 0.748 - ETA: 3:19 - loss: 0.5614 - accuracy: 0.7498 - recall_8: 0.7498 - precision_8: 0.749 - ETA: 3:18 - loss: 0.5601 - accuracy: 0.7509 - recall_8: 0.7509 - precision_8: 0.750 - ETA: 3:18 - loss: 0.5588 - accuracy: 0.7520 - recall_8: 0.7520 - precision_8: 0.752 - ETA: 3:18 - loss: 0.5586 - accuracy: 0.7523 - recall_8: 0.7523 - precision_8: 0.752 - ETA: 3:17 - loss: 0.5584 - accuracy: 0.7525 - recall_8: 0.7525 - precision_8: 0.752 - ETA: 3:17 - loss: 0.5591 - accuracy: 0.7518 - recall_8: 0.7518 - precision_8: 0.751 - ETA: 3:17 - loss: 0.5579 - accuracy: 0.7529 - recall_8: 0.7529 - precision_8: 0.752 - ETA: 3:16 - loss: 0.5586 - accuracy: 0.7522 - recall_8: 0.7522 - precision_8: 0.752 - ETA: 3:16 - loss: 0.5584 - accuracy: 0.7524 - recall_8: 0.7524 - precision_8: 0.752 - ETA: 3:16 - loss: 0.5595 - accuracy: 0.7518 - recall_8: 0.7518 - precision_8: 0.751 - ETA: 3:16 - loss: 0.5615 - accuracy: 0.7502 - recall_8: 0.7502 - precision_8: 0.750 - ETA: 3:15 - loss: 0.5603 - accuracy: 0.7513 - recall_8: 0.7513 - precision_8: 0.751 - ETA: 3:15 - loss: 0.5601 - accuracy: 0.7515 - recall_8: 0.7515 - precision_8: 0.751 - ETA: 3:15 - loss: 0.5589 - accuracy: 0.7526 - recall_8: 0.7526 - precision_8: 0.752 - ETA: 3:14 - loss: 0.5576 - accuracy: 0.7536 - recall_8: 0.7536 - precision_8: 0.753 - ETA: 3:14 - loss: 0.5574 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 3:14 - loss: 0.5591 - accuracy: 0.7523 - recall_8: 0.7523 - precision_8: 0.752 - ETA: 3:13 - loss: 0.5592 - accuracy: 0.7525 - recall_8: 0.7525 - precision_8: 0.752 - ETA: 3:13 - loss: 0.5590 - accuracy: 0.7527 - recall_8: 0.7527 - precision_8: 0.752 - ETA: 3:13 - loss: 0.5579 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 3:13 - loss: 0.5587 - accuracy: 0.7531 - recall_8: 0.7531 - precision_8: 0.753 - ETA: 3:12 - loss: 0.5587 - accuracy: 0.7533 - recall_8: 0.7533 - precision_8: 0.753 - ETA: 3:12 - loss: 0.5594 - accuracy: 0.7527 - recall_8: 0.7527 - precision_8: 0.752 - ETA: 3:12 - loss: 0.5583 - accuracy: 0.7537 - recall_8: 0.7537 - precision_8: 0.753 - ETA: 3:11 - loss: 0.5571 - accuracy: 0.7547 - recall_8: 0.7547 - precision_8: 0.754 - ETA: 3:11 - loss: 0.5569 - accuracy: 0.7549 - recall_8: 0.7549 - precision_8: 0.754 - ETA: 3:11 - loss: 0.5558 - accuracy: 0.7559 - recall_8: 0.7559 - precision_8: 0.755 - ETA: 3:10 - loss: 0.5576 - accuracy: 0.7545 - recall_8: 0.7545 - precision_8: 0.754 - ETA: 3:10 - loss: 0.5568 - accuracy: 0.7547 - recall_8: 0.7547 - precision_8: 0.754 - ETA: 3:10 - loss: 0.5566 - accuracy: 0.7548 - recall_8: 0.7548 - precision_8: 0.754 - ETA: 3:09 - loss: 0.5587 - accuracy: 0.7534 - recall_8: 0.7534 - precision_8: 0.753 - ETA: 3:09 - loss: 0.5588 - accuracy: 0.7536 - recall_8: 0.7536 - precision_8: 0.753 - ETA: 3:09 - loss: 0.5585 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 3:09 - loss: 0.5575 - accuracy: 0.7548 - recall_8: 0.7548 - precision_8: 0.754 - ETA: 3:08 - loss: 0.5572 - accuracy: 0.7549 - recall_8: 0.7549 - precision_8: 0.754 - ETA: 3:08 - loss: 0.5570 - accuracy: 0.7551 - recall_8: 0.7551 - precision_8: 0.755 - ETA: 3:08 - loss: 0.5597 - accuracy: 0.7529 - recall_8: 0.7529 - precision_8: 0.752 - ETA: 3:07 - loss: 0.5613 - accuracy: 0.7516 - recall_8: 0.7516 - precision_8: 0.751 - ETA: 3:07 - loss: 0.5613 - accuracy: 0.7518 - recall_8: 0.7518 - precision_8: 0.751 - ETA: 3:07 - loss: 0.5611 - accuracy: 0.7519 - recall_8: 0.7519 - precision_8: 0.751 - ETA: 3:06 - loss: 0.5608 - accuracy: 0.7521 - recall_8: 0.7521 - precision_8: 0.752 - ETA: 3:06 - loss: 0.5606 - accuracy: 0.7523 - recall_8: 0.7523 - precision_8: 0.752 - ETA: 3:06 - loss: 0.5613 - accuracy: 0.7517 - recall_8: 0.7517 - precision_8: 0.751 - ETA: 3:06 - loss: 0.5601 - accuracy: 0.7527 - recall_8: 0.7527 - precision_8: 0.752 - ETA: 3:05 - loss: 0.5599 - accuracy: 0.7529 - recall_8: 0.7529 - precision_8: 0.752 - ETA: 3:05 - loss: 0.5589 - accuracy: 0.7538 - recall_8: 0.7538 - precision_8: 0.753 - ETA: 3:05 - loss: 0.5578 - accuracy: 0.7547 - recall_8: 0.7547 - precision_8: 0.754 - ETA: 3:04 - loss: 0.5577 - accuracy: 0.7549 - recall_8: 0.7549 - precision_8: 0.754 - ETA: 3:04 - loss: 0.5567 - accuracy: 0.7558 - recall_8: 0.7558 - precision_8: 0.755 - ETA: 3:04 - loss: 0.5571 - accuracy: 0.7552 - recall_8: 0.7552 - precision_8: 0.755 - ETA: 3:04 - loss: 0.5572 - accuracy: 0.7554 - recall_8: 0.7554 - precision_8: 0.755 - ETA: 3:03 - loss: 0.5570 - accuracy: 0.7556 - recall_8: 0.7556 - precision_8: 0.755 - ETA: 3:03 - loss: 0.5560 - accuracy: 0.7565 - recall_8: 0.7565 - precision_8: 0.756 - ETA: 3:03 - loss: 0.5558 - accuracy: 0.7566 - recall_8: 0.7566 - precision_8: 0.756 - ETA: 3:02 - loss: 0.5547 - accuracy: 0.7575 - recall_8: 0.7575 - precision_8: 0.757 - ETA: 3:02 - loss: 0.5546 - accuracy: 0.7577 - recall_8: 0.7577 - precision_8: 0.757 - ETA: 3:02 - loss: 0.5536 - accuracy: 0.7585 - recall_8: 0.7585 - precision_8: 0.758 - ETA: 3:01 - loss: 0.5542 - accuracy: 0.7580 - recall_8: 0.7580 - precision_8: 0.758 - ETA: 3:01 - loss: 0.5532 - accuracy: 0.7588 - recall_8: 0.7588 - precision_8: 0.758 - ETA: 3:01 - loss: 0.5530 - accuracy: 0.7590 - recall_8: 0.7590 - precision_8: 0.759 - ETA: 3:00 - loss: 0.5537 - accuracy: 0.7584 - recall_8: 0.7584 - precision_8: 0.758 - ETA: 3:00 - loss: 0.5546 - accuracy: 0.7579 - recall_8: 0.7579 - precision_8: 0.757 - ETA: 3:00 - loss: 0.5536 - accuracy: 0.7587 - recall_8: 0.7587 - precision_8: 0.758 - ETA: 3:00 - loss: 0.5559 - accuracy: 0.7574 - recall_8: 0.7574 - precision_8: 0.757 - ETA: 2:59 - loss: 0.5548 - accuracy: 0.7583 - recall_8: 0.7583 - precision_8: 0.758 - ETA: 2:59 - loss: 0.5547 - accuracy: 0.7585 - recall_8: 0.7585 - precision_8: 0.758 - ETA: 2:59 - loss: 0.5545 - accuracy: 0.7586 - recall_8: 0.7586 - precision_8: 0.7586"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/882 [===========>..................] - ETA: 2:58 - loss: 0.5543 - accuracy: 0.7587 - recall_8: 0.7587 - precision_8: 0.758 - ETA: 2:58 - loss: 0.5549 - accuracy: 0.7582 - recall_8: 0.7582 - precision_8: 0.758 - ETA: 2:58 - loss: 0.5548 - accuracy: 0.7583 - recall_8: 0.7583 - precision_8: 0.758 - ETA: 2:58 - loss: 0.5563 - accuracy: 0.7571 - recall_8: 0.7571 - precision_8: 0.757 - ETA: 2:57 - loss: 0.5561 - accuracy: 0.7572 - recall_8: 0.7572 - precision_8: 0.757 - ETA: 2:57 - loss: 0.5559 - accuracy: 0.7574 - recall_8: 0.7574 - precision_8: 0.757 - ETA: 2:57 - loss: 0.5549 - accuracy: 0.7582 - recall_8: 0.7582 - precision_8: 0.758 - ETA: 2:56 - loss: 0.5547 - accuracy: 0.7584 - recall_8: 0.7584 - precision_8: 0.758 - ETA: 2:56 - loss: 0.5545 - accuracy: 0.7585 - recall_8: 0.7585 - precision_8: 0.758 - ETA: 2:56 - loss: 0.5560 - accuracy: 0.7573 - recall_8: 0.7573 - precision_8: 0.757 - ETA: 2:55 - loss: 0.5559 - accuracy: 0.7574 - recall_8: 0.7574 - precision_8: 0.757 - ETA: 2:55 - loss: 0.5549 - accuracy: 0.7582 - recall_8: 0.7582 - precision_8: 0.758 - ETA: 2:55 - loss: 0.5548 - accuracy: 0.7584 - recall_8: 0.7584 - precision_8: 0.758 - ETA: 2:55 - loss: 0.5538 - accuracy: 0.7592 - recall_8: 0.7592 - precision_8: 0.759 - ETA: 2:54 - loss: 0.5528 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 2:54 - loss: 0.5535 - accuracy: 0.7595 - recall_8: 0.7595 - precision_8: 0.759 - ETA: 2:54 - loss: 0.5533 - accuracy: 0.7596 - recall_8: 0.7596 - precision_8: 0.759 - ETA: 2:53 - loss: 0.5546 - accuracy: 0.7584 - recall_8: 0.7584 - precision_8: 0.758 - ETA: 2:53 - loss: 0.5537 - accuracy: 0.7592 - recall_8: 0.7592 - precision_8: 0.759 - ETA: 2:53 - loss: 0.5544 - accuracy: 0.7587 - recall_8: 0.7587 - precision_8: 0.758 - ETA: 2:52 - loss: 0.5534 - accuracy: 0.7595 - recall_8: 0.7595 - precision_8: 0.759 - ETA: 2:52 - loss: 0.5545 - accuracy: 0.7590 - recall_8: 0.7590 - precision_8: 0.759 - ETA: 2:52 - loss: 0.5551 - accuracy: 0.7584 - recall_8: 0.7584 - precision_8: 0.758 - ETA: 2:52 - loss: 0.5557 - accuracy: 0.7579 - recall_8: 0.7579 - precision_8: 0.757 - ETA: 2:51 - loss: 0.5563 - accuracy: 0.7574 - recall_8: 0.7574 - precision_8: 0.757 - ETA: 2:51 - loss: 0.5561 - accuracy: 0.7576 - recall_8: 0.7576 - precision_8: 0.757 - ETA: 2:51 - loss: 0.5574 - accuracy: 0.7564 - recall_8: 0.7564 - precision_8: 0.756 - ETA: 2:50 - loss: 0.5572 - accuracy: 0.7565 - recall_8: 0.7565 - precision_8: 0.756 - ETA: 2:50 - loss: 0.5564 - accuracy: 0.7573 - recall_8: 0.7573 - precision_8: 0.757 - ETA: 2:50 - loss: 0.5555 - accuracy: 0.7581 - recall_8: 0.7581 - precision_8: 0.758 - ETA: 2:49 - loss: 0.5552 - accuracy: 0.7582 - recall_8: 0.7582 - precision_8: 0.758 - ETA: 2:49 - loss: 0.5551 - accuracy: 0.7584 - recall_8: 0.7584 - precision_8: 0.758 - ETA: 2:49 - loss: 0.5549 - accuracy: 0.7585 - recall_8: 0.7585 - precision_8: 0.758 - ETA: 2:49 - loss: 0.5541 - accuracy: 0.7592 - recall_8: 0.7592 - precision_8: 0.759 - ETA: 2:48 - loss: 0.5539 - accuracy: 0.7594 - recall_8: 0.7594 - precision_8: 0.759 - ETA: 2:48 - loss: 0.5530 - accuracy: 0.7601 - recall_8: 0.7601 - precision_8: 0.760 - ETA: 2:48 - loss: 0.5536 - accuracy: 0.7596 - recall_8: 0.7596 - precision_8: 0.759 - ETA: 2:47 - loss: 0.5548 - accuracy: 0.7585 - recall_8: 0.7585 - precision_8: 0.758 - ETA: 2:47 - loss: 0.5547 - accuracy: 0.7586 - recall_8: 0.7586 - precision_8: 0.758 - ETA: 2:47 - loss: 0.5545 - accuracy: 0.7588 - recall_8: 0.7588 - precision_8: 0.758 - ETA: 2:46 - loss: 0.5544 - accuracy: 0.7589 - recall_8: 0.7589 - precision_8: 0.758 - ETA: 2:46 - loss: 0.5545 - accuracy: 0.7590 - recall_8: 0.7590 - precision_8: 0.759 - ETA: 2:46 - loss: 0.5536 - accuracy: 0.7598 - recall_8: 0.7598 - precision_8: 0.759 - ETA: 2:46 - loss: 0.5548 - accuracy: 0.7587 - recall_8: 0.7587 - precision_8: 0.758 - ETA: 2:45 - loss: 0.5540 - accuracy: 0.7594 - recall_8: 0.7594 - precision_8: 0.759 - ETA: 2:45 - loss: 0.5538 - accuracy: 0.7595 - recall_8: 0.7595 - precision_8: 0.759 - ETA: 2:45 - loss: 0.5544 - accuracy: 0.7590 - recall_8: 0.7590 - precision_8: 0.759 - ETA: 2:44 - loss: 0.5535 - accuracy: 0.7598 - recall_8: 0.7598 - precision_8: 0.759 - ETA: 2:44 - loss: 0.5527 - accuracy: 0.7599 - recall_8: 0.7599 - precision_8: 0.759 - ETA: 2:44 - loss: 0.5533 - accuracy: 0.7594 - recall_8: 0.7594 - precision_8: 0.759 - ETA: 2:43 - loss: 0.5531 - accuracy: 0.7595 - recall_8: 0.7595 - precision_8: 0.759 - ETA: 2:43 - loss: 0.5523 - accuracy: 0.7602 - recall_8: 0.7602 - precision_8: 0.760 - ETA: 2:43 - loss: 0.5514 - accuracy: 0.7609 - recall_8: 0.7609 - precision_8: 0.760 - ETA: 2:43 - loss: 0.5519 - accuracy: 0.7605 - recall_8: 0.7605 - precision_8: 0.760 - ETA: 2:42 - loss: 0.5517 - accuracy: 0.7606 - recall_8: 0.7606 - precision_8: 0.760 - ETA: 2:42 - loss: 0.5535 - accuracy: 0.7595 - recall_8: 0.7595 - precision_8: 0.759 - ETA: 2:42 - loss: 0.5533 - accuracy: 0.7596 - recall_8: 0.7596 - precision_8: 0.759 - ETA: 2:41 - loss: 0.5524 - accuracy: 0.7603 - recall_8: 0.7603 - precision_8: 0.760 - ETA: 2:41 - loss: 0.5523 - accuracy: 0.7605 - recall_8: 0.7605 - precision_8: 0.760 - ETA: 2:41 - loss: 0.5515 - accuracy: 0.7612 - recall_8: 0.7612 - precision_8: 0.761 - ETA: 2:41 - loss: 0.5506 - accuracy: 0.7618 - recall_8: 0.7618 - precision_8: 0.761 - ETA: 2:40 - loss: 0.5512 - accuracy: 0.7614 - recall_8: 0.7614 - precision_8: 0.761 - ETA: 2:40 - loss: 0.5510 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 2:40 - loss: 0.5502 - accuracy: 0.7622 - recall_8: 0.7622 - precision_8: 0.762 - ETA: 2:39 - loss: 0.5494 - accuracy: 0.7629 - recall_8: 0.7629 - precision_8: 0.762 - ETA: 2:39 - loss: 0.5493 - accuracy: 0.7630 - recall_8: 0.7630 - precision_8: 0.763 - ETA: 2:39 - loss: 0.5511 - accuracy: 0.7614 - recall_8: 0.7614 - precision_8: 0.761 - ETA: 2:38 - loss: 0.5510 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 2:38 - loss: 0.5516 - accuracy: 0.7610 - recall_8: 0.7610 - precision_8: 0.761 - ETA: 2:38 - loss: 0.5514 - accuracy: 0.7611 - recall_8: 0.7611 - precision_8: 0.761 - ETA: 2:38 - loss: 0.5517 - accuracy: 0.7612 - recall_8: 0.7612 - precision_8: 0.761 - ETA: 2:37 - loss: 0.5515 - accuracy: 0.7613 - recall_8: 0.7613 - precision_8: 0.761 - ETA: 2:37 - loss: 0.5517 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 2:37 - loss: 0.5514 - accuracy: 0.7616 - recall_8: 0.7616 - precision_8: 0.761 - ETA: 2:36 - loss: 0.5506 - accuracy: 0.7622 - recall_8: 0.7622 - precision_8: 0.762 - ETA: 2:36 - loss: 0.5514 - accuracy: 0.7618 - recall_8: 0.7618 - precision_8: 0.761 - ETA: 2:36 - loss: 0.5519 - accuracy: 0.7613 - recall_8: 0.7613 - precision_8: 0.761 - ETA: 2:35 - loss: 0.5517 - accuracy: 0.7614 - recall_8: 0.7614 - precision_8: 0.761 - ETA: 2:35 - loss: 0.5515 - accuracy: 0.7615 - recall_8: 0.7615 - precision_8: 0.761 - ETA: 2:35 - loss: 0.5514 - accuracy: 0.7616 - recall_8: 0.7616 - precision_8: 0.761 - ETA: 2:35 - loss: 0.5519 - accuracy: 0.7612 - recall_8: 0.7612 - precision_8: 0.761 - ETA: 2:34 - loss: 0.5518 - accuracy: 0.7613 - recall_8: 0.7613 - precision_8: 0.761 - ETA: 2:34 - loss: 0.5530 - accuracy: 0.7603 - recall_8: 0.7603 - precision_8: 0.760 - ETA: 2:34 - loss: 0.5524 - accuracy: 0.7604 - recall_8: 0.7604 - precision_8: 0.760 - ETA: 2:33 - loss: 0.5530 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.760 - ETA: 2:33 - loss: 0.5534 - accuracy: 0.7596 - recall_8: 0.7596 - precision_8: 0.759 - ETA: 2:33 - loss: 0.5534 - accuracy: 0.7597 - recall_8: 0.7597 - precision_8: 0.759 - ETA: 2:33 - loss: 0.5542 - accuracy: 0.7592 - recall_8: 0.7592 - precision_8: 0.759 - ETA: 2:32 - loss: 0.5553 - accuracy: 0.7583 - recall_8: 0.7583 - precision_8: 0.758 - ETA: 2:32 - loss: 0.5552 - accuracy: 0.7584 - recall_8: 0.7584 - precision_8: 0.758 - ETA: 2:32 - loss: 0.5550 - accuracy: 0.7585 - recall_8: 0.7585 - precision_8: 0.758 - ETA: 2:31 - loss: 0.5542 - accuracy: 0.7592 - recall_8: 0.7592 - precision_8: 0.759 - ETA: 2:31 - loss: 0.5540 - accuracy: 0.7593 - recall_8: 0.7593 - precision_8: 0.759 - ETA: 2:31 - loss: 0.5532 - accuracy: 0.7599 - recall_8: 0.7599 - precision_8: 0.759 - ETA: 2:30 - loss: 0.5531 - accuracy: 0.7600 - recall_8: 0.7600 - precision_8: 0.7600"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/882 [============>.................] - ETA: 2:30 - loss: 0.5535 - accuracy: 0.7596 - recall_8: 0.7596 - precision_8: 0.759 - ETA: 2:30 - loss: 0.5540 - accuracy: 0.7592 - recall_8: 0.7592 - precision_8: 0.759 - ETA: 2:30 - loss: 0.5539 - accuracy: 0.7593 - recall_8: 0.7593 - precision_8: 0.759 - ETA: 2:29 - loss: 0.5537 - accuracy: 0.7594 - recall_8: 0.7594 - precision_8: 0.7594"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=Y_train1H, epochs=cnn_params['epochs'],\n",
    "                    verbose=1, batch_size=cnn_params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T09:52:42.894138Z",
     "start_time": "2021-04-18T09:52:42.888149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1\n",
      " 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(ypred_crackl_mean < 0.5, 0, 1)[:, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "494px",
    "left": "1299px",
    "right": "20px",
    "top": "125px",
    "width": "550px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
